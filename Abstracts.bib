@article{mcgrath_rem_1978,
	abstract = {Reviews the literature on {REM} sleep in regard to whether {REM} sleep prepares the S for subsequent learning or facilitates the retention of learning and/or the adaptation to prior stimulation. It is concluded that when studies are classified paradigmatically, E. M. Dewan's (1969) {REM} sleep metaprogramming hypothesis provides a useful conceptual scheme for interpreting the relevant literature. Suggested modifications to this hypothesis and anticipated future ones are discussed. (90 ref) ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved)},
}
@article{maho_responses_1992,
	abstract = {To test the hypothesis that new associations can be acquired during sleep, we developed a conditioning paradigm in which both conditioned ({CS)} and unconditioned ({US)} stimuli were non-awakening intra-cerebral stimulations. The {CS} was a stimulation of the Medial Geniculate body and the {US} a stimulation of the Central Grey. An increase in hippocampal multiunit activity to {CS} was taken as the conditioned response. {CS-US} pairings were presented across 14 sessions, with 15 trials per session and a 24-h inter-session interval. Three groups were studied: in a group the {CS-US} pairings were given during the awake state (group W), and in two groups pairings were presented during sleep, either slow-wave sleep (group {SWS)} or paradoxical sleep (group {PS).} In the last group, to test the possibility of transfer to the awake state of the hippocampal response acquired in {PS}, the {CS} alone were presented interspersed with periods of wakefulness. Results showed that, before pairing, {CS} presentation induced no change in hippocampal multiunit activity in the three groups. After pairing, no hippocampal response to {CS} presentation occurred in {SWS.} In contrast, in the W group and in the {PS} group, a marked increase in hippocampal activity appeared to {CS.} The hippocampal response in the {PS} group developed progressively across sessions; it occurred only two sessions later than in the W group. Moreover, when the {CS-evoked} response reached the asymptotic level in {PS}, the presentation of {CS} alone in awake animals elicited the hippocampal response. These results suggest that a cellular conditioning can be established during {PS} and that the cellular conditioned response developed in {PS} can be transferred to the awake state.},
}
@article{botvinick_short-term_2006,
	abstract = {Despite a century of research, the mechanisms underlying short-term or working memory for serial order remain uncertain. Recent theoretical models have converged on a particular account, based on transient associations between independent item and context representations. In the present article, the authors present an alternative model, according to which sequence information is encoded through sustained patterns of activation within a recurrent neural network architecture. As demonstrated through a series of computer simulations, the model provides a parsimonious account for numerous benchmark characteristics of immediate serial recall, including data that have been considered to preclude the application of recurrent neural networks in this domain. Unlike most competing accounts, the model deals naturally with findings concerning the role of background knowledge in serial recall and makes contact with relevant neuroscientific data. Furthermore, the model gives rise to numerous testable predictions that differentiate it from competing theories. Taken together, the results presented indicate that recurrent neural networks may offer a useful framework for understanding short-term memory for serial order.},
}
@article{ishibashi_different_2011,
	abstract = {A remarkable cognitive ability in humans is the competency to use a wide variety of different tools. Two cortical regions, the anterior temporal lobes ({ATL)} and left inferior parietal lobule ({IPL)}, have been proposed to make differential contributions to two kinds of knowledge about tools -- function vs. manipulation. We used repetitive transcranial magnetic stimulation ({rTMS)} and two semantic decision tasks to assess the role of these regions in healthy participants. Participants made semantic decisions about the function (what for) or manipulation (how) of tools used in daily life. The stimulation of {ATL} resulted in longer responses for the ``function'' judgments, whilst stimulation of {IPL} yielded longer responses for the ``manipulation'' judgments. In line with the neuropsychological literature, these results are discussed within hub-and-spoke framework of semantic memory.},
}
@article{ekaterini_processing_2002,
	abstract = {Under the theoretical assumption that lexical ambiguity is not a homogeneous phenomenon, but rather that it is subdivided into two distinct types, namely homonymy and polysemy, the present study investigated whether these different types of lexical ambiguity are psychologically real. Four types of ambiguous words, homonymous words (e.g., ``pen''), polysemous words with metaphorical extensions (e.g., ``eye''), polysemous words with a count/mass metonymic extension (e.g., ``turkey''), and polysemous words with a producer/product metonymic extension (e.g., {``Dali'')}, were used in a cross-modal sentence-priming lexical decision task. Overall, the theoretical distinction between homonymy and polysemy was reflected in the results of the present study, which revealed differential processing depending on the type of ambiguity.},
}
@article{randall_distinctiveness_2004,
	abstract = {Patients with category-specific deficits have motivated a range of hypotheses about the structure of the conceptual system. One class of models claims that apparent category dissociations emerge from the internal structure of concepts rather than fractionation of the system into separate substores. This account claims that distinctive properties of concepts in the living domain are vulnerable because of their weak correlation with other features. Given the assumption that mutual activation among correlated properties produces faster activation in the normal system, the authors predicted a disadvantage for the distinctive features of living things for unimpaired adults. Results of a speeded feature verification study supported this prediction, as did a computational simulation in which networks mapped from orthography to semantics.},
}
@article{bressler_cortical_2001,
	abstract = {New imaging techniques in cognitive neuroscience have produced a deluge of information correlating cognitive and neural phenomena. Yet our understanding of the inter-relationship between brain and mind remains hampered by the lack of a theoretical language for expressing cognitive functions in neural terms. We propose an approach to understanding operational laws in cognition based on principles of coordination dynamics that are derived from a simple and experimentally verified theoretical model. When applied to the dynamical properties of cortical areas and their coordination, these principles support a mechanism of adaptive inter-area pattern constraint that we postulate underlies cognitive operations generally.},
}
@article{watanabe_prediction_2011,
	abstract = {Application of multivoxel pattern analysis ({MVPA)} to functional magnetic resonance imaging ({fMRI)} data enables reconstruction and classification of cognitive status from brain activity. However, previous studies using {MVPA} have extracted information about cognitive status that is experienced simultaneously with {fMRI} scanning, but not one that will be observed after the scanning. In this study, by focusing on activity in the medial temporal lobe ({MTL)}, we demonstrate that {MVPA} on {fMRI} data is capable of predicting subsequent recognition performance. In this experiment, six runs of {fMRI} signals were acquired during encoding of phonogram stimuli. In the analysis, using data acquired in runs 1--3, we first conducted {MVPA-based} voxel-wise search for the clusters in the {MTL} whose signals contained the most information about subsequent recognition performance. Next, using the {fMRI} signals acquired in runs 1--3 from the selected clusters, we trained a classifier function in {MVPA.} Finally, the trained classifier function was applied to {fMRI} signals acquired in runs 4--6. Consequently, we succeeded in predicting the subsequent recognition performance for stimuli studied in runs 4--6 with significant accuracy. This accurate prediction suggests that {MVPA} can extract information that is associated not only with concurrent cognitive status, but also with behavior in the near future.},
}
@article{pavlides_long-term_1988,
	abstract = {Long-term potentiation ({LTP)}, a long lasting enhancement of synaptic efficacy is considered a model for learning and memory. In anesthetized rats, theta-rhythm was induced in the dentate gyrus by midbrain stimulation. Short trains of pulses were applied to the perforant pathway either at the peak of theta-rhythm or its trough. Trains applied at the peak of theta-rhythm induced {LTP} while trains applied at the trough produced a decrease of synaptic efficacy or had no effect. Thus, theta-rhythm may play a modulating role in the induction of {LTP}, suggesting a possible mnemonic function for the rhythm during the behaviors in which it occurs.},
}
@article{gibson_noisy-channel_2013,
	abstract = {The distribution of word orders across languages is highly nonuniform, with subject-verb-object ({SVO)} and subject-object-verb ({SOV)} orders being prevalent. Recent work suggests that the {SOV} order may be the default in human language. Why, then, is {SVO} order so common? We hypothesize that {SOV/SVO} variation can be explained by language users' sensitivity to the possibility of noise corrupting the linguistic signal. In particular, the noisy-channel hypothesis predicts a shift from the default {SOV} order to {SVO} order for semantically reversible events, for which potential ambiguity arises in {SOV} order because two plausible agents appear on the same side of the verb. We found support for this prediction in three languages (English, Japanese, and Korean) by using a gesture-production task, which reflects word-order preferences largely independent of native language. Other patterns of crosslinguistic variation (e.g., the prevalence of case marking in {SOV} languages and its relative absence in {SVO} languages) also straightforwardly follow from the noisy-channel hypothesis.},
}
@article{pollak_development_2009,
	abstract = {How do children's early social experiences influence their perception of emotion-specific information communicated by the face? To examine this question, we tested a group of abused children who had been exposed to extremely high levels of parental anger expression and physical threat. Children were presented with arrays of stimuli that depicted the unfolding of facial expressions, from neutrality to peak emotions. The abused children accurately recognized anger early in the formation of the facial expression, when few physiological cues were available. The speed of children's recognition was associated with the degree of anger/hostility reported by the child's parent. These data highlight the ways in which perceptual learning can shape the timing of emotion perception.},
}
@article{cloninger_role_1997,
	abstract = {Normal and abnormal personality development can be quantified in terms of 15 specific steps in the self-organization of character as a complex adaptive system. Character is measured as three dimensions of Self-directedness, Cooperativeness, and Self-transcendence, each with five components corresponding to steps in personality development. Each of these steps is differentially influenced by heritable temperament dimensions, antecedent steps in character development, and life experiences. Predictions about the nonlinear dynamics of personality development, such as equifinality and multifinality, are confirmed in longitudinal data about individuals representative of the general population. The stepwise development of character determines large differences between individuals in their risk of psychopathology, as well as varying degrees of maturity and health.},
}
@article{kan_role_2003,
	abstract = {Is our knowledge about the appearance of objects more closely related to verbal thought or to perception? In a behavioural study using a property verification task, Kosslyn (1976) reported that there are both amodal and perceptual representations of concepts, but that amodal representations may be more easily accessed. However, Solomon (1997) argued that due to the nature of Kosslyn's stimuli, subjects may be able to bypass semantics entirely and perform this task using differences in the strength of association between words in true trials (e.g., cat-whiskers) and those in false trials (e.g., mouse-stinger). Solomon found no evidence for amodal representations when the task materials were altered to include associated false trials (e.g., cat-litter), which require semantic processing, as opposed to associative strategies. In the current study, we used {fMRI} to examine the response of regions of visual association cortex while subjects performed a property verification task with either associated or unassociated false trials. We found reliable activity across subjects within the left fusiform gyrus when true trials were intermixed with associated false trials but not when true trials were intermixed with unassociated false trials. Our data support the idea that conceptual knowledge is organised visually and that it is grounded in the perceptual system.},
}
@article{schwartz_quantitative_1991,
	abstract = {Abstract This paper outlines a theoretical approach to the study of action in simple, routine activities, along with a coding system for describing and analysing performance. The approach is exemplified through a single case study involving a patient who developed a profound action disorder following rupture of a pericallosal artery aneurysm and concomitant anterior cerebral artery spasm. The Action Coding System provides a detailed, quantitative picture of this patient's action disorder as it was manifested in two routine tasks and as it recovered over time. Discussion focuses on the cognitive organisation and processing of simple, everyday tasks and suggests how disruption of performance may ensue when intentional control of action is compromised.},
}
@article{plaut_understanding_1996,
	abstract = {A connectionist approach to processing in quasi-regular domains, as exemplified by English word reading, is developed. Networks using appropriately structured orthographic and phonological representations were trained to read both regular and exception words, and yet were also able to read pronounceable nonwords as well as skilled readers. A mathematical analysis of a simplified system clarifies the close relationship of word frequency and spelling-sound consistency in influencing naming latencies. These insights were verified in subsequent simulations, including an attractor network that accounted for latency data directly in its time to settle on a response. Further analyses of the ability of networks to reproduce data on acquired surface dyslexia support a view of the reading system that incorporates a graded division of labor between semantic and phonological processes, and contrasts in important ways with the standard dual-route account.},
}
@article{barsalou_simulation_2009,
	abstract = {Based on accumulating evidence, simulation appears to be a basic computational mechanism in the brain that supports a broad spectrum of processes from perception to social cognition. Further evidence suggests that simulation is typically situated, with the situated character of experience in the environment being reflected in the situated character of the representations that underlie simulation. A basic architecture is sketched of how the brain implements situated simulation. Within this framework, simulators implement the concepts that underlie knowledge, and situated conceptualizations capture patterns of multi-modal simulation associated with frequently experienced situations. A pattern completion inference mechanism uses current perception to activate situated conceptualizations that produce predictions via simulations on relevant modalities. Empirical findings from perception, action, working memory, conceptual processing, language and social cognition illustrate how this framework produces the extensive prediction that characterizes natural intelligence.},
}
@article{mesulam_words_2013,
}
@article{rasmussen_model_2012,
	abstract = {Interest is increasing in applying discriminative multivariate analysis techniques to the analysis of functional neuroimaging data. Model interpretation is of great importance in the neuroimaging context, and is conventionally based on a 'brain map' derived from the classification model. In this study we focus on the relative influence of model regularization parameter choices on both the model generalization, the reliability of the spatial patterns extracted from the classification model, and the ability of the resulting model to identify relevant brain networks defining the underlying neural encoding of the experiment. For a support vector machine, logistic regression and Fisher's discriminant analysis we demonstrate that selection of model regularization parameters has a strong but consistent impact on the generalizability and both the reproducibility and interpretable sparsity of the models for both L 2 and L 1 regularization. Importantly, we illustrate a trade-off between model spatial reproducibility and prediction accuracy. We show that known parts of brain networks can be overlooked in pursuing maximization of classification accuracy alone with either L 2 and/or L 1 regularization. This supports the view that the quality of spatial patterns extracted from models cannot be assessed purely by focusing on prediction accuracy. Our results instead suggest that model regularization parameters must be carefully selected, so that the model and its visualization enhance our ability to interpret the brain.},
}
@article{chouinard_category-specific_2010,
	abstract = {Using activation-likelihood estimation ({ALE)} meta-analysis, we identified brain areas that are invoked when people name pictures of animals and pictures of tools. We found that naming animals and naming tools invoked separate distributed networks in the brain. Specifically, we found that naming animals invoked greater responses than naming tools in frontal lobe structures that are typically modulated by emotional content and task demands, and in a number of visual areas in the ventral stream. In contrast, naming tools invoked greater responses in a different set of areas in the ventral stream than those invoked by naming animals. Naming tools also invoked greater responses than naming animals in motor areas in the frontal lobe as well as in sensory areas in the parietal lobe. The only overlapping sites of activation that we found for naming these two categories of objects were in the left pars triangularis, the left inferior temporal gyrus, and the left parahippocampal gyrus. Taken together, our meta-analysis reveals that animals and tools are categorically represented in visual areas but show convergence in higher-order associative areas in the temporal and frontal lobes in regions that are typically regarded as being involved in memory and/or semantic processing. Our results also reveal that naming tools not only engages visual areas in the ventral stream but also a fronto-parietal network associated with tool use. Whether or not this network associated with tool use contributes directly to recognition will require further investigation.},
}
@article{bornstein_color_1976,
	abstract = {2 studies examined the organization of color perception in a total of 165 4-mo-old infants. In Study 1, Ss looked at selected spectral stimuli repeatedly until their visual attention waned. The stimuli represented instances of basic adult hue categories (blue, green, yellow, and red). Following habituation, Ss were shown a series of wavelengths which were the same as or different from the stimuli first seen. Analyses of infant attention indicate that infants categorize wavelengths by perceptual similarity (i.e., they see hues in the spectrum much as adults do). In Study 2, infants who looked at the alteration of 2 wavelengths from the same hue category habituated as did Ss who looked at the repetition of a single wavelength from that category, but Ss who looked at 2 wavelengths from different categories habituated at a slower rate. Data suggest a high degree of organization of the color world prior to language acquisition. (11/2 p ref)},
}
@article{mummery_disrupted_1999,
}
@article{rich_brief_1997,
	abstract = {Shortly before the time of this writing, Michael Ter-Pogossian, {PhD}, passed away at the age of 71. He was considered by many to be the father of {PET} and is best known for experiments beginning in the 1950s, which led to the development of {PET} as a practical diagnostic tool (Fig. 1). In my research of the literature for this article, Dr. Ter-Pogossian's name appeared frequently on many of the landmark publications and I have drawn heavily from his work as a historian and scientist. His death is a great loss to the nuclear medicine community. It is with his achievements in mind, as well as the achievements of many other outstanding scientists, that I have written this article. I have tried to be as accurate as possible in my documentation of events as well as in my interpretation of their significance. I trust that the reader will gain as much as I have from this endeavor.},
}
@article{tranel_left_2009,
	abstract = {Background: The neuroanatomical basis of lexical retrieval has been studied intensively. The current review focuses on the special case of proper nouns. Aims: This article reviews a programme of research that has used both lesion-deficit and functional-imaging ({PET)} approaches to investigate the neuroanatomical basis for lexical retrieval of proper nouns. In lesion-deficit studies we found that damage to the left temporal polar ({TP)} region leads to reliable and specific impairments in naming famous persons (e.g., {``George} Clooney'') and famous landmarks (e.g., {``Golden} Gate Bridge''). In functional-imaging studies we found that when participants name famous persons and landmarks they produce specific activation (increases in regional cerebral blood flow) in the left {TP} region. Main Contribution: These findings converge with lesion and functional-imaging data from other laboratories to support the idea that the left {TP} region is important for the retrieval of names for unique concrete entities, persons and landmarks being typical examples of such categories of entities. Conclusions: We have interpreted these results within a theoretical framework which suggests that left {TP} contains convergence regions that operate as intermediaries between conceptual knowledge retrieval and lexical retrieval for classes of unique concrete entities.},
}
@article{fogassi_parietal_2005,
	abstract = {Inferior parietal lobule ({IPL)} neurons were studied when monkeys performed motor acts embedded in different actions and when they observed similar acts done by an experimenter. Most motor {IPL} neurons coding a specific act (e.g., grasping) showed markedly different activations when this act was part of different actions (e.g., for eating or for placing). Many motor {IPL} neurons also discharged during the observation of acts done by others. Most responded differentially when the same observed act was embedded in a specific action. These neurons fired during the observation of an act, before the beginning of the subsequent acts specifying the action. Thus, these neurons not only code the observed motor act but also allow the observer to understand the agent's intentions.},
}
@article{lin_seeing_2009,
	abstract = {When an image is presented to one eye and a very different image is presented to the corresponding location of the other eye, the two images compete for conscious representations, such that only one image is visible at a time while the other is suppressed. Called binocular rivalry, this phenomenon and its deviants have been extensively exploited to study the mechanism and neural correlates of consciousness. In this paper, we propose a framework - the unconscious binding hypothesis - to distinguish unconscious processing from conscious processing. According to this framework, the unconscious mind not only encodes individual features but also temporally binds distributed features to give rise to cortical representations; unlike conscious binding, however, unconscious binding is fragile. Under this framework, we review evidence from psychophysical and neuroimaging studies and come to two important conclusions. First, processing of invisible features depends on the "level" of the features as defined by their neural mechanisms. For low-level simple features, prolonged exposure to visual patterns (e.g. tilt) and simple translational motion can alter the appearance of subsequent visible features (i.e. adaptation). For invisible high-level features, complex spiral motion cannot produce adaptation, nor can objects/words enhance subsequent processing of related stimuli (i.e. priming). Yet images of tools can activate the dorsal pathway. Second, processing of invisible features has functional significance. Although invisible central cues cannot orient attention, invisible erotic pictures in the periphery can nevertheless guide attention, likely through emotional arousal; reciprocally, the processing of invisible information can be modulated by attention.},
}
@article{carter_nexus_2013,
}
@article{balota_english_2007,
}
@article{mo_electrophysiological_2011,
	abstract = {Previous studies have shown that the effect of language on categorical perception of color is stronger when stimuli are presented in the right visual field than in the left. To examine whether this lateralized effect occurs preattentively at an early stage of processing, we monitored the visual mismatch negativity, which is a component of the event-related potential of the brain to an unfamiliar stimulus among a temporally presented series of stimuli. In the oddball paradigm we used, the deviant stimuli were unrelated to the explicit task. A significant interaction between color-pair type (within-category vs. between-category) and visual field (left vs. right) was found. The amplitude of the visual mismatch negativity component evoked by the within-category deviant was significantly smaller than that evoked by the between-category deviant when displayed in the right visual field, but no such difference was observed for the left visual field. This result constitutes electroencephalographic evidence that the lateralized Whorf effect per se occurs out of awareness and at an early stage of processing.},
}
@article{roelofs_dynamics_2008,
	abstract = {Since W. Wundt (1904) and H. J. Watt (1906), researchers have found no agreement on how goals direct word retrieval. A prevailing associative account (E. K. Miller \& J. D. Cohen, 2001) holds that goals bias association strength, which determines retrieval latency and whether irrelevant words interfere. A symbolic account (A. Roelofs, 2003) holds that goals enable retrieval rules and predicts no strict dependence of interference on latency. Here, 3 chronometric experiments in which the role of relative retrieval latency was investigated through distributional analyses, following Watt, are reported. Participants verbally categorized picture-word pairs that were semantically related or unrelated, or they categorized single pictures or words. The pairs yielded semantic latency effects in both word and picture categorizing, although single words were categorized slower than single pictures. Semantic effects occurred in word categorizing even when postexposure of the pictures compensated for the difference in categorizing latency. Vincentile and ex-Gaussian analyses revealed that the semantic effects occurred throughout the latency distributions, excluding goal neglect as the cause of the effects. The results were interpreted as most consistent with the symbolic account, which was corroborated by computer simulations. ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved) (journal abstract)},
}
@article{devlin_is_2002,
	abstract = {Patients with semantic impairments sometimes demonstrate category-specific deficits suggesting that the anatomical substrates of semantic memory may reflect categorical organisation, however, neuroimaging studies have failed to provide consistent data in support of a category-based account. We conducted three functional neuroimaging experiments to investigate the neural correlates of semantic processing, two with positron emission tomography ({PET)} and a third with functional magnetic resonance imaging ({fMRI).} The first experiment used a lexical decision task to search for brain regions selectively activated by concepts from four different categories---animals, fruit, tools, and vehicles. The second experiment used a semantic categorisation task to increase the demands on the semantic system and to look for evidence of consistent activations for the domains of natural kinds or man-made items. The final experiment was a replication of the semantic categorisation task using {fMRI} to increase the spatial resolution and statistical sensitivity of the experiment. The results of these experiments reliably identified a distributed neural system common to both natural kinds and artifacts but failed to find robust evidence of functional segregation by domain or categories. Category effects were neither reliable nor consistently present across experiments although some were consistent with previous studies. We discuss the implications of these findings, arguing that they are most consistent with a semantic system undifferentiated by category at the neural level.},
}
@article{lyon_disynaptic_2010,
	abstract = {Summary 
}
@article{kaunitz_intercepting_2011,
	abstract = {The operations and processes that the human brain employs to achieve fast visual categorization remain a matter of debate. A first issue concerns the timing and place of rapid visual categorization and to what extent it can be performed with an early feed-forward pass of information through the visual system. A second issue involves the categorization of stimuli that do not reach visual awareness. There is disagreement over the degree to which these stimuli activate the same early mechanisms as stimuli that are consciously perceived. We employed continuous flash suppression ({CFS)}, {EEG} recordings, and machine learning techniques to study visual categorization of seen and unseen stimuli. Our classifiers were able to predict from the {EEG} recordings the category of stimuli on seen trials but not on unseen trials. Rapid categorization of conscious images could be detected around 100ms on the occipital electrodes, consistent with a fast, feed-forward mechanism of target detection. For the invisible stimuli, however, {CFS} eliminated all traces of early processing. Our results support the idea of a fast mechanism of categorization and suggest that this early categorization process plays an important role in later, more subtle categorizations, and perceptual processes.},
}
@article{kay_what_1984,
	abstract = {The history of empirical research on the Sapir-Whorf hypothesis is reviewed. A more sensitive test of the hypothesis is devised and a clear Whorfian effect is detected in the domain of color. A specific mechanism is proposed to account for this effect and a second experiment, designed to block the hypothesized mechanism, is performed. The effect disappears as predicted. The Sapir-Whorf hypothesis is reevaluated in the light of these results.},
}
@article{eichenbaum_towards_2012,
	abstract = {Here we describe a model of medial temporal lobe organization in which parallel ``what'' and ``where'' processing streams converge within the hippocampus to represent events in the spatio-temporal context in which they occurred; this circuitry also mediates the retrieval of context from event cues and vice versa, which are prototypes of episodic recall. Evidence from studies in animals are reviewed in support of this model, including experiments that distinguish characteristics of episodic recollection from familiarity, neuropsychological and recording studies that have identified a key role for the hippocampus in recollection and in associating events with the context in which they occurred, and distinct roles for parahippocampal region areas in separate ``what'' and ``where'' information processing that contributes to recollective and episodic memory.},
}
@article{ralph_taking_2010,
}
@article{mechelli_dynamic_2003,
	abstract = {In this study, we combined functional magnetic resonance imaging ({fMRI)} and dynamic causal modeling ({DCM)} to investigate whether object category effects in the occipital and temporal cortex are mediated by inputs from early visual cortex or parietal regions. Resolving this issue may provide anatomical constraints on theories of category specificity--- which make different assumptions about the underlying neurophysiology. The data were acquired by Ishai, Ungerleider, Martin, Schouten, and Haxby (1999, 2000) and provided by the National {fMRI} Data Center (http://www.fmridc.org). The original authors used a conventional analysis to estimate differential effects in the occipital and temporal cortex in response to pictures of chairs, faces, and houses. We extended this approach by estimating neuronal interactions that mediate category effects using {DCM.} {DCM} uses a Bayesian framework to estimate and make inferences about the influence that one region exerts over another and how this is affected by experimental changes. {DCM} differs from previous approaches to brain connectivity, such as multivariate autoregressive models and structural equation modeling, as it assumes that the observed hemodynamic responses are driven by experimental changes rather than endogenous noise. {DCM} therefore brings the analysis of brain connectivity much closer to the analysis of regionally specific effects usually applied to functional imaging data. We used {DCM} to estimate the influence that V3 and the superior/inferior parietal cortex exerted over category-responsive regions and how this was affected by the presentation of houses, faces, and chairs. We found that category effects in occipital and temporal cortex were mediated by inputs from early visual cortex. In contrast, the connectivity from the superior/inferior parietal area to the category-responsive areas was unaffected by the presentation of chairs, faces, or houses. These findings indicate that category effects in the occipital and temporal cortex can be mediated by bottom--up mechanisms---a finding that needs to be embraced by models of category specificity.},
}
@misc{bates_linear_2013,
}
@book{marr_vision:_1982,
}
@article{kay_resolving_2003,
	abstract = {The existence of cross-linguistic universals in color naming is currently contested. Early empirical studies, based principally on languages of industrialized societies, suggested that all languages may draw on a universally shared repertoire of color categories. Recent work, in contrast, based on languages from nonindustrialized societies, has suggested that color categories may not be universal. No comprehensive objective tests have yet been conducted to resolve this issue. We conduct such tests on color naming data from languages of both industrialized and nonindustrialized societies and show that strong universal tendencies in color naming exist across both sorts of language.},
}
@article{grabowski_role_2001,
	abstract = {Both lesion and functional imaging studies have implicated sectors of high-order association cortices of the left temporal lobe in the retrieval of words for objects belonging to varied conceptual categories. In particular, the cortices located in the left temporal pole have been associated with naming unique persons from faces. Because this neuroanatomical-behavioral association might be related to either the specificity of the task (retrieving a name at unique level) or to the possible preferential processing of faces by anterior temporal cortices, we performed a {PET} imaging experiment to test the hypothesis that the effect is related to the specificity of the word retrieval task. Normal subjects were asked to name at unique level entities from two conceptual categories: famous landmarks and famous faces. In support of the hypothesis, naming entities in both categories was associated with increases in activity in the left temporal pole. No main effect of category (faces vs. landmarks/buildings) or interaction of task and category was found in the left temporal pole. Retrieving names for unique persons and for names for unique landmarks activate the same brain region. These findings are consistent with the notion that activity in the left temporal pole is linked to the level of specificity of word retrieval rather than the conceptual class to which the stimulus belongs. Hum. Brain Mapping 13:199--212, 2001. \copywrite 2001 Wiley-Liss, Inc.},
}
@article{grafman_conceptualizing_2000,
	abstract = {There are at least four major forms of functional neuroplasticity that can be studied in humans: homologous area adaptation, cross-modal reassignment, map expansion, and compensatory masquerade. Homologous area adaptation is the assumption of a particular cognitive process by a homologous region in the opposite hemisphere. Cross-modal reassignment occurs when structures previously devoted to processing a particular kind of sensory input now accepts input from a new sensory method. Map expansion is the enlargement of a functional brain region on the basis of performance. Compensatory masquerade is a novel allocation of a particular cognitive process to perform a task. By focusing on these four forms of functional neuroplasticity, several fundamental questions about how functional cooperation between brain regions is achieved can be addressed.},
}
@article{noppeney_two_2006,
	abstract = {The cognitive and neural mechanisms mediating category-selective responses in the human brain remain controversial. Using functional magnetic resonance imaging and effective connectivity analyses (Dynamic Causal Modelling), we investigated animal- and tool-selective responses by manipulating stimulus modality (pictures versus words) and task (implicit versus explicit semantic). We dissociated two distinct mechanisms that engender category selectivity: in the ventral occipito-temporal cortex, tool-selective responses were observed irrespective of task, greater for pictures and mediated by bottom-up effects. In a left temporo-parietal action system, tool-selective responses were observed irrespective of modality, greater for explicit semantic tasks and mediated by top-down modulation from the left prefrontal cortex. These distinct activation and connectivity patterns suggest that the two systems support different cognitive operations, with the ventral occipito-temporal regions engaged in structural processing and the dorsal visuo-motor system in strategic semantic processing. Consistent with current semantic theories, explicit semantic processing of tools might thus rely on reactivating their associated action representations via top-down modulation. In terms of neuronal mechanisms, the category selectivity may be mediated by distinct top-down (task-dependent) and bottom-up (stimulus-dependent) mechanisms.},
}
@article{huk_task-related_2000,
}
@article{dozois_changes_2009,
	abstract = {Negative cognitive structure (particularly for interpersonal content) has been shown in some research to persist past a current episode of depression and potentially to be a stable marker of vulnerability for depression (D. J. A. Dozois, 2007; D. J. A. Dozois \& K. S. Dobson, 2001a). Given that cognitive therapy ({CT)} is highly effective for treating the acute phase of a depressive episode and that this treatment also reduces the risk of relapse and recurrence, it is possible that {CT} may alter these stable cognitive structures. In the current study, patients were randomly assigned to {CT+} pharmacotherapy (n = 21) or to pharmacotherapy alone (n = 21). Both groups evidenced significant and similar reductions in level of depression (as measured with the Beck Depression Inventory-{II} and the Hamilton Rating Scale for Depression), as well as automatic thoughts and dysfunctional attitudes. However, group differences were found on cognitive organization in favor of individuals who received the combination of {CT+} pharmacotherapy. The implications of these results for understanding mechanisms of change in therapy and the prophylactic nature of {CT} are discussed.},
}
@article{koch_attention_2007,
	abstract = {The close relationship between attention and consciousness has led many scholars to conflate these processes. This article summarizes psychophysical evidence, arguing that top-down attention and consciousness are distinct phenomena that need not occur together and that can be manipulated using distinct paradigms. Subjects can become conscious of an isolated object or the gist of a scene despite the near absence of top-down attention; conversely, subjects can attend to perceptually invisible objects. Furthermore, top-down attention and consciousness can have opposing effects. Such dissociations are easier to understand when the different functions of these two processes are considered. Untangling their tight relationship is necessary for the scientific elucidation of consciousness and its material substrate.},
}
@article{hill_sleep_2008,
	abstract = {Sleep after learning often enhances task performance, but the underlying mechanisms remain unclear. Using a well-characterized rotation learning paradigm implemented both behaviorally and in computer simulations, we compared two main hypotheses: the first, that off-line replay during sleep leads to further potentiation of synaptic circuits involved in learning; the second, that sleep enhances performance by uniformly downscaling synaptic strength. A simple computer model implemented synaptic changes associated with rotation adaptation (30 degrees ), yielding a reduction in mean directional error. Simulating further synaptic potentiation led to a further reduction of mean directional error, but not of directional variability. By contrast, simulating sleep-dependent synaptic renormalization by scaling down all synaptic weights by 15\% decreased both mean directional error and variability. Two groups of subjects were tested after either two rotation adaptation training sessions or after a single training session followed by sleep. After two training sessions, mean direction error decreased, but directional variability remained high. However, subjects who slept after a single training session showed a reduction in both directional error and variability, consistent with a downscaling mechanism during sleep.},
}
@article{kanwisher_fusiform_1997,
	abstract = {Using functional magnetic resonance imaging ({fMRI)}, we found an area in the fusiform gyrus in 12 of the 15 subjects tested that was significantly more active when the subjects viewed faces than when they viewed assorted common objects. This face activation was used to define a specific region of interest individually for each subject, within which several new tests of face specificity were run. In each of five subjects tested, the predefined candidate ``face area'' also responded significantly more strongly to passive viewing of (1) intact than scrambled two-tone faces, (2) full front-view face photos than front-view photos of houses, and (in a different set of five subjects) (3) three-quarter-view face photos (with hair concealed) than photos of human hands; it also responded more strongly during (4) a consecutive matching task performed on three-quarter-view faces versus hands. Our technique of running multiple tests applied to the same region defined functionally within individual subjects provides a solution to two common problems in functional imaging: (1) the requirement to correct for multiple statistical comparisons and (2) the inevitable ambiguity in the interpretation of any study in which only two or three conditions are compared. Our data allow us to reject alternative accounts of the function of the fusiform face area (area {``FF'')} that appeal to visual attention, subordinate-level classification, or general processing of any animate or human forms, demonstrating that this region is selectively involved in the perception of faces.},
}
@article{kutas_thirty_2011,
	abstract = {We review the discovery, characterization, and evolving use of the N400, an event-related brain potential response linked to meaning processing. We describe the elicitation of N400s by an impressive range of stimulus types---including written, spoken, and signed words or pseudowords; drawings, photos, and videos of faces, objects, and actions; sounds; and mathematical symbols---and outline the sensitivity of N400 amplitude (as its latency is remarkably constant) to linguistic and nonlinguistic manipulations. We emphasize the effectiveness of the N400 as a dependent variable for examining almost every aspect of language processing and highlight its expanding use to probe semantic memory and to determine how the neurocognitive system dynamically and flexibly uses bottom-up and top-down information to make sense of the world. We conclude with different theories of the N400's functional significance and offer an N400-inspired reconceptualization of how meaning processing might unfold.},
}
@article{mummery_generating_1996,
	abstract = {Positron emission tomography was used to investigate differences in regional cerebral activity during word retrieval in response to different prompts. The contrast of semantic category fluency and initial letter fluency resulted in selective activation of left temporal regions; the reverse contrast yielded activation in left frontal regions ({BA44/6).} A further comparison between types of category fluency demonstrated a more anterior temporal response for natural kinds and more posterior activation for manipulable manmade objects. These results support behavioural data suggesting that category fluency is relatively more dependent on temporal-lobe regions, and initial letter fluency on frontal structures; and that categorical word retrieval is not a uniformly distributed function within the brain. This is compatible with the category-specific deficits observed after some focal lesions.},
}
@article{pulvermuller_brain_2005,
	abstract = {For a long time the cortical systems for language and actions were believed to be independent modules. However, as these systems are reciprocally connected with each other, information about language and actions might interact in distributed neuronal assemblies. A critical case is that of action words that are semantically related to different parts of the body (for example, 'lick', 'pick' and 'kick'): does the comprehension of these words specifically, rapidly and automatically activate the motor system in a somatotopic manner, and does their comprehension rely on activity in the action system?},
}
@article{chou_object-based_2012,
	abstract = {In this study, we investigated whether awareness of objects is necessary for object-based guidance of attention. We used the two-rectangle method (Egly, Driver, \& Rafal, 1994) to probe object-based attention and adopted the continuous flash suppression technique (Tsuchiya \& Koch, 2005) to control for the visibility of the two rectangles. Our results show that object-based attention, as indexed by the same-object advantage---faster response to a target within a cued object than within a noncued object---was obtained regardless of participants' awareness of the objects. This study provides the first evidence of object-based attention under unconscious conditions by showing that the selection unit of attention can be at an object level even when these objects are invisible---a level higher than the previous evidence for a subliminally cued location. We suggest that object-based attentional guidance plays a fundamental role of binding features in both the conscious and unconscious mind.},
}
@article{lamb_spectrophotometric_1975,
}
@article{walker_sleep-dependent_2004,
	abstract = {While the functions of sleep remain largely unknown, one of the most exciting and contentious hypotheses is that sleep contributes importantly to memory. A large number of studies offer a substantive body of evidence supporting this role of sleep in what is becoming known as sleep-dependent memory processing. This review will provide evidence of sleep-dependent memory consolidation and sleep-dependent brain plasticity and is divided into five sections: (1) an overview of sleep stages, memory categories, and the distinct stages of memory development; (2) a review of the specific relationships between sleep and memory, both in humans and animals; (3) a survey of evidence describing sleep-dependent brain plasticity, including human brain imaging studies as well as animal studies of cellular neurophysiology and molecular biology. We close (4) with a consideration of unanswered questions as well as existing arguments against the role of sleep in learning and memory and (5) a concluding summary.},
}
@article{capitani_what_2003,
	abstract = {In this study we provide a critical review of the clinical evidence available to date in the field of semantic category-specific deficits. The motivation for undertaking this review is that not all the data reported in the literature are useful for adjudicating among extant theories. This project is an attempt to answer two basic questions: (1) what are the categories of category-specific deficits, and (2) is there an interaction between impairment for a type of knowledge (e.g., visual, functional, etc.) and impairment for a given category of objects (e.g., biological, artefacts, etc.). Of the 79 case studies in which the reported data are sufficiently informative with respect to the aims of our study, 61 presented a disproportionate impairment for biological categories and 18 presented a disproportionate impairment for artefacts. Less than half of the reported cases provide statistically and theoretically interpretable data. Each case is commented upon individually. The facts that emerge from our critical review are that (1) the categories of category-specific semantic deficits are animate objects, inanimate biological objects, and artefacts (the domain of biological objects fractionates into two independent semantic categories: animals, and fruit/vegetables); (2) the types of category-specific deficits are not associated with specific types of conceptual knowledge deficits. Other conclusions that emerge from our review are that the evidence in favour of the existence of cases of reliable category-specific agnosia or anomia is not very strong, and that the visual structural description system functions relatively autonomously from conceptual knowledge about object form.},
}
@article{mesulam_primary_2001,
	abstract = {Primary progressive aphasia ({PPA)} is a focal dementia characterized by an isolated and gradual dissolution of language function. The disease starts with word-finding disturbances (anomia) and frequently proceeds to impair the grammatical structure (syntax) and comprehension (semantics) of language. The speech output in {PPA} can be fluent or nonfluent. Memory, visual processing, and personality remain relatively well-preserved until the advanced stages and help to distiguish {PPA} from frontal lobe dementia and the typical forms of Alzheimer's disease. The term ``semantic dementia'' was originally introduced to designate a different group of patients with a combination of verbal and visual processing deficits. In practice, however, this diagnosis is also being used in a variant sense to denote a subtype of {PPA} with fluent speech and impaired comprehension, even in the absence of visual processing deficits. Insofar as the diagnosis of semantic dementia can have these two different meanings, it is important to specify whether it is being used in the original sense or to denote a subtype of {PPA.} Structural and physiological neuroimaging confirms the selective predilection of {PPA} for the left hemisphere, especially for its language-related cortices. A few patients with {PPA} display the neuropathological markers of Alzheimer's disease, but in an unusual distribution. The majority of the autopsies in {PPA} have shown either Pick's disease or lobar atrophy without distinctive histopathology. The suggestion has been made that {PPA} and frontal lobe dementia constitute phenotypical variations of a unitary disease process within the {``Pick-lobar} atrophy'' spectrum. Recent advances in chromosome 17-linked dementias justify a rigorous search for tau polymorphisms and tauopathy in sporadic {PPA.} An informed approach to this syndrome will increase the effectiveness with which clinicians can address the unique challenges associated with the diagnosis and care of {PPA.} Ann Neurol 2001;49:425--432},
}
@article{noppeney_two_2006-1,
}
@article{tranel_neural_2003,
	abstract = {The neural correlates of conceptual knowledge for actions are not well understood. To begin to address this knowledge gap, we tested the hypothesis that the retrieval of conceptual knowledge for actions depends on neural systems located in higher-order association cortices of left premotor/prefrontal, parietal, and posterior middle temporal regions. The investigation used the lesion method and involved 90 subjects with damage to various regions of the left or right hemisphere. The experimental tasks measured retrieval of knowledge for actions, in a nonverbal format: Subjects evaluated attributes of pictured actions, and compared and matched pictures of actions. In support of our hypothesis, we found that the regions of highest lesion overlap in subjects with impaired retrieval of conceptual knowledge for actions were in the left premotor/prefrontal sector, the left parietal region, and in the white matter underneath the left posterior middle temporal region. These sites are partially distinct from those identified previously as being important for the retrieval of words for actions. We propose that a key function of the sites is to operate as two-way intermediaries between perception and concept retrieval, to promote the retrieval of the multidimensional aspects of knowledge that are necessary and sufficient for the mental representation of a concept of a given action.},
}
@article{schubo_texture_2004,
	abstract = {{'Parallel'} visual search and effortless texture segmentation were believed to rely on similar mechanisms until Wolfe [Vis. Res. 32 (1992) 757] demonstrated that efficient visual search and effortless texture segmentation are not always the same thing. In a recent study, Meinecke and Donk [Perception 31 (2002) 591] varied display size in a pop-out task and found that, albeit stimulus elements and the task remained the same, different set sizes led to different processing modes. These findings indicate that it may suffice to vary set size in an otherwise unchanged pop-out task to initiate different processing which may be similar to the processing in efficient visual search and in effortless texture segmentation. In four experiments, we further investigated this issue by presenting stimulus arrays of different set sizes while recording event-related brain potentials ({ERPs).} We found that when display size was increased, detection performance first decreased slightly before it then increased. {ERP} effects were observed for the posterior N2 (N2p), the N2pc and the P3 component. All three components showed variations with set size; N2p differential amplitude effects were confined to large set sizes, whereas an N2pc was obtained for a broader set size range except for very small set sizes and the largest set size (121 elements). We interpret both the non-monotonic relationship between set size and response data and the variations of {ERP} components with set size as evidence in favor of different processing occurring for stimulus arrays with small and large set sizes.},
}
@article{kriegeskorte_information-based_2006,
	abstract = {The development of high-resolution neuroimaging and multielectrode electrophysiological recording provides neuroscientists with huge amounts of multivariate data. The complexity of the data creates a need for statistical summary, but the local averaging standardly applied to this end may obscure the effects of greatest neuroscientific interest. In neuroimaging, for example, brain mapping analysis has focused on the discovery of activation, i.e., of extended brain regions whose average activity changes across experimental conditions. Here we propose to ask a more general question of the data: Where in the brain does the activity pattern contain information about the experimental condition? To address this question, we propose scanning the imaged volume with a ``searchlight,'' whose contents are analyzed multivariately at each location in the brain.},
}
@article{marks_functional_1995,
	abstract = {The biological function of {REM} sleep is defined in terms of the functions of neural processes that selectively operate during the {REM} sleep state. The high amounts of {REM} sleep expressed by the young during a period of central nervous system plasticity suggest that one function of {REM} sleep is in development. The phenomenon of activity-dependent development has been clearly shown to be one mechanism by which early sensory experience can affect the course of neural development. Activity-dependent development may be a ubiquitous process in brain maturation by which activity in one brain region can influence the developmental course of other regions. We hypothesize an ontogenetic function of {REM} sleep; namely, the widespread control of neuronal activity exerted by specific {REM} sleep processes help to direct brain maturation through activity-dependent developmental mechanisms. Preliminary tests of the hypothesis have been conducted in the developing feline visual system, which has long been known to incorporate information derived from visual experience in establishing neuronal connectivity. We find that suppression of {REM} sleep processes by an instrumental {REM} deprivation procedure results in a significant enhancement of the effects of altered visual experience by monocular occlusion. Bilateral brainstem lesions that selectively block the occurrence of ponto-geniculo-occipital ({PGO)} waves are sufficient to produce similar results. These data indicate that the propagation of phasic influences during {REM} sleep interacts with other processes subserving neural development. This source of influence appears not to derive from the environment but rather stems from an intrinsic source of genetic origin. Examination of the neural activity associated with {PGO} waves in the lateral geniculate nucleus reveals a distribution of facilitatory influence markedly different from that induced by visual experience. We conclude that {REM} sleep directs the course of brain maturation in early life through the control of neural activity.},
}
@article{patterson_deficits_2001,
	abstract = {Two distinct mechanisms are often considered necessary to account for generation of the past-tense of English verbs: a lexical associative process for irregular forms like speak --> spoke, and a rule-governed process ('add -ed') for regular and novel forms like talk --> talked and wug --> wugged. An alternative account based on a parallel-distributed processing approach proposes that one complex procedure processes all past-tense types. In this alternative view, neuropsychological dissociations are explained by reduced input from word meaning that plays a greater role in successful generation of the past-tense for lower frequency irregular verbs, and by phonological deficits that disproportionately affect regular and novel forms. Only limited evidence has been available concerning the relationship between knowledge of word meaning and verb-tense processing. The study reported here evaluated the past-tense verb abilities of 11 patients with semantic dementia, a neurodegenerative condition characterised by degraded semantic knowledge. We predicted and confirmed that the patients would have essentially normal ability to generate and recognise regular (and novel) past-tense forms, but a marked and frequency-modulated deficit on irregular verbs. Across the set of 11 patients, the degree of impairment for the irregular past-tense was significantly correlated with the degree of comprehension impairment as measured by verb synonym judgements. These results, plus other features of the data such as the nature of the errors to irregular verbs, are discussed in relation to currently developing theories of the language system.},
}
@article{jiang_gender-_2006,
	abstract = {Human observers are constantly bombarded with a vast amount of information. Selective attention helps us to quickly process what is important while ignoring the irrelevant. In this study, we demonstrate that information that has not entered observers' consciousness, such as interocularly suppressed (invisible) erotic pictures, can direct the distribution of spatial attention. Furthermore, invisible erotic information can either attract or repel observers' spatial attention depending on their gender and sexual orientation. While unaware of the suppressed pictures, heterosexual males' attention was attracted to invisible female nudes, heterosexual females' attention was attracted to invisible male nudes, gay males behaved similarly to heterosexual females, and gay/bisexual females performed in-between heterosexual males and females.},
}
@phdthesis{stengel_organization_2013,
	abstract = {According to sensory-motor accounts of semantic memory, conceptual knowledge is partly represented in the modality-specific perceptual systems through which the concepts are acquired. Tests of this hypothesis have been hindered by the fact that concept acquisition typically involves a complex mixture of perceptual, motor, and verbal experiences. Further understanding the representation of elegant cortex involved with conceptual knowledge for audition and vision may be a valuable tool for neurosurgeons when faced with determining what pieces of cortex are more essential in processing conceptual knowledge. The goal of the study was to create a task that further examined the neuroanatomical representations of conceptual knowledge for a variety of modalities and determine the extent of shared neural resources between conceptual and perceptual processing. This goal was achieved through two experiments. In the first experiment, participants were trained to associate a set of unknown bird names with either bird pictures (Visual), bird calls (Auditory) or verbal statements (Facts). During {fMRI}, participants performed a similarity rating task in which two bird names from the same modality set were visually presented and participants rated how similar the two birds were on a scale from one (very dissimilar) to four (very similar) based on their training. Bilateral parahippocampal, fusiform and inferior temporal gyri showed greater activity for Visual over other conditions. The left supramarginal and inferior temporal gyri showed greater activity for Auditory over other conditions. Left angular gyrus and bilateral posterior cingulate/precuneus cortex showed greater activation for Facts over other conditions. These results support the hypothesis that concept knowledge is represented within distinct modality-specific perceptual systems. Given the complexity of the brain, it is highly likely that conceptual knowledge is highly distributed in large-scale brain networks. The second experiment used the results from the first experiment as seeds in a resting-state {fMRI} study. Results from this experiment suggest that the modality-specific perceptual systems used for acquiring conceptual knowledge are spontaneously active and form distinct networks even in the absence of externally imposed task conditions. ({PsycINFO} Database Record (c) 2013 {APA}, all rights reserved)},
}
@article{deweer_selective_1976,
	abstract = {Ninety-eight Sprague-Dawley rats, implanted with electrodes in the mesencephalic tegmentum (reticular activating system, {RAS)} served as subjects in two experiments. In the first experiment (n = 42) we investigated the effects of a {RAS} stimulation (5 $mu$ A, 300 Hz, 90 sec in duration) on the acquisition of a positively reinforced light--dark discrimination in a T-maze. In the second experiment (n = 56) the reinforcement and the treatment were dissociated by comparing the effects of the {RAS} stimulation administered after correct or incorrect choices, during the same discrimination task.
}
@article{kriegeskorte_circular_2009,
	abstract = {A neuroscientific experiment typically generates a large amount of data, of which only a small fraction is analyzed in detail and presented in a publication. However, selection among noisy measurements can render circular an otherwise appropriate analysis and invalidate results. Here we argue that systems neuroscience needs to adjust some widespread practices to avoid the circularity that can arise from selection. In particular, 'double dipping', the use of the same dataset for selection and selective analysis, will give distorted descriptive statistics and invalid statistical inference whenever the results statistics are not inherently independent of the selection criteria under the null hypothesis. To demonstrate the problem, we apply widely used analyses to noise data known to not contain the experimental effects in question. Spurious effects can appear in the context of both univariate activation analysis and multivariate pattern-information analysis. We suggest a policy for avoiding circularity.},
}
@article{gilbert_whorf_2006,
	abstract = {The question of whether language affects perception has been debated largely on the basis of cross-language data, without considering the functional organization of the brain. The nature of this neural organization predicts that, if language affects perception, it should do so more in the right visual field than in the left visual field, an idea unexamined in the debate. Here, we find support for this proposal in lateralized color discrimination tasks. Reaction times to targets in the right visual field were faster when the target and distractor colors had different names; in contrast, reaction times to targets in the left visual field were not affected by the names of the target and distractor colors. Moreover, this pattern was disrupted when participants performed a secondary task that engaged verbal working memory but not a task making comparable demands on spatial working memory. It appears that people view the right (but not the left) half of their visual world through the lens of their native language, providing an unexpected resolution to the language-and-thought debate.},
}
@article{roberson_categorical_2008,
	abstract = {In this study we demonstrate that Korean (but not English) speakers show Categorical perception ({CP)} on a visual search task for a boundary between two Korean colour categories that is not marked in English. These effects were observed regardless of whether target items were presented to the left or right visual field. Because this boundary is unique to Korean, these results are not consistent with a suggestion made by Drivonikou [Drivonikou, G. V., Kay, P., Regier, T., Ivry, R. B., Gilbert, A. L., Franklin, A. et al. (2007) Further evidence that Whorfian effects are stronger in the right visual field than in the left. Proceedings of the National Academy of Sciences 104, 1097--1102] that {CP} effects in the left visual field provide evidence for the existence of a set of universal colour categories. Dividing Korean participants into fast and slow responders demonstrated that fast responders show {CP} only in the right visual field while slow responders show {CP} in both visual fields. We argue that this finding is consistent with the view that {CP} in both visual fields is verbally mediated by the left hemisphere language system.},
}
@article{giovannetti_naturalistic_2002,
	abstract = {Naturalistic actions are everyday tasks (e.g. cooking) that require one to use multiple objects and sequence steps to achieve a goal. Naturalistic action impairment has been attributed to executive dysfunction [Higher cortical functions in man. New York: Basic Books, 1966], semantic knowledge degradation [Brain 111 (1988) 1173], and, more recently, general limitations in cognitive resources [Neuropsychology 12 (1998) 13]. Action impairments were explored in 51 dementia participants with the short form of the multi-level action test ({MLAT-S).} A clinical neuropsychological test protocol was also administered. Regression analyses including measures of executive functioning, semantic knowledge, and global cognitive functioning showed that global cognitive functioning was the best predictor of {MLAT-S} errors. Furthermore, task demands significantly influenced the type and frequency of errors, and dementia participants showed a pattern of errors similar to that reported in other clinical populations [Cognitive Neuropsychology 15 (1998) 617; Neuropsychologia 37 (1999) 51; Neuropsychology 12 (1998) 13]. Taken together, the present findings are inconsistent with semantic and executive accounts, but support the limited-capacity resource theory of naturalistic action impairment.},
}
@article{costello_semantic_2009,
	abstract = {In general, stimuli that are familiar and recognizable have an advantage of predominance during binocular rivalry. Recent research has demonstrated that familiar and recognizable stimuli such as upright faces and words in a native language could break interocular suppression faster than their matched controls. In this study, a visible word prime was presented binocularly then replaced by a high-contrast dynamic noise pattern presented to one eye and either a semantically related or unrelated word was introduced to the other eye. We measured how long it took for target words to break from suppression. To investigate word-parts priming, a second experiment also included word pairs that had overlapping subword fragments. Results from both experiments consistently show that semantically related words and words that shared subword fragments were faster to gain dominance compared to unrelated words, suggesting that words, even when interocularly suppressed and invisible, can benefit from semantic and subword priming.},
}
@article{mazza_multiple_2012,
	abstract = {Exact computation of numerosity requires the selective individuation of the elements to be enumerated so that each element is counted once and only once. Such a mechanism should operate not only when the elements to be enumerated are presented in isolation but also when they are presented in cluttered scenes. To uncover the electrophysiological correlates of the level of object representation necessary for exact enumeration, we examined {ERP} measures during the execution of a target enumeration task. A variable number (1--4) of lateralized targets were presented with or without distracters on the target side. An early nonlateralized response (N1, 120--180 msec) was modulated by target numerosity only when presented without distracters. By contrast, the amplitudes of a lateralized and later response (N2pc, 180--300 msec) increased as a function of target numerosity both with and without distracters, reaching a plateau at three targets. We propose that the stage of processing reflected in the N2pc corresponds to the component of individuation that binds specific indexes to properties and locations and that this provides the representation type necessary for exact enumeration.},
}
@article{tranel_effects_2005,
}
@article{glenberg_grounding_2002,
	abstract = {We report a new phenomenon associated with language comprehension: theaction---sentence compatibility effect ({ACE).} Participants judged whether sentences were sensible by making a response that required moving toward or away from their bodies. When a sentence implied action in one direction (e.g., {``Close} the drawer'' implies action away from the body), the participants had difficulty making a sensibility judgment requiring a response in the opposite direction. The {ACE} was demonstrated for three sentences types: imperative sentences, sentences describing the transfer of concrete objects, and sentences describing the transfer of abstract entities, such as {``Liz} told you the story.'' These data are inconsistent with theories of language comprehension in which meaning is represented as a set of relations among nodes. Instead, the data support an embodied theory of meaning that relates the meaning of sentences to human action.},
}
@article{makar_formate_1975,
}
@incollection{ghosh_adaptive_2012,
}
@article{smith_metal_1975,
}
@article{meyer_predicting_2010,
	abstract = {Using multivariate pattern analysis of functional magnetic resonance imaging data, we found that the subjective experience of sound, in the absence of auditory stimulation, was associated with content-specific activity in early auditory cortices in humans. As subjects viewed sound-implying, but silent, visual stimuli, activity in auditory cortex differentiated among sounds related to various animals, musical instruments and objects. These results support the idea that early sensory cortex activity reflects perceptual experience, rather than sensory stimulation alone.},
}
@article{alexander_brocas_1990,
	abstract = {We report 9 cases of aphasia following lesions in the region of the left frontal operculum. It is not possible to capture their variety of clinical manifestations with the simple labels of {``Broca's} aphasia'' or {``Broca's} area aphasia.'' Analysis of the breakdown of various components of speech and language in these cases suggests that the operculum, lower motor cortex, and subjacent subcortical and periventricular white matter contain critical parts of different language systems. These systems can be independently impaired. There are several common language syndromes that follow damage that includes the left frontal operculum. These syndromes reflect the effects of the direction and extent of the lesion in the various language systems.},
}
@article{beretta_effects_2005,
}
@article{ochipa_ideational_1989,
	abstract = {We report a 67-year-old left-handed man who exhibited an ideational apraxia in both clinical and nonclinical natural settings following a right hemisphere infarction. His inability to use tools could not be explained by a motor production deficit (ideomotor apraxia), because he made content errors and could not match tools with objects. His deficit could not be attributed to an agnosia or language comprehension deficit, because he could name tools and point to tools on command. Based on our testing, it appeared that this patient had a loss of knowledge related to tool use.},
}
@article{moss_anteromedial_2005,
}
@article{ghahramanlou-holloway_differentiating_2007,
	abstract = {Quantitative research suggests that depressed and anxious patients can be differentiated based on their cognitive content. This study used qualitative research methods to separate the specific components of open-ended depressive and anxious thought content in 79 psychiatric outpatients. Patients with major depressive disorder ({MDD;} n = 36), generalized anxiety disorder ({GAD;} n = 10), and other psychiatric disorders ({PC;} n = 33) were instructed to (a) describe their most bothersome problem; (b) imagine the worst possible negative outcome followed by the best possible positive outcome; and (c) describe associated thoughts and emotions for each scenario. The content of patients' responses were coded to examine (a) the types and severity of problems; (b) the presence or absence of hopelessness, catastrophizing, hopefulness, and unrealistic positive expectations; and (c) the presence or absence of particular emotions associated with imagined worst and best outcomes. More {GAD} patients than {MDD} and {PC} patients indicated anticipated anxious emotions associated with imagined worst outcomes, and fewer {MDD} patients than {GAD} and {PC} patients indicated anticipated happiness associated with imagined best outcomes. No group differences emerged for the other variables considered. These findings suggest that depressed and anxious patients differ in their cognitive expectancies about future life events in terms of their own anticipated emotional reactions.},
}
@article{li_sparse_2012,
	abstract = {Considering the two-class classification problem in brain imaging data analysis, we propose a sparse representation-based multi-variate pattern analysis ({MVPA)} algorithm to localize brain activation patterns corresponding to different stimulus classes/brain states respectively. Feature selection can be modeled as a sparse representation (or sparse regression) problem. Such technique has been successfully applied to voxel selection in {fMRI} data analysis. However, single selection based on sparse representation or other methods is prone to obtain a subset of the most informative features rather than all. Herein, our proposed algorithm recursively eliminates informative features selected by a sparse regression method until the decoding accuracy based on the remaining features drops to a threshold close to chance level. In this way, the resultant feature set including all the identified features is expected to involve all the informative features for discrimination. According to the signs of the sparse regression weights, these selected features are separated into two sets corresponding to two stimulus classes/brain states. Next, in order to remove irrelevant/noisy features in the two selected feature sets, we perform a nonparametric permutation test at the individual subject level or the group level. In data analysis, we verified our algorithm with a toy data set and an intrinsic signal optical imaging data set. The results show that our algorithm has accurately localized two class-related patterns. As an application example, we used our algorithm on a functional magnetic resonance imaging ({fMRI)} data set. Two sets of informative voxels, corresponding to two semantic categories (i.e., ``old people'' and ``young people''), respectively, are obtained in the human brain.},
}
@article{tibshirani_regression_1994,
	abstract = {We propose a new method for estimation in linear models. The "lasso" minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly zero and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable...},
}
@article{adolphs_role_2000,
	abstract = {Although lesion and functional imaging studies have broadly implicated the right hemisphere in the recognition of emotion, neither the underlying processes nor the precise anatomical correlates are well understood. We addressed these two issues in a quantitative study of 108 subjects with focal brain lesions, using three different tasks that assessed the recognition and naming of six basic emotions from facial expressions. Lesions were analyzed as a function of task performance by coregistration in a common brain space, and statistical analyses of their joint volumetric density revealed specific regions in which damage was significantly associated with impairment. We show that recognizing emotions from visually presented facial expressions requires right somatosensory-related cortices. The findings are consistent with the idea that we recognize another individual's emotional state by internally generating somatosensory representations that simulate how the other individual would feel when displaying a certain facial expression. Follow-up experiments revealed that conceptual knowledge and knowledge of the name of the emotion draw on neuroanatomically separable systems. Right somatosensory-related cortices thus constitute an additional critical component that functions together with structures such as the amygdala and right visual cortices in retrieving socially relevant information from faces.},
}
@article{morita_neural_2004,
	abstract = {It is well established that seeing color activates the ventral occipital cortex, including the fusiform and lingual gyri, but less is known about whether the region directly relates to conscious color perception. We investigated the neural correlates of conscious color perception in the ventral occipital cortex. To vary conscious color perception with the stimuli-remaining constant, we took advantage of the {McCollough} effect, an illusory color effect that is contingent on the orientation of grating stimuli. Subjects were exposed to a specific combination of chromatic grating patterns for 10 min to induce the {McCollough} effect. We compared brain activities measured while the subjects viewed achromatic grating stimuli before ({PRE)} and after the induction of the {McCollough} effect ({POST)} using functional magnetic resonance imaging ({fMRI).} There were two groups: one group was informed that they would perceive illusory color during the session ({INFORMED} group), whereas the other group was not informed ({UNINFORMED} group). The successful induction of the {McCollough} effect was confirmed in all subjects after the {fMRI} experiment; nevertheless, only approximately half of the {UNINFORMED} subjects had been aware of the color during the {POST} session, while the other half had not. The left anterior portion of the color-selective area in the ventral occipital cortex, presumably V4alpha, was significantly active in subjects who had consciously perceived the color during {MR} scan. This study demonstrates the activity in a subregion of the color-selective area in the ventral occipital cortex directly related to conscious color perception.},
}
@article{basmadjian_hemodynamic_1986,
	abstract = {A previous analysis (Basmadjian, J. Biomechanics 17, 287-298, 1984) of the embolizing forces acting on thrombi in steady Poiseuille flow has been extended to pulsatile blood flow conditions in the major blood vessels. We show that for incipient and small compact thrombi up to 0.1 mm height, the maximum embolizing stresses can be calculated from the corresponding 'quasi-steady' viscous drag forces and measured maximum wall shear. Their magnitude is from 5 to 30 times (tau {w)Max}, the maximum wall shear stress during the cardiac cycle in the absence of thrombi. For larger thrombi, inertial and 'history' effects have to be taken into account, leading to embolizing stresses in excess of 100 Pa (1000 dyn cm-2).},
}
@article{boronat_distinctions_2005,
	abstract = {A prominent account of conceptual knowledge proposes that information is distributed over visual, tactile, auditory, motor and verbal-declarative attribute domains to the degree to which these features were activated when the knowledge was acquired [{D.A.} Allport, Distributed memory, modular subsystems and dysphagia, In: {S.K.} Newman, R. Epstein (Eds.), Current perspectives in dysphagia, Churchill Livingstone, Edinburgh, 1985, pp. 32--60]. A corollary is that when drawing upon this knowledge (e.g., to answer questions), particular aspects of this distributed information is re-activated as a function of the requirements of the task at hand [{L.J.} Buxbaum, {E.M.} Saffran, Knowledge of object manipulation and object function: dissociations in apraxic and non-apraxic subjects. Brain and Language, 82 (2002) 179--199; {L.J.} Buxbaum, T. Veramonti, {M.F.} Schwartz, Function and manipulation tool knowledge in apraxia: knowing 'what for' but not 'how', Neurocase, 6 (2000) 83--97; W. Simmons, L. Barsalou, The similarity-in-topography principle: Reconciling theories of conceptual deficits, Cognitive Neuropsychology, 20 (2003) 451--486]. This account predicts that answering questions about object manipulation should activate brain regions previously identified as components of the distributed sensory-motor system involved in object use, whereas answering questions about object function (that is, the purpose that it serves) should activate regions identified as components of the systems supporting verbal-declarative features. These predictions were tested in a functional magnetic resonance imaging ({fMRI)} study in which 15 participants viewed picture or word pairs denoting manipulable objects and determined whether the objects are manipulated similarly (M condition) or serve the same function (F condition). Significantly greater and more extensive activations in the left inferior parietal lobe bordering the intraparietal sulcus were seen in the M condition with pictures and, to a lesser degree, words. These findings are consistent with the known role of this region in skilled object use [{K.M.} Heilman, {L.J.} Gonzalez Rothi, Apraxia, In: {K.M.} Heilman, E. Valenstein (Eds.), Clinical Neuropsychology, Oxford University Press, New York, 1993, pp. 141--150] as well as previous {fMRI} results [M. Kellenbach, M. Brett, K. Patterson, Actions speak louder than functions: the importance of manipulability and action in tool representation, Journal of Cognitive Neuroscience, 15 (2003) 30--46] and behavioral findings in brain-lesion patients [{L.J.} Buxbaum, {E.M.} Saffran, Knowledge of object manipulation and object function: dissociations in apraxic and non-apraxic subjects, Brain and Language, 82 (2002) 179--199]. No brain regions were significantly more activated in the F than M condition. These data suggest that brain regions specialized for sensory-motor function are a critical component of distributed representations of manipulable objects.},
}
@article{mesulam_core_2003,
}
@article{wang_remodelling_1995,
	abstract = {The primate somatosensory cortex, which processes tactile stimuli, contains a topographic representation of the signals it receives, but the way in which such maps are maintained is poorly understood. Previous studies of cortical plasticity indicated that changes in cortical representation during learning arise largely as a result of hebbian synaptic change mechanisms. Here we show, using owl monkeys trained to respond to specific stimulus sequence events, that serial application of stimuli to the fingers results in changes to the neuronal response specificity and maps of the hand surfaces in the true primary somatosensory cortical field (S1 area 3b). In this representational remodelling stimuli applied asychronously to the fingers resulted in these fingers being integrated in their representation, whereas fingers to which stimuli were applied asynchronously were segregated in their representation. Ventroposterior thalamus response maps derived in these monkeys were not equivalently reorganized. This representational plasticity appears to be cortical in origin.},
}
@article{seger_category_2010,
	abstract = {The ability to group items and events into functional categories is a fundamental characteristic of sophisticated thought. It is subserved by plasticity in many neural systems, including neocortical regions (sensory, prefrontal, parietal, and motor cortex), the medial temporal lobe, the basal ganglia, and midbrain dopaminergic systems. These systems interact during category learning. Corticostriatal loops may mediate recursive, bootstrapping interactions between fast reward-gated plasticity in the basal ganglia and slow reward-shaded plasticity in the cortex. This can provide a balance between acquisition of details of experiences and generalization across them. Interactions between the corticostriatal loops can integrate perceptual, response, and feedback-related aspects of the task and mediate the shift from novice to skilled performance. The basal ganglia and medial temporal lobe interact competitively or cooperatively, depending on the demands of the learning task.},
}
@article{verheyen_determining_2007,
	abstract = {When multidimensional scaling solutions are used to study semantic concepts, the dimensionality of the optimal configuration has to be determined. Several strategies have been proposed to choose the appropriate dimensionality. In the present paper, the traditional dimensionality choice criteria were evaluated and compared to a method based on the prediction of an external criterion. Two studies were conducted in which typicality of an exemplar within a semantic concept was predicted from its distance to the concept centroid. In contrast to the low-dimensional solutions selected by the traditional methods, predictions of an external criterion improved with additional dimensions up till dimensionalities that were much higher than what is common in the literature. This suggests that traditional methods underestimate the richness of semantic concepts as revealed in spatial representations derived from similarity measures.},
}
@article{cowell_virtual_2009,
	abstract = {Is the fusiform face area ({FFA)} a module specialized for processing faces, or does it simply support generic visual expertise? Researchers have investigated this question using Multi-Voxel Pattern Analysis ({MVPA)} applied to {fMRI} results. Haxby et al. (2001) showed that patterns of neural activation in object-selective visual cortex can be used to discriminate object categories, even when voxels selective for those categories are removed. This provided evidence for a distributed neural code, in which information about faces exists outside the {FFA.} In contrast, Spiridon and Kanwisher (2002) showed that activation patterns in face-selective cortex were more effective for making face vs. non-face discriminations than for non-face vs. non-face discriminations, whereas this was not true for other object categories. This implied {FFA} neurons contain special information about faces, but that there is no specialized module for other categories.
}
@article{landis_emotional_2006,
	abstract = {Aphasic patients, in particular global aphasics, may still swear and produce emotional utterances with ease. Based on these clinical observations we investigated emotional word ``reading'' in a series of different experiments over 25 years, not only in aphasic patients, but also in the left ({LVF)} and right ({RVF)} visual fields of healthy subjects, and in a depth-recorded epileptic patient. Across these experiments we found: i) behaviorally a strong emotional word effect in the left visual field (right hemisphere --- {RH)} of normals, correlating well with the emotional word performance of aphasic patients, pointing to a specific role of the right hemisphere; ii) electro-physiologically a specific early (100-140 msec) brain response to emotional words during scalp recordings in healthy subjects subsequent to right visual field (left hemisphere --- {LH)} stimulation, that source localization procedures project to posterior areas of the right hemisphere; iii) preliminary data of a very early (60 msec) activation of the left amygdala in a depth-recorded epileptic patient when the same emotional words were presented to the right visual field (left hemisphere); and iv) a consistent gender difference showing that the above findings might be relevant for men only. Both hemispheres therefore appear to be implicated in emotional word ``reading'' but in different ways. We propose that the left amygdala via extrastriate connections acts as a detector of emotional word content at a very early stage of processing; that this amygdala response subsequently modulates the cortical response to emotional words asymmetrically, rendering the left visual cortex less sensitive to emotional words than that of the right hemisphere; and that this modulation is gender dependent.},
}
@article{davidoff_color_2006,
	abstract = {In their lead articles, both Kowalski and Zimiles (2006) and {O'Hanlon} and Roberson (2006) declare a general relation between color term knowledge and the ability to conceptually represent color. Kowalski and Zimiles, in particular, argue for a priority for the conceptual representation in color term acquisition. The complexities of the interaction are taken up in the current commentary, especially with regard to the neuropsychological evidence. Data from aphasic patients also argue for a priority for abstract thought, but nevertheless it may still be that the use of color terms is the only way in which to form color categories even if both linguistic and attentional factors play an important role.},
}
@article{bai_effectiveness_2007,
	abstract = {The thresholded t-map produced by the General Linear Model ({GLM)} gives an effective summary of activation patterns in functional brain images and is widely used for feature selection in {fMRI} related classification tasks. As part of a project to build content-based retrieval systems for {fMRI} images, we have investigated ways to make {GLM} more adaptive and more robust in dealing with {fMRI} data from widely differing experiments. In this paper we report on exploration of the Finite Impulse Response model, combined with multiple linear regression, to identify the "locally best Hemodynamic Response Function ({HRF)} for each voxel" and to simultaneously estimate activation levels corresponding to several stimulus conditions. The goal is to develop a procedure for processing datasets of varying natures. Our experiments show that Finite Impulse Response ({FIR)} models with a smoothing factor produce better retrieval performance than does the canonical double gamma {HRF} in terms of retrieval accuracy.},
}
@article{schyns_development_1998,
}
@article{vertes_case_2000,
}
@article{mion_what_2010,
}
@article{downing_cortical_2001,
	abstract = {Despite extensive evidence for regions of human visual cortex that respond selectively to faces, few studies have considered the cortical representation of the appearance of the rest of the human body. We present a series of functional magnetic resonance imaging ({fMRI)} studies revealing substantial evidence for a distinct cortical region in humans that responds selectively to images of the human body, as compared with a wide range of control stimuli. This region was found in the lateral occipitotemporal cortex in all subjects tested and apparently reflects a specialized neural system for the visual perception of the human body.},
}
@article{goldberg_dysfunctional_2008,
	abstract = {Dysfunctional thought patterns are presumed to underlie cognitive biases in mood disorder patients. However, few studies have compared dysfunctional thought patterns in bipolar manic and unipolar depressed patients. Cognitive schemas and dysfunctional attitudes were evaluated using the cognitive checklist for mania and Dysfunctional Attitudes Scale ({DAS)} in 34 bipolar manic, 35 unipolar depressed, and 29 nonpsychiatric control subjects. Unipolar depressed subjects had significantly higher total {DAS} scores and subfactor scores as compared with nonpsychiatric controls, whereas bipolar patients had intermediate scores between both groups. Significant correlations emerged between cognitive checklist for mania total and subcomponent scores and the {DAS} (total, performance subfactor, and approval subfactor scales) for the bipolar, but not the unipolar or nonpsychiatric control groups. Core beliefs among bipolar patients appear negativistic during manic phases, potentially reflecting an overcompensation for depression. The findings support clinical approaches targeting depressive cognitions regardless of the presence of manic symptoms.},
}
@article{buzsaki_hippocampo-neocortical_1996,
	abstract = {In gross anatomical terms, the hippocampal archicortex can be conceived as an ``appendage'' of the large neocortex. In contrast to neocortical areas, the main output targets of the hippocampus are the same as its main inputs (i.e., the entorhinal cortex). Highly processed information about the external world (the content) reaches the hippocampus via the entorhinal cortex, whereas information about the ``internal world'' (the context) is conveyed by the subcortical inputs. Removal of the context makes the content illegible, as demonstrated by the observation that the behavioral impairment following surgical removal of hippocampopetal subcortical inputs is as devastating as removing the hippocampus itself. From its strategic anatomical position and input-output connections, it may be suggested that the main function of the hippocampal formation is to modify its inputs by feeding back a processed ``reafferent copy'' to the neocortex. I hypothesize that neocortico-hippocampal transfer of information and the modification process in neocortical circuitries by the hippocampal output take place in a temporally discontinuous manner and might be delayed by minutes, hours, or days. Acquisition of information may happen very fast during the activated state of the hippocampus associated with theta/gamma oscillations. Intrahippocampal consolidation and the hippocampal-neocortical transfer of the stored representations, on the other hand, is protracted and carried by discrete quanta of cooperative neuronal bursts during slow wave sleep.},
}
@article{kang_semantic_2011,
	abstract = {It has been intensely debated whether visual stimuli are processed to the point of semantic analysis in the absence of awareness. In the present study, we used two related interocular suppression paradigms to measure the extent to which the meaning of a stimulus was registered across multiple levels of visibility. To infer whether a stimulus was semantically analyzed we measured the N400 component of observers' event-related potentials ({ERPs)}, a highly sensitive index of the semantic mismatch between a stimulus and the context in which it is presented. Observers judged the semantic relatedness of a prime and target word while {ERPs} were recorded under continuous flash suppression (Experiment 1) and binocular rivalry (Experiment 2). Also, we parametrically manipulated the visibility of the target word by increasing the contrast between the target word and the suppressive stimulus presented to the other eye (Experiment 3). We found that the amplitude of the N400 was attenuated with increasing suppression depth and absent whenever the observers could not discriminate the meaning of the words. We interpret these findings in the context of single-process models of consciousness which can account for a large body of empirical evidence obtained from visual masking, attention and, now, interocular suppression paradigms.},
}
@article{mitchell_predicting_2008,
}
@article{shepard_perceptual-cognitive_2001,
}
@article{koch_test_2011,
	abstract = {How will we know when we've built a sentient computer? By making it solve a simple puzzle},
}
@article{davis_self-schema_1979,
}
@article{price_anatomy_2010,
	abstract = {In this review of 100 {fMRI} studies of speech comprehension and production, published in 2009, activation is reported for: prelexical speech perception in bilateral superior temporal gyri; meaningful speech in middle and inferior temporal cortex; semantic retrieval in the left angular gyrus and pars orbitalis; and sentence comprehension in bilateral superior temporal sulci. For incomprehensible sentences, activation increases in four inferior frontal regions, posterior planum temporale, and ventral supramarginal gyrus. These effects are associated with the use of prior knowledge of semantic associations, word sequences, and articulation that predict the content of the sentence. Speech production activates the same set of regions as speech comprehension but in addition, activation is reported for: word retrieval in left middle frontal cortex; articulatory planning in the left anterior insula; the initiation and execution of speech in left putamen, pre-{SMA}, {SMA}, and motor cortex; and for suppressing unintended responses in the anterior cingulate and bilateral head of caudate nuclei. Anatomical and functional connectivity studies are now required to identify the processing pathways that integrate these areas to support language.},
}
@article{martin_weak_2003,
	abstract = {Deficits in pragmatic language ability are common to a number of clinical populations, for example, right-hemisphere damage ({RHD)}, Autism and traumatic brain injury ({TBI).} In these individuals the basic structural components of language may be intact, but the ability to use language to engage socially is impaired. Despite the nature of these difficulties being well documented, exactly what causes these difficulties is less clear. Furthermore, the current status of causal explanations for pragmatic difficulties across these populations is divergent and sometimes contradictory. This paper explores the empirical validity of three theories that attempt to explain pragmatic language impairment. It is recommended that a new, more convergent approach to investigating the causes of pragmatic language disability be adopted.},
}
@article{ahissar_reverse_2004,
}
@article{funnell_categories_1992,
	abstract = {Abstract This paper reports an investigation into an apparent category-specific disorder in a young woman whose semantic memory was impaired following a road accident. In Experiment 1, an impairment for processing specific items in tasks of naming pictures and defining words was related to a selective impairment for living things and also to the familiarity level of the items. In Experiment 2, a difference in semantic category (living or nonliving) was pitted against a difference in familiarity (high or low) in a picture-naming task. A significant effect of familiarity was found, but no effect of semantic category. It was shown that, in a widely used set of published pictures, living things were generally of lower familiarity than nonliving things. Moreover, measures of familiarity were shown to be confounded with some reported evidence in support of a selective impairment to living things. It was concluded that, at present, there is no convincing evidence to support the theory that semantic memory is organised into dissociable categories of living and nonliving things.},
}
@article{chen_linear_2013,
	abstract = {Conventional group analysis is usually performed with Student-type t-test, regression, or standard {AN(C)OVA} in which the variance--covariance matrix is presumed to have a simple structure. Some correction approaches are adopted when assumptions about the covariance structure is violated. However, as experiments are designed with different degrees of sophistication, these traditional methods can become cumbersome, or even be unable to handle the situation at hand. For example, most current {FMRI} software packages have difficulty analyzing the following scenarios at group level: (1) taking within-subject variability into account when there are effect estimates from multiple runs or sessions; (2) continuous explanatory variables (covariates) modeling in the presence of a within-subject (repeated measures) factor, multiple subject-grouping (between-subjects) factors, or the mixture of both; (3) subject-specific adjustments in covariate modeling; (4) group analysis with estimation of hemodynamic response ({HDR)} function by multiple basis functions; (5) various cases of missing data in longitudinal studies; and (6) group studies involving family members or twins.
}
@article{mcintosh_toward_2013,
	abstract = {Comments on an article by Jorge Renner Cardoso de Almeida and Mary Louise Phillips (see record 2012-18692-001). Almeida and Phillips review the neuroimaging evidence distinguishing unipolar from bipolar depression and make several insightful suggestions for how research in this area could be improved. These recommendations focus on conducting larger studies and investigating high-risk samples before and after illness and treatment onset. Almeida and Phillips advocate adopting dimensional approaches to the disease phenotype. A point that clearly emerges from their paper is the fact that subclinical manic symptoms are common in major depression, and depressed mood is almost universally found across a wide spectrum of psychiatric disorders. Traits such as neuroticism, extraversion and cyclothymic temperament are closely linked with both depressive symptoms and mood disorder. Testing their relationship with brain imaging parameters may be statistically powerful and provide novel insights into the pathophysiology of mood disorder. Imaging is a useful aid for improving our biologic understanding of depression and other mood disorders. To move psychiatric neuroimaging research to a stage at which it can meaningfully inform routine clinical practice will require substantial investment at a time when resources are scarce. ({PsycINFO} Database Record (c) 2013 {APA}, all rights reserved)},
}
@article{coltheart_computational_2010,
	abstract = {Woollams, Lambon Ralph, Plaut, and Patterson (see record 
}
@article{rissman_distributed_2012,
	abstract = {Forging new memories for facts and events, holding critical details in mind on a moment-to-moment basis, and retrieving knowledge in the service of current goals all depend on a complex interplay between neural ensembles throughout the brain. Over the past decade, researchers have increasingly utilized powerful analytical tools (e.g., multivoxel pattern analysis) to decode the information represented within distributed functional magnetic resonance imaging activity patterns. In this review, we discuss how these methods can sensitively index neural representations of perceptual and semantic content and how leverage on the engagement of distributed representations provides unique insights into distinct aspects of memory-guided behavior. We emphasize that, in addition to characterizing the contents of memories, analyses of distributed patterns shed light on the processes that influence how information is encoded, maintained, or retrieved, and thus inform memory theory. We conclude by highlighting open questions about memory that can be addressed through distributed pattern analyses.},
}
@article{lee_categorical_2012,
	abstract = {Although much effort has been directed toward understanding the neural basis of speech processing, the neural processes involved in the categorical perception of speech have been relatively less studied, and many questions remain open. In this functional magnetic resonance imaging ({fMRI)} study, we probed the cortical regions mediating categorical speech perception using an advanced brain-mapping technique, whole-brain multivariate pattern-based analysis ({MVPA).} Normal healthy human subjects (native English speakers) were scanned while they listened to 10 consonant--vowel syllables along the /ba/--/da/ continuum. Outside of the scanner, individuals' own category boundaries were measured to divide the {fMRI} data into /ba/ and /da/ conditions per subject. The whole-brain {MVPA} revealed that Broca's area and the left pre-supplementary motor area evoked distinct neural activity patterns between the two perceptual categories (/ba/ vs /da/). Broca's area was also found when the same analysis was applied to another dataset (Raizada and Poldrack, 2007), which previously yielded the supramarginal gyrus using a univariate {adaptation--fMRI} paradigm. The consistent {MVPA} findings from two independent datasets strongly indicate that Broca's area participates in categorical speech perception, with a possible role of translating speech signals into articulatory codes. The difference in results between univariate and multivariate pattern-based analyses of the same data suggest that processes in different cortical areas along the dorsal speech perception stream are distributed on different spatial scales.},
}
@article{glenberg_embodied_2003,
}
@article{nerlich_ambiguities_2001,
	abstract = {Contrary to traditional research into polysemy and ambiguity, we argue that polysemy is neither just a phenomenon of the dictionary, nor a purely cognitive phenomenon, but that its exploitation in everyday discourse has important communicational and pragmatic functions. Contrary to current work in psycholinguistics, we argue that ambiguity should not only be studied in vitro, as in priming studies and similar approaches using decontextualized samples, but that it should be analysed in vivo. Contrary to some older theories of implicature and some newer theories of relevance, we argue that people who engage in conversation do not always strive for rationality and relevance, that they do not always intend words to have one meaning and 'disambiguate' polysemous words automatically in context. The use and understanding of polysemous words may have costs in terms of processing time, but what Kittay (1987) calls 'purposive ambiguity' has important semantic, pragmatic and conversational benefits, such as reinforcing the semantic links between the nodes in a network of senses, strengthening the social bonds between those who exploit polysemy in conversation, and helping to negotiate crucial junctures between conversational turns.},
}
@article{cappa_effects_1998,
	abstract = {Neuropsychological studies of patients with category-specific recognition disorders, as well as {PET} investigations of semantic category effects in visual recognition tasks, have led some authors to the hypothesis that visual-perceptual knowledge plays a crucial role in the recognition of natural items, such as animals, while functional-associative information is more important for the recognition of man-made tools. To study the cerebral correlates of the retrieval of different types of semantic knowledge about living and nonliving entities, we performed a {PET} experiment in which normal subjects were required to access visual- and functional-associative information related to visually presented words corresponding to animals and tools. The experimental conditions were the following: (1) Rest. (2) Baseline: letter detection in pseudo-words. (3) Animal, visual knowledge: decide whether the animal has a long or short tail with respect to the body. (4) Animal, associative knowledge: decide whether the animal is typically found in Italy. (5) Tool, visual knowledge: decide whether the object is longer than wider or vice versa. (6) Tool, functional knowledge: decide whether the object is typically used as a kitchen tool. Lexical-semantic access (all lexical conditions pooled) activated the prefrontal cortex on the left and the parietal--occipital junction and posterior cingulate cortex bilaterally. An analysis of the individual experimental conditions in comparison with the nonword baseline showed that accessing visual versus associative knowledge was associated with different activation patterns: predominantly frontal in the case of visual features, temporoparietal for associative knowledge. While the activation patterns involved similar areas for living and nonliving entities, in the case of the latter they were restricted to the left hemisphere. The analysis of main effects confirmed these findings: there were several significant differences in the visual-associative comparison, while category-related differences were less prominent. These findings indicate that the retrieval of different types of knowledge is associated with distinct patterns of brain activation; on the other hand, category-related differences were less evident than in picture matching and naming tasks.},
}
@article{bressler_large-scale_1995,
	abstract = {The well-known parcellation of the mammalian cerebral cortex into a large number of functionally distinct cytoarchitectonic areas presents a problem for understanding the complex cortical integrative functions that underlie cognition. How do cortical areas having unique individual functional properties cooperate to accomplish these complex operations? Do neurons distributed throughout the cerebral cortex act together in large-scale functional assemblages? This review examines the substantial body of evidence supporting the view that complex integrative functions are carried out by large-scale networks of cortical areas. Pathway tracing studies in non-human primates have revealed widely distributed networks of interconnected cortical areas, providing an anatomical substrate for large-scale parallel processing of information in the cerebral cortex. Functional coactivation of multiple cortical areas has been demonstrated by neurophysiological studies in non-human primates and several different cognitive functions have been shown to depend on multiple distributed areas by human neuropsychological studies. Electriphysiological studies on interareal synchronization have provided evidence that active neurons in different cortical areas may become not only coactive, but also functionally interdependent. The computational advantages of synchronization between cortical areas in large-scale networks have been elucidated by studies using artificial neural network models. Recent observations of time-varying multi-areal cortical synchronization suggest that the functional topology of a large-scale cortical network is dynamically reorganized during visuomotor behavior.},
}
@article{smith_sleep_1995,
	abstract = {Evidence for the involvement of rapid eye movement ({REM)} sleep or paradoxical sleep ({PS)} with memory processing continues to accumulate. In animals, there is continuing evidence of relatively small, vulnerable paradoxical sleep windows ({PSWs)} following successful acquisition. These {PSWs}, which manifest as increases in {PS} over normal levels, appear to exhibit shorter latencies to onset when the amount of material presented during acquisition is increased. Prevention of the {PSW} results in memory deficits. In humans, there is now evidence that different types of tasks are differentially sensitive to rapid eye movement sleep deprivation ({REMD).} Memory for declarative or explicit types of tasks appear not to be affected by {REM} sleep loss, while memory for cognitive procedural or implicit types of material are impaired by {REMD.} Using post training auditory stimulation during {REM} sleep, memory enhancement of the procedural material is also possible. The memory for a fine motor task appears to be sensitive to post training stage 2 sleep loss. The important neural structures are generally not yet identifiable, although the hippocampus would appear to be important for place learning in the Morris water maze.},
}
@article{mahon_judging_2010,
	abstract = {Much of mental life consists in thinking about object concepts that are not currently within the scope of perception. The general system that enables multiple representations to be maintained and compared is referred to as ``working memory'' [Repov{\v s} G, Baddeley A (2006) Neuroscience 139:5--21], and involves regions in medial and lateral parietal and frontal cortex [e.g., Smith {EE}, Jonides J (1999) Science 283:1657--1661]. It has been assumed that the contents of working memory index information in regions of the brain that are critical for processing and storing object knowledge. To study the processes involved in thinking about common object concepts, we used event related {fMRI} to study {BOLD} activity while participants made judgments of conceptual similarity over pairs of sequentially presented auditory words. Through a combination of conventional {fMRI} analysis approaches and multi-voxel pattern analysis ({MVPA)}, we show that the brain responses associated with the second word in a pair carry information about the conceptual similarity between the two members of the pair. This was the case in frontal and parietal regions involved in the working memory and decision components of the task for both analysis approaches. However, in other regions of the brain, including early visual regions, {MVPA} permitted classification of semantic distance relationships where conventional averaging approaches failed to show a difference. These findings suggest that diffuse and statistically sub-threshold ``scattering'' of {BOLD} activity in some regions may carry substantial information about the contents of mental representations.},
}
@article{kreiman_brain_2007,
	abstract = {We still lack a clear understanding of how brain imaging signals relate to neuronal activity. Recent work shows that the simultaneous activity of neuronal ensembles strongly correlates with local field potentials and imaging measurements.},
}
@article{field_high-resolution_2011,
	abstract = {Identifying the connectivity of the myriad neurons within a circuit is key to understanding its function. We developed a novel technique to map the functional connectivity between thousands of cone photoreceptors and hundreds of ganglion cells in the primate retina. These measurements reveal the nature of cone sampling by midget ganglion cells, providing insight to the origins of red-green color opponency.},
}
@article{forster_motor_1997,
}
@article{derrington_chromatic_1984,
}
@article{hoffman_semantic_2011,
	abstract = {Word frequency is a powerful predictor of language processing efficiency in healthy individuals and in computational models. Puzzlingly, frequency effects are often absent in stroke aphasia, challenging the assumption that word frequency influences the behavior of any computational system. To address this conundrum, we investigated divergent effects of frequency in two comprehension-impaired patient groups. Patients with semantic dementia have degraded conceptual knowledge as a consequence of anterior temporal lobe atrophy and show strong frequency effects. Patients with multimodal semantic impairments following stroke (semantic aphasia [{SA])}, in contrast, show little or no frequency effect. Their deficits arise from impaired control processes that bias activation toward task-relevant aspects of knowledge. We hypothesized that high-frequency words exert greater demands on cognitive control because they are more semantically diverse---they tend to appear in a broader range of linguistic contexts and have more variable meanings. Using latent semantic analysis, we developed a new measure of semantic diversity that reflected the variability of a word's meaning across different context. Frequency, but not diversity, was a significant predictor of comprehension in semantic dementia, whereas diversity was the best predictor of performance in {SA.} Most importantly, {SA} patients did show typical frequency effects but only when the influence of diversity was taken into account. These results are consistent with the view that higher-frequency words place higher demands on control processes, so that when control processes are damaged the intrinsic processing advantages associated with higher-frequency words are masked.},
}
@article{naselaris_bayesian_2009,
}
@article{franklin_new_2004,
	abstract = {Bornstein, Kessen, and Weiskopf (1976) reported that pre-linguistic infants perceive colour categorically for primary boundaries: Following habituation, dishabituation only occurred if the test stimulus was from a different adult category to the original. Here, we replicated this important study and extended it to include secondary boundaries, with a crucial modification: The separations between habituated and novel stimuli were equated in a perceptually uniform metric (Munsell), rather than in wavelength. Experiment 1 found Categorical Perception and no within-category novelty preference for primary boundary blue-green and secondary boundary blue-purple. Experiment 2 replicated the categorical effect for blue-purple and found no within-category novelty preference with increased stimulus separation. Experiment 3 showed category effects for a lightness/saturation boundary, pink-red. Novelty preference requires a categorical difference between the habituated and novel stimulus. The implications for the origin of linguistic colour categories are discussed.},
}
@article{suzuki_distinct_2013,
	abstract = {The posterior parietal cortex and the prefrontal cortex are associated with eye movements and visual attention, but their specific contributions are poorly understood. We compared the dorsolateral prefrontal cortex ({dlPFC)} and the lateral intraparietal area ({LIP)} in monkeys using a memory saccade task in which a salient distractor flashed at a variable timing and location during the memory delay. We found that the two areas had similar responses to target selection, but made distinct contributions to distractor suppression. Distractor responses were more strongly suppressed and more closely correlated with performance in the {dlPFC} relative to {LIP.} Moreover, reversible inactivation of the {dlPFC} produced much larger increases in distractibility than inactivation of {LIP.} These findings suggest that {LIP} and {dlPFC} mediate different aspects of selective attention. Although both areas can contribute to the perceptual selection of salient information, the {dlPFC} has a decisive influence on whether and how attended stimulus is linked with actions.},
}
@article{wnuczko_when_2012,
}
@article{bornstein_color_1973,
	abstract = {Proposes an hypothesis which relates physiological differences in visual processing to semantic categorization. A comparison of primary color-naming systems across cultures reveals a regular geographic patterning of color-naming confusions. These semantic data indicative of a short wavelength (blue) insensitive, so-called tritan, color vision have been corroborated by psychophysically measured depressions in spectral sensitivity and confusions in color matching. Yellow intraocular pigmentation which is biometeorologically adaptive and which attenuates effective short wavelength radiation is assessed to contribute in varying degrees toward mimicry of the tritan color-vision complex. Furthermore, the density of yellow intraocular pigmentation is found to parallel the worldwide distribution of collapsed color-naming systems (51/2 p. ref.)},
}
@article{stewart_naming_1992,
	abstract = {An apparently clear case of category-specific naming impairment selectively affecting animals was detected in a patient who had recovered from herpes simplex encephalitis. However, subsequent investigation demonstrated that these category-specific effects could be eliminated by controlling simultaneously for three factors in picture naming: word frequency, concept familiarity, and visual complexity. The results emphasize the importance of controlling for all factors pertinent to picture naming when attempting to demonstrate category specificity in picture naming. Further testing indicated that deficits were also apparent when naming to definition was required, and some impairment in the ability to answer questions about objects and living things was also noted. Theoretical implications of these data are considered. Fiona Stewart is now at the Department of Speech Therapy, Frenchay Hospital, Bristol {BS16} {1LE}, {U.K.}},
}
@misc{_erp_????,
	abstract = {Using event-related brain potentials ({ERPs)}, we investigated the time course of facial expression processing in human subjects watching photographs of fearful and neutral faces. Upright fearful faces elicited a frontocentral positivity within 120 ms after stimulus presentation, which was followed...},
}
@article{buchel_multimodal_1998,
	abstract = {Reading words and naming pictures involves the association of visual stimuli with phonological and semantic knowledge. Damage to a region of the brain in the left basal posterior temporal lobe ({BA37)}, which is strategically situated between the visual cortex and the more anterior temporal cortex, leads to reading and naming deficits,. Additional evidence implicating this region in linguistic processing comes from functional neuroimaging studies of reading in normal subjects and subjects with developmental dyslexia,. Here we test whether the visual component of reading is essential for activation of {BA37} by comparing cortical activations elicited by word processing in congenitally blind, late-blind and sighted subjects using functional neuroimaging. Despite the different modalities used (visual and tactile), all groups of subjects showed a common activation of {BA37} by words relative to non-word letter-strings. These findings agree with the proposal that {BA37} is an association area that integrates converging inputs from many regions. Our study confirms a prediction of theories of brain function that depend on convergence zones; the absence of one input (that is, visual) does not alter the response properties of such a convergence region.},
}
@article{kanske_emotion_2011,
	abstract = {Coherent behavior depends on attentional control that detects and resolves conflict between opposing actions. The current functional magnetic resonance imaging study tested the hypothesis that emotion triggers attentional control to speed up conflict processing in particularly salient situations. Therefore, we presented emotionally negative and neutral words in a version of the flanker task. In response to conflict, we found activation of the dorsal anterior cingulate cortex ({ACC)} and of the amygdala for emotional stimuli. When emotion and conflict coincided, a region in the ventral {ACC} was activated, which resulted in faster conflict processing in reaction times. Emotion also increased functional connectivity between the ventral {ACC} and activation of the dorsal {ACC} and the amygdala in conflict trials. These data suggest that the ventral {ACC} integrates emotion and conflict and prioritizes the processing of conflict in emotional trials. This adaptive mechanism ensures rapid detection and resolution of conflict in potentially threatening situations signaled by emotional stimuli. Hum Brain Mapp, 2011. \copywrite 2010 Wiley-Liss, Inc.},
}
@article{fusar-poli_functional_2009,
	abstract = {Background: Most of our social interactions involve perception of emotional information from the faces of other people. Furthermore, such emotional processes are thought to be aberrant in a range of clinical disorders, including psychosis and depression. However, the exact neurofunctional maps underlying emotional facial processing are not well defined. Methods: Two independent researchers conducted separate comprehensive {PubMed} (1990 to May 2008) searches to find all functional magnetic resonance imaging ({fMRI)} studies using a variant of the emotional faces paradigm in healthy participants. The search terms were: {``fMRI} {AND} happy faces,'' {``fMRI} {AND} sad faces,'' {``fMRI} {AND} fearful faces,'' {``fMRI} {AND} angry faces,'' {``fMRI} {AND} disgusted faces'' and {``fMRI} {AND} neutral faces.'' We extracted spatial coordinates and inserted them in an electronic database. We performed activation likelihood estimation analysis for voxel-based meta-analyses. Results: Of the originally identified studies, 105 met our inclusion criteria. The overall database consisted of 1785 brain coordinates that yielded an overall sample of 1600 healthy participants. Quantitative voxel-based meta-analysis of brain activation provided neurofunctional maps for 1) main effect of human faces; 2) main effect of emotional valence; and 3) modulatory effect of age, sex, explicit versus implicit processing and magnetic field strength. Processing of emotional faces was associated with increased activation in a number of visual, limbic, temporoparietal and prefrontal areas; the putamen; and the cerebellum. Happy, fearful and sad faces specifically activated the amygdala, whereas angry or disgusted faces had no effect on this brain region. Furthermore, amygdala sensitivity was greater for fearful than for happy or sad faces. Insular activation was selectively reported during processing of disgusted and angry faces. However, insular sensitivity was greater for disgusted than for angry faces. Conversely, neural response in the visual cortex and cerebellum was observable across all emotional conditions. Limitations: Although the activation likelihood estimation approach is currently one of the most powerful and reliable meta-analytical methods in neuroimaging research, it is insensitive to effect sizes. Conclusion: Our study has detailed neurofunctional maps to use as normative references in future {fMRI} studies of emotional facial processing in psychiatric populations. We found selective differences between neural networks underlying the basic emotions in limbic and insular brain regions. ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved) (journal abstract)},
}
@article{yang_accessing_2011,
	abstract = {Previous research has shown implicit semantic processing of faces or pictures, but whether symbolic carriers such as words can be processed this way remains controversial. Here we examine this issue by adopting the continuous flash suppression paradigm to ensure that the processing undergone is indeed unconscious without the involvement of partial awareness. Negative or neutral words projected into one eye were made invisible due to strong suppression induced by dynamic-noise patterns shown in the other eye through binocular rivalry. Inverted and scrambled words were used as controls to provide baselines at orthographic and feature levels, respectively. Compared to neutral words, emotion-described and emotion-induced negative words required longer time to release from suppression, but only for upright words. These results suggest that words can be processed unconsciously up to semantic level since under interocular suppression completely invisible words can lead to different processing speed due to the emotion information they carry.},
}
@article{foundas_anomia:_1998,
	abstract = {Abstract In a recent case study of anomic aphasia following a unilateral left hemispheric stroke limited to Brodmann's area 37, it was proposed that this area may be important for object naming by allowing the semantic system access to stored lexical information. Based on this finding and theories postulating a modular system for word retrieval, we proposed that a patient with a lesion to area 37 and another patient with a lesion to a speech production region located serially downstream from area 37 would both be anomic, and in neither case could the anomia be attributed to a significant semantic impairment. Using a case study design to investigate the level of naming disturbance in these two patients with unilateral left hemispheric strokes, we have demonstrated that Patient 1, who had a lesion to area 37, and Patient 2, with a lesion to inferior-lateral portions of Brodmann's area 6, were anomic with semantic knowledge of words relatively preserved.},
}
@article{tononi_regional_2005,
}
@article{sillito_always_2006,
	abstract = {Feedback projections are an integral part of the mammalian visual system. Although it is tempting to relegate them to a subsidiary role in visual processing, because their supposed latency and lag might appear to be unfavourable for an involvement in fast processing, this is a dangerous simplification. Certainly for the world in motion, feedback from higher motion areas can influence the transfer of ascending input when, or even before, the input arrives. Here, we consider the circuit formed by layer 6 feedback cells in the visual cortex and how this straddles the retinothalamic and thalamocortical transfer of visual input. We discuss its links to feedback from the cortical motion area {MT} (V5), and suggest that motion perception involves a dynamic interplay between {MT}, V1 and the thalamus. This review is part of the {TINS} special issue on The Neural Substrates of Cognition.},
}
@article{bode_decoding_2009,
	abstract = {The flow of information from sensory stimuli to motor responses in the human brain can be flexibly re-routed depending on task demands. However, it has remained unclear which sequence of processes is involved in preparing the brain for an upcoming task. Here, we used a combination of {fMRI} and multivariate pattern classification to decompose the information flow in a task-switching experiment. Specifically, we present a time-resolved decoding approach that allowed us to track the temporal buildup of task-related information. This approach also allowed us to distinguish encoding of the task from encoding of target stimuli and motor responses, thus separating between different components of information processing. We were able to decode from parietal and lateral prefrontal cortex which specific task-set a subject was currently holding. Importantly, this revealed that the intraparietal sulcus encoded task-set information before prefrontal cortex, and it was the only region to encode the specific task-set before the relevant target stimulus was presented. This suggests that task-related information in parietal cortex does not rely on input from prefrontal cortex as previously suggested. In contrast, our findings suggest that parietal cortex might play a role in establishing task-sets in prefrontal cortex.},
}
@article{mesulam_primary_2003,
	abstract = {Dementia is a generic term used to designate chronically progressive brain disease that impairs intellect and behavior to the point where customary activities of daily living become compromised.1,2 In some patients, specific abnormalities, such as a vitamin B12 deficiency, normal pressure hydrocephalus, multiple strokes, paraneoplastic encephalitis, or human immunodeficiency virus infection, are identified as the underlying cause. In others, characteristic sensory or motor abnormalities indicate that the dementia is a component of a more extensive neurologic disease such as Parkinson's disease, Huntington's disease, amyotrophic lateral sclerosis, or multiple sclerosis. In the majority of patients with dementia, however, none . . .},
}
@article{heider_structure_1972,
	abstract = {Ss from two cultures with markedly different color terminologies were tested on two color-judgment tasks. One was a nonverbal task of color matching from memory, while the other was a verbal task of color-naming. Both tasks were performed by 41 American Ss and 40 New Guinea Dani (who have a basically two-term color language). Multidimensional scaling based upon the four resulting sets of data yielded structures that were more similar under the memory condition than under the naming condition. For neither culture were equally distant colors confused in memory more within than across name boundaries. Retention of color images in short-term memory appears to be unaffected by wide cultural differences in the semantic reference of color words.},
}
@article{van_der_linden_task-_2013,
	abstract = {In this study, we bridge the gap between monkey electrophysiological recordings that showed selective responses to informative features and human {fMRI} data that demonstrated increased and selective responses to trained objects. Human participants trained with computer-generated fish stimuli. For each participant, two features of the fish were informative for category membership and two features were uninformative. After training, participants showed higher perceptual sensitivity to the informative dimensions. An {fMRI} adaptation paradigm revealed that during categorization the right inferior frontal gyrus and occipitotemporal cortex were selectively responsive to the informative features. These selective cortical responses were experience dependent; they were not present for the entire trained object, but specific for those features that were informative for categorization. Responses in the inferior frontal gyrus showed category selectivity. Moreover, selectivity to the informative features correlated with performance on the categorization task during scanning. This all suggests that the frontal cortex is involved in actively categorizing objects and that it uses informative features to do so while ignoring those features that do not contribute category information. Occipitotemporal cortex also showed selectivity to the informative features during the categorization task. Interestingly, this area showed a positive correlation of performance during training and selectivity to the informative features and a negative correlation with selectivity to the uninformative features. This indicates that training enhanced sensitivity to trained items and decreased sensitivity to uninformative features. The absence of sensitivity for informative features during a color change detection task indicates that there is a strong component of task-related processing of these features.},
}
@article{baronchelli_networks_2013,
	abstract = {Networks of interconnected nodes have long played a key role in Cognitive Science, from artificial neural networks to spreading activation models of semantic memory. Recently, however, a new Network Science has been developed, providing insights into the emergence of global, system-scale properties in contexts as diverse as the Internet, metabolic reactions, and collaborations among scientists. Today, the inclusion of network theory into Cognitive Sciences, and the expansion of complex-systems science, promises to significantly change the way in which the organization and dynamics of cognitive and behavioral processes are understood. In this paper, we review recent contributions of network theory at different levels and domains within the Cognitive Sciences.},
}
@article{winawer_effects_2003,
	abstract = {Across languages, verbal codes divide the color spectrum in different ways. Do linguistic codes affect color discrimination? In a {2AFC} recognition memory task, it was shown that subjects (Ss) are less likely to false alarm to cross category ({CC)} than within category ({WC)} foils, but that this advantage disappears with a verbal interference task (Roberson \& Davidoff). This effect might be explained by a verbal contribution to categorical perception, or by language acting as a secondary code to meet the demands of working memory. We asked whether Ss show a {CC} advantage in tasks with no memory component, whether this advantage is selectively reduced by verbal interference, and whether this advantage can be seen in a language group that has a verbal color boundary and not in one without the same boundary.
}
@article{carroll_prediction_2009,
	abstract = {We explore to what extent the combination of predictive and interpretable modeling can provide new insights for functional brain imaging. For this, we apply a recently introduced regularized regression technique, the Elastic Net, to the analysis of the {PBAIC} 2007 competition data. Elastic Net regression controls via one parameter the number of voxels in the resulting model, and via another the degree to which correlated voxels are included. We find that this method produces highly predictive models of {fMRI} data that provide evidence for the distributed nature of neural function. We also use the flexibility of Elastic Net to demonstrate that model robustness can be improved without compromising predictability, in turn revealing the importance of localized clusters of activity. Our findings highlight the functional significance of patterns of distributed clusters of localized activity, and underscore the importance of models that are both predictive and interpretable.},
}
@article{beauchamp_parallel_2002,
}
@article{tranel_naming_2005,
	abstract = {We have proposed that the left inferotemporal ({IT)} region contains structures that mediate between conceptual knowledge retrieval and word-form retrieval, and we have hypothesized that these structures are utilized for word retrieval irrespective of the sensory modality through which an entity is apprehended, thus being ``modality neutral.'' We tested this idea in two sensory modalities, visual and auditory, and for two categories of concrete entities, tools and animals. In a {PET} experiment, 10 normal participants named tools and animals either from pictures or from characteristic sounds (e.g., ``scissors'' from a picture of a scissors or from the sound of a scissors cutting; ``rooster'' from a picture of a rooster or from the sound of a rooster crowing). Visual and auditory naming of tools activated the left posterior/lateral {IT;} visual and auditory naming of animals activated the left anterior/ ventral {IT.} For both tools and animals, the left {IT} activations were similar in location and magnitude regardless of whether participants were naming entities from pictures or from sounds. The results provide novel evidence to support the notion that left {IT} structures contain ``modality-neutral'' systems for mediating between conceptual knowledge and word retrieval.},
}
@article{naccache_priming_2001,
	abstract = {Most of the current brain imaging methods are limited by the low spatial resolution of neuroimaging techniques and remain unable to measure activity at the scale of single neurons or small columns of neurons, which are the coding elements of the nervous system. In this work we have adapted the priming method, an emerging research strategy that can overcome some of these spatial limitations, to investigate the coding of numerical quantities in the human brain. This approach combines the logic of psychological priming experiments with the recently discovered neurophysiological phenomenon called repetition suppression ({RS).} In each trial, while subjects perform a constant task, a subliminal prime is presented prior to each target. By varying the relationship between prime and target, one can detect which brain areas present {RS} specifically for any given level of prime--target repetition. We first expose the general logic, potential and limitations of the priming method and then illustrate it by demonstrating that a region of parietal cortex is coding for numbers at the quantity level, independently of other stimulus attributes, and that this region processes both consciously and unconsciously perceived stimuli.},
}
@article{van_gerven_interpreting_2009,
	abstract = {Univariate statistical approaches are often used for the analysis of neuroimaging data but are unable to detect subtle interactions between different components of brain activity. In contrast, multivariate approaches that use classification as a basis are well-suited to detect such interactions, allowing the analysis of neuroimaging data on the single trial level. However, multivariate approaches typically assign a non-zero contribution to every component, making interpretation of the results troublesome. This paper introduces groupwise regularisation as a novel method for finding sparse, and therefore easy to interpret, models that are able to predict the experimental condition to which single trials belong. Furthermore, the obtained models can be constrained in various ways by placing features extracted from the data that are thought to belong together into groups. In order to learn models from data, we introduce a new algorithm that makes use of stability conditions that have been derived in this paper. The algorithm is used to classify multisensor {EEG} signals recorded for a motor imagery task using (groupwise) regularised logistic regression as the underlying classifier. We show that regularisation dramatically reduces the number of features without reducing the classification rate. This improves model interpretability as it finds features in the data such as mu and beta desynchronisation in the motor cortex contralateral to the imagined movement. By choosing particular groupings we can constrain the regularised solutions such that a lower number of sensors is used or a model is obtained that generalises well over subjects. The identification of a small number of groups of features that best explain the data make groupwise regularisation a useful new tool for single trial analysis.},
}
@article{dilkina_conceptual_2013,
	abstract = {Current views of semantic memory share the assumption that conceptual representations are based on multimodal experience, which activates distinct modality-specific brain regions. This proposition is widely accepted, yet little is known about how each modality contributes to conceptual knowledge and how the structure of this contribution varies across these multiple information sources. We used verbal feature lists, features from drawings, and verbal co-occurrence statistics from latent semantic analysis to examine the informational structure in four domains of knowledge: perceptual, functional, encyclopedic, and verbal. The goals of the analysis were three-fold: (1) to assess the structure within individual modalities; (2) to compare structures between modalities; and (3) to assess the degree to which concepts organize categorically or randomly. Our results indicated significant and unique structure in all four modalities: perceptually, concepts organize based on prominent features such as shape, size, color, and parts; functionally, they group based on use and interaction; encyclopedically, they arrange based on commonality in location or behavior; and verbally, they group associatively or relationally. Visual/perceptual knowledge gives rise to the strongest hierarchical organization and is closest to classic taxonomic structure. Information is organized somewhat similarly in the perceptual and encyclopedic domains, which differs significantly from the structure in the functional and verbal domains. Notably, the verbal modality has the most unique organization, which is not at all categorical but also not random. The idiosyncrasy and complexity of conceptual structure across modalities raise the question of how all of these modality-specific experiences are fused together into coherent, multifaceted yet unified concepts. Accordingly, both methodological and theoretical implications of the present findings are discussed.},
}
@article{mumford_deconvolving_2012,
	abstract = {Use of multivoxel pattern analysis ({MVPA)} to predict the cognitive state of a subject during task performance has become a popular focus of {fMRI} studies. The input to these analyses consists of activation patterns corresponding to different tasks or stimulus types. These activation patterns are fairly straightforward to calculate for blocked trials or slow event-related designs, but for rapid event-related designs the evoked {BOLD} signal for adjacent trials will overlap in time, complicating the identification of signal unique to specific trials. Rapid event-related designs are often preferred because they allow for more stimuli to be presented and subjects tend to be more focused on the task, and thus it would be beneficial to be able to use these types of designs in {MVPA} analyses. The present work compares 8 different models for estimating trial-by-trial activation patterns for a range of rapid event-related designs varying by interstimulus interval and signal-to-noise ratio. The most effective approach obtains each trial's estimate through a general linear model including a regressor for that trial as well as another regressor for all other trials. Through the analysis of both simulated and real data we have found that this model shows some improvement over the standard approaches for obtaining activation patterns. The resulting trial-by-trial estimates are more representative of the true activation magnitudes, leading to a boost in classification accuracy in fast event-related designs with higher signal-to-noise. This provides the potential for {fMRI} studies that allow simultaneous optimization of both univariate and {MVPA} approaches.},
}
@article{simmons_common_2007,
	abstract = {Functional neuroimaging research has demonstrated that retrieving information about object-associated colors activates the left fusiform gyrus in posterior temporal cortex. Although regions near the fusiform have previously been implicated in color perception, it remains unclear whether color knowledge retrieval actually activates the color perception system. Evidence to this effect would be particularly strong if color perception cortex was activated by color knowledge retrieval triggered strictly with linguistic stimuli. To address this question, subjects performed two tasks while undergoing {fMRI.} First, subjects performed a property verification task using only words to assess conceptual knowledge. On each trial, subjects verified whether a named color or motor property was true of a named object (e.g., {TAXI-yellow}, {HAIR-combed).} Next, subjects performed a color perception task. A region of the left fusiform gyrus that was highly responsive during color perception also showed greater activity for retrieving color than motor property knowledge. These data provide the first evidence for a direct overlap in the neural bases of color perception and stored information about object-associated color, and they significantly add to accumulating evidence that conceptual knowledge is grounded in the brain's modality-specific systems.},
}
@article{kenward_small_1997,
}
@article{goldstone_influences_1994,
	abstract = {Four experiments investigated the influence of categorization training on perceptual discrimination. Ss were trained according to 1 of 4 different categorization regimes. Subsequent to category learning, Ss performed a {Same--Different} judgment task. Ss' sensitivities ( d's) for discriminating between items that varied on category-(ir)relevant dimensions were measured. Evidence for acquired distinctiveness (increased perceptual sensitivity for items that are categorized differently) was obtained. One case of acquired equivalence (decreased perceptual sensitivity for items that are categorized together) was found for separable, but not integral, dimensions. Acquired equivalence within a categorization-relevant dimension was never found for either integral or separable dimensions. The relevance of the results for theories of perceptual learning, dimensional attention, categorical perception, and categorization are discussed.},
}
@article{notman_nature_2005,
	abstract = {Categorical perception is often cited as a striking example of cognitive influences on perception. However, some evidence suggests the term is a misnomer, with effects based on cognitive not perceptual processing. Here, using a psychophysical approach, we provide evidence consistent with a learned categorical perception effect that is dependent on analysis within the visual processing stream. An improvement in participants' discrimination between grating patterns that they had learned to place in different categories was 'tuned' around the orientation of the patterns experienced during category learning. Thus, here, categorical perception may result from attentionally modulated perceptual learning about diagnostic category features, based upon orientation-selective stages of analysis. This argues strongly that category learning can alter our perception of the world.},
}
@article{gerlach_perceptual_1999,
	abstract = {The purpose of the present {PET} study was (i) to investigate the neural correlates of object recognition, i.e. the matching of visual forms to memory, and (ii) to test the hypothesis that this process is more difficult for natural objects than for artefacts. This was done by using object decision tasks where subjects decided whether pictures represented real objects or non-objects. The object decision tasks differed in their difficulty (the degree of perceptual differentiation needed to perform them) and in the category of the real objects used (natural objects versus artefacts). A clear effect of task difficulty was found in both the behavioural and in the {PET} data. In the {PET} data, the increase in task difficulty was associated with increased regional cerebral blood flow in the posterior part of the right inferior temporal gyrus and in the anterior part of the right fusiform gyrus. This may be the neural correlate of matching visual forms to memory, and the amount of activation in these regions may correspond to the degree of perceptual differentiation required for recognition to occur. With respect to behaviour, it took significantly longer to make object decisions on natural objects than on artefacts in the difficult object decision tasks. Natural objects also recruited larger parts of the right inferior temporal and anterior fusiform gyri compared with artefacts as task difficulty increased. Differences in the amount of activation in these regions may reflect the greater perceptual differentiation required for recognizing natural objects. These findings are discussed in relation to category-specific impairments after neural damage.},
}
@article{poldrack_future_2011,
}
@article{buzsaki_two-stage_1989,
	abstract = {Review of the normally occurring neuronal patterns of the hippocampus suggests that the two principal cell types of the hippocampus, the pyramidal neurons and granule cells, are maximally active during different behaviors. Granule cells reach their highest discharge rates during theta-concurrent exploratory activities, while population synchrony of pyramidal cells is maximum during immobility, consummatory behaviors, and slow wave sleep associated with field sharp waves. Sharp waves reflect the summed postsynaptic depolarization of large numbers of pyramidal cells in the {CA1} and subiculum as a consequence of synchronous discharge of bursting {CA3} pyramidal neurons. The trigger for the population burst in the {CA3} region is the temporary release from subcortical tonic inhibition.
}
@article{tsuchiya_continuous_2005,
	abstract = {Illusions that produce perceptual suppression despite constant retinal input are used to manipulate visual consciousness. Here we report on a powerful variant of existing techniques, continuous flash suppression. Distinct images flashed successively at 10 Hz into one eye reliably suppress an image presented to the other eye. The duration of perceptual suppression is at least ten times greater than that produced by binocular rivalry. Using this tool we show that the strength of the negative afterimage of an adaptor was reduced by half when it was perceptually suppressed by input from the other eye. The more completely the adaptor was suppressed, the more strongly the afterimage intensity was reduced. Paradoxically, trial-to-trial visibility of the adaptor did not correlate with the degree of reduction. Our results imply that formation of afterimages involves neuronal structures that access input from both eyes but that do not correspond directly to the neuronal correlates of perceptual awareness.},
}
@article{murison_sleep_1982,
	abstract = {Sprague-Dawley male rats were deprived of food for 40 hr and subjected to sleep deprivation by the ``flower pot'' or handling intervention procedures during the final 24 hr. Five of six rats in the flower pot group exhibited stomach erosions. Only one rat in the handling group, and no rats in a food deprived control group showed such erosions. The flower pot group also had higher levels of corticosterone than the food deprived control group. These findings argue for more serious consideration of the effects of the stress of procedures for sleep deprivation.},
}
@article{mckenzie_consolidation_2011,
}
@article{frank_mechanisms_2012,
	abstract = {Growing evidence suggests that the prefrontal cortex ({PFC)} is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit, the basal ganglia gate frontal actions, with some striatal units gating the inputs to {PFC} and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if--then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-reinforcement learning mixture of experts ({MoE)} model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the {MoE} model. This 2-pronged modeling approach leads to multiple quantitative predictions that are tested with functional magnetic resonance imaging in the companion paper.},
}
@article{chouinard_category-specific_2010-1,
	abstract = {Using activation-likelihood estimation ({ALE)} meta-analysis, we identified brain areas that are invoked when people name pictures of animals and pictures of tools. We found that naming animals and naming tools invoked separate distributed networks in the brain. Specifically, we found that naming animals invoked greater responses than naming tools in frontal lobe structures that are typically modulated by emotional content and task demands, and in a number of visual areas in the ventral stream. In contrast, naming tools invoked greater responses in a different set of areas in the ventral stream than those invoked by naming animals. Naming tools also invoked greater responses than naming animals in motor areas in the frontal lobe as well as in sensory areas in the parietal lobe. The only overlapping sites of activation that we found for naming these two categories of objects were in the left pars triangularis, the left inferior temporal gyrus, and the left parahippocampal gyrus. Taken together, our meta-analysis reveals that animals and tools are categorically represented in visual areas but show convergence in higher-order associative areas in the temporal and frontal lobes in regions that are typically regarded as being involved in memory and/or semantic processing. Our results also reveal that naming tools not only engages visual areas in the ventral stream but also a fronto-parietal network associated with tool use. Whether or not this network associated with tool use contributes directly to recognition will require further investigation.},
}
@article{gerhardstein_roles_1999,
	abstract = {For both adults and infants, whether a unique target pops out from a background of distractors and captures attention depends on the perceived target-distractor similarity. For adults, this similarity can be categorical as well as perceptual, but whether the same is true for infants is unknown. Here, the authors examined whether infants' colour pop-out is affected by categorical target-distractor similarity using targetdistractor pairs in Munsell colours from either the same or a different category and representing different degrees of perceptual similarity. It was found that only targets that were perceptually most dissimilar from the distractor colours popped out, irrespective of category membership; target colours more perceptually similar to the distractor colour did not, even if they were from a different colour category. Although young infants are known to categorize colours in an adult-like fashion, whether or not they preattentively detect a uniquely coloured target is determined by a noncategorical, perceptual colour metric.},
}
@article{rogers_structure_2004,
}
@article{oliveira_cognitive_2013,
	abstract = {{INTRODUCTION:} Cognitive schemas are often related to psychological problems. However, the role of these structures within sexual problems is not yet well established.
}
@article{almeida_unconscious_2008,
	abstract = {Visual object recognition is subserved by ventral temporal and occipital regions of the brain. Regions comprising the dorsal visual pathway have not been considered relevant for object recognition, despite strong categorical biases for tool-related information in those regions. Here, we show that dorsal stream processes influence object categorization. We used two techniques to render prime pictures invisible: continuous flash suppression ({CFS)}, which obliterates input into ventral temporal regions, but leaves dorsal stream processes largely unaffected, and backward masking ({BM)}, which allows suppressed information to reach both ventral and dorsal stream structures. Categorically congruent primes suppressed under {CFS} facilitate categorization of tools but have no effect on nonmanipulable objects; in contrast, primes rendered invisible through {BM} facilitate target categorization for both tools and nonmanipulable things. Our findings demonstrate that information computed by the dorsal stream is used in object categorization, but only for a category of manipulable objects.},
}
@article{kouider_levels_2007,
	abstract = {Understanding the extent and limits of non-conscious processing is an important step on the road to a thorough understanding of the cognitive and cerebral correlates of conscious perception. In this article, we present a critical review of research on subliminal perception during masking and other related experimental conditions. Although initially controversial, the possibility that a broad variety of processes can be activated by a non-reportable stimulus is now well established. Behavioural findings of subliminal priming indicate that a masked word or digit can have an influence on perceptual, lexical and semantic levels, while neuroimaging directly visualizes the brain activation that it evokes in several cortical areas. This activation is often attenuated under subliminal presentation conditions compared to consciously reportable conditions, but there are sufficiently many exceptions, in paradigms such as the attentional blink, to indicate that high activation, per se, is not a sufficient condition for conscious access to occur. We conclude by arguing that for a stimulus to reach consciousness, two factors are jointly needed: (i) the input stimulus must have enough strength (which can be prevented by masking) and (ii) it must receive top-down attention (which can be prevented by drawing attention to another stimulus or task). This view leads to a distinction between two types of non-conscious processes, which we call subliminal and preconscious. According to us, maintaining this distinction is essential in order to make sense of the growing neuroimaging data on the neural correlates of consciousness.},
}
@article{tononi_consciousness_2005,
	abstract = {Clinical observations have established that certain parts of the brain are essential for consciousness whereas other parts are not. For example, different areas of the cerebral cortex contribute different modalities and submodalities of consciousness, whereas the cerebellum does not, despite having even more neurons. It is also well established that consciousness depends on the way the brain functions. For example, consciousness is much reduced during slow wave sleep and generalized seizures, even though the levels of neural activity are comparable or higher than in wakefulness. To understand why this is so, empirical observations on the neural correlates of consciousness need to be complemented by a principled theoretical approach. Otherwise, it is unlikely that we could ever establish to what extent consciousness is present in neurological conditions such as akinetic mutism, psychomotor seizures, or sleepwalking, and to what extent it is present in newborn babies and animals. A principled approach is provided by the information integration theory of consciousness. This theory claims that consciousness corresponds to a system's capacity to integrate information, and proposes a way to measure such capacity. The information integration theory can account for several neurobiological observations concerning consciousness, including: (i) the association of consciousness with certain neural systems rather than with others; (ii) the fact that neural processes underlying consciousness can influence or be influenced by neural processes that remain unconscious; (iii) the reduction of consciousness during dreamless sleep and generalized seizures; and (iv) the time requirements on neural interactions that support consciousness.},
}
@article{tranel_impaired_2006,
	abstract = {Previous studies have shown that the left temporal polar ({TP)} region is important for the retrieval of proper names for persons. It has been proposed that the key specialization of left {TP} is for proper nouns (rather than names for persons, per se), which predicts that left {TP} should support other categories whose members are denoted by proper names (e.g., landmarks). A lesion study tested the hypothesis that impaired naming of famous unique landmarks would be associated with damage to left {TP.} A Landmark Recognition and Naming Test was administered to participants with lesions to left {TP}, right {TP}, or regions outside {TP.} The results provided strong support for the hypothesis: Landmark naming was significantly inferior in the left group, supporting the hypothesis. The findings converge with previous lesion and functional imaging data to support the idea that the left {TP} region is important for the retrieval of names for unique entities. This fits the proposal that left {TP} contains convergence regions that operate as intermediaries between conceptual knowledge retrieval and lexical retrieval for classes of unique stimuli (H. Damasio, D. Tranel, T. J. Grabowski, R. Adolphs, \& A. R. Damasio, 2004). ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved). (journal abstract)},
}
@article{wu_searching_2013,
	abstract = {Visual search is often guided by top--down attentional templates that specify target-defining features. But search can also occur at the level of object categories. We measured the N2pc component, a marker of attentional target selection, in two visual search experiments where targets were defined either categorically (e.g., any letter) or at the item level (e.g., the letter C) by a prime stimulus. In both experiments, an N2pc was elicited during category search, in both familiar and novel contexts (Experiment 1) and with symbolic primes (Experiment 2), indicating that, even when targets are only defined at the category level, they are selected at early sensory-perceptual stages. However, the N2pc emerged earlier and was larger during item-based search compared with category-based search, demonstrating the superiority of attentional guidance by item-specific templates. We discuss the implications of these findings for attentional control and category learning.},
}
@article{mitchell_learning_2004,
	abstract = {Over the past decade, functional Magnetic Resonance Imaging ({fMRI)} has emerged as a powerful new instrument to collect vast quantities of data about activity in the human brain. A typical {fMRI} experiment can produce a three-dimensional image related to the human subject's brain activity every half second, at a spatial resolution of a few millimeters. As in other modern empirical sciences, this new instrumentation has led to a flood of new data, and a corresponding need for new data analysis methods. We describe recent research applying machine learning methods to the problem of classifying the cognitive state of a human subject based on {fRMI} data observed over a single time interval. In particular, we present case studies in which we have successfully trained classifiers to distinguish cognitive states such as (1) whether the human subject is looking at a picture or a sentence, (2) whether the subject is reading an ambiguous or non-ambiguous sentence, and (3) whether the word the subject is viewing is a word describing food, people, buildings, etc. This learning problem provides an interesting case study of classifier learning from extremely high dimensional (10 5 features), extremely sparse (tens of training examples), noisy data. This paper summarizes the results obtained in these three case studies, as well as lessons learned about how to successfully apply machine learning methods to train classifiers in such settings.},
}
@article{grabowski_premotor_1998,
	abstract = {It has been shown that the retrieval of words denoting visually presented concrete entities engages neural systems in the left temporal lobe and that the precise pattern of activation within the temporal lobe depends in part on the conceptual category to which the entity belongs. Here, we used [{15O]water} positron emission tomography to test the hypothesis that the pattern of activation associated with word retrieval in left frontal lobe would also be related to conceptual category. The design entailed the performance of three tasks requiring the retrieval of words denoting animals, tools, and unique persons. The visual stimuli were presented at different rates, to produce equal performance success across categories, a feature which also had the effect of equalizing the proportion of scan time spent in mental search. All three word retrieval tasks activated the left inferior frontal gyrus, but they differed in their recruitment of two other premotor and prefrontal areas. Activity in a portion of the middle frontal gyrus, corresponding to Brodmann area 46, bore a linear relation to response latency and may index the extent of mental search. This region was most active when subjects named persons. Activity in the anterior bank of the precentral gyrus, along the inferior and middle frontal gyri, was most marked for naming tools. This region overlaps the area activated when subjects generate words for actions. We suggest that it is engaged by the retrieval of words denoting actions or objects with characteristic actions. The data presented here provide additional support for the notion that ``nonclassical'' language areas in extrasylvian frontal and temporal regions mediate word retrieval and that the pattern of their engagement relates to conceptual category.},
}
@article{saffran_dog_2007,
	abstract = {Human infants possess powerful learning mechanisms used for the acquisition of language. To what extent are these mechanisms domain specific? One well-known infant language learning mechanism is the ability to detect and generalize rule-like similarity patterns, such as {ABA} or {ABB} [Marcus, G. F., Vijayan, S., Rao, S. B., \& Vishton, P. M. (1999). Rule learning by seven-month-old infants. Science, 283, 77-80.]. The results of three experiments demonstrate that 7-month-old infants can detect and generalize these same patterns when the elements consist of pictures of animals (dogs and cats). These findings indicate that rule learning of this type is not specific to language acquisition.},
}
@article{hanson_combinatorial_2004,
	abstract = {Haxby et al. [Science 293 (2001) 2425] recently argued that category-related responses in the ventral temporal ({VT)} lobe during visual object identification were overlapping and distributed in topography. This observation contrasts with prevailing views that object codes are focal and localized to specific areas such as the fusiform and parahippocampal gyri. We provide a critical test of Haxby's hypothesis using a neural network ({NN)} classifier that can detect more general topographic representations and achieves 83\% correct generalization performance on patterns of voxel responses in out-of-sample tests. Using voxel-wise sensitivity analysis we show that substantially the same {VT} lobe voxels contribute to the classification of all object categories, suggesting the code is combinatorial. Moreover, we found no evidence for local single category representations. The neural network representations of the voxel codes were sensitive to both category and superordinate level features that were only available implicitly in the object categories.},
}
@article{rao_sparse_2013,
	abstract = {Multitask learning can be effective when features useful in one task are also useful for other tasks, and the group lasso is a standard method for selecting a common subset of features. In this paper, we are interested in a less restrictive form of multitask learning, wherein (1) the available features can be organized into subsets according to a notion of similarity and (2) features useful in one task are similar, but not necessarily identical, to the features best suited for other tasks. The main contribution of this paper is a new procedure called Sparse Overlapping Sets ({SOS)} lasso, a convex optimization that automatically selects similar features for related learning tasks. Error bounds are derived for {SOSlasso} and its consistency is established for squared error loss. In particular, {SOSlasso} is motivated by multi- subject {fMRI} studies in which functional activity is classified using brain voxels as features. Experiments with real and synthetic data demonstrate the advantages of {SOSlasso} compared to the lasso and group lasso.},
}
@article{humphrey_role_1994,
	abstract = {Three experiments were conducted to explore the role of colour and other surface properties in object recognition. The effects of manipulating the availability of surface-based information on object naming in a patient with visual form agnosia and in two age-matched control subjects were examined in experiment 1. The objects were presented under seven different viewing conditions ranging from a full view of the actual objects to line drawings of those same objects. The presence of colour and other surface properties aided the recognition of natural objects such as fruits and vegetables in both the patient and the control subjects. Experiment 2 was focused on four of the critical viewing conditions used in experiment 1 but with a large sample of normal subjects. As in experiment 1, it was found that surface properties, particularly colour, aided the naming of natural objects. The presence of colour did not facilitate the naming of manufactured objects. Experiment 3 was focused on possible ways by which colour could assist in the recognition of natural objects and it was found that object naming was facilitated only if the objects were presented in their usual colour. The results of the experiments show that colour does improve recognition for some types of objects and that the improvement occurs at a high level of visual analysis.},
}
@article{jefferies_semantic_2006,
	abstract = {Different neuropsychological populations implicate diverse cortical regions in semantic memory: semantic dementia ({SD)} is characterized by atrophy of the anterior temporal lobes whilst poor comprehension in stroke aphasia is associated with prefrontal or temporal--parietal infarcts. This study employed a case-series design to compare {SD} and comprehension-impaired stroke aphasic patients directly on the same battery of semantic tests. Although the two groups obtained broadly equivalent scores, they showed qualitatively different semantic deficits. The {SD} group showed strong correlations between different semantic tasks---regardless of input/output modality---and substantial consistency when a set of items was assessed several times. They were also highly sensitive to frequency/familiarity and made coordinate and superordinate semantic errors in picture naming. These findings support the notion that amodal semantic representations degrade in {SD.} The stroke aphasia group also showed multimodal deficits and consistency across different input modalities, but inconsistent performance on tasks requiring different types of semantic processing. They were insensitive to familiarity/frequency---instead, tests of semantic association were influenced by the ease with which relevant semantic relationships could be identified and distractors rejected. In addition, the aphasic patients made associative semantic errors in picture naming that {SD} patients did not make. The aphasic patients' picture naming performance improved considerably with phonemic cues suggesting that these patients retained knowledge that could not be accessed without contextual support. We propose that semantic cognition is supported by two interacting principal components: (i) a set of amodal representations (which progressively degrade in {SD)} and (ii) executive processes that help to direct and control semantic activation in a task-appropriate fashion (which are dysfunctional in comprehension-impaired stroke aphasic patients).},
}
@article{weiner_neural_2013,
	abstract = {Neurophysiology and optical imaging studies in monkeys and functional magnetic resonance imaging ({fMRI)} studies in both monkeys and humans have localized clustered neural responses in inferotemporal cortex selective for images of biologically relevant categories, such as faces and limbs. Using higher resolution (1.5 mm voxels) {fMRI} scanning methods than past studies (3--5 mm voxels), we recently reported a network of multiple face- and limb-selective regions that neighbor one another in human ventral temporal cortex (Weiner and Grill-Spector, Neuroimage, 52(4):1559--1573, 2010) and lateral occipitotemporal cortex (Weiner and Grill-Spector, Neuroimage, 56(4):2183--2199, 2011). Here, we expand on three basic organization principles of high-level visual cortex revealed by these findings: (1) consistency in the anatomical location of functional regions, (2) preserved spatial relationship among functional regions, and (3) a topographic organization of face- and limb-selective regions in adjacent and alternating clusters. We highlight the implications of this structure in comparing functional brain organization between typical and atypical populations. We conclude with a new model of high-level visual cortex consisting of ventral, lateral, and dorsal components, where multimodal processing related to vision, action, haptics, and language converges in the lateral pathway. ({PsycINFO} Database Record (c) 2013 {APA}, all rights reserved) (journal abstract)},
}
@article{binder_where_2009,
}
@article{torriero_changes_2010,
	abstract = {The cerebellum is involved in motor learning of new procedures both during actual execution of a motor task and during observational training. These processes are thought to depend on the activity of a neural network that involves the lateral cerebellum and primary motor cortex (M1). In this study, we used a twin-coil {TMS} technique to investigate whether execution and observation of a visuomotor procedural learning task is related to modulation of cerebello-motor connectivity. We observed that, at rest, a magnetic conditioning pulse applied over the lateral cerebellum reduced the motor-evoked potentials obtained by stimulating the contralateral M1, indicating activation of a cerebello-motor connection. Furthermore, during procedural learning, cerebellar stimulation resulted in selective facilitation, not inhibition, of contralateral M1 excitability. The effects were evident when motor learning was obtained by actual execution of the task or by observation, but they disappeared if procedural learning had already been acquired by previous observational training. These results indicate that changes in cerebello-motor connectivity occur in relation to specific phases of procedural learning, demonstrating a complex pattern of excitatory and inhibitory drives modulated across time.},
}
@article{moss_anteromedial_2005-1,
}
@article{joseph_functional_2001,
	abstract = {Functional neuroimaging studies in which the cortical organization for semantic knowledge has been addressed have revealed interesting dissociations in the recognition of different object categories, such as faces, natural objects, and manufactured objects. The present paper critically reviews these studies and performs a meta-analysis of stereotactic coordinates to determine whether category membership predicts patterns of brain activation across different studies. This meta-analysis revealed that, in the ventral temporal cortex, recognition of manufactured objects activates more medial aspects of the fusiform gyrus, as compared with natural object or face recognition. Face recognition activates more inferior aspects of the ventral temporal cortex, as compared with manufactured object recognition. The recognition task used---viewing, matching, or naming---also predicted brain activation patterns. Specifically, matching tasks recruit more inferior occipital regions than do either naming or viewing tasks, whereas naming tasks recruit more anterior ventral temporal sites than do either viewing or matching tasks. These findings indicate that the cognitive demands of a particular recognition task are as predictive of cortical activation patterns as is category membership.},
}
@article{mandler_separating_1991,
	abstract = {The nature of the conceptual categories that children have developed in the second year was studied in a series of experiments using an object-manipulation task. In the first two experiments, it was shown that by 18 months children have developed global conceptual categories of animals and vehicles without yet clearly differentiating basic-level categories within these domains. The basic-level categories were tested by using a series of contrasts: a low degree of contrast was provided by presenting the children with dogs versus horses and with cars versus trucks. A moderate degree of contrast consisted of dogs versus rabbits and cars versus motorcycles. A high degree of contrast consisted of dogs versus fish (or birds) and cars versus airplanes. A domain-level contrast of animals versus vehicles was included as well. From 18 to 30 months the children tended to respond categorically only on the global domain-level contrast and on the high-contrast basic-level distinctions. Not until 30 months did the children consistently differentiate the low and moderate basic-level contrasts. Experiment 3 replicated the finding of global animal and vehicle categories, using the widest possible range of exemplars. Experiment 4 extended the study of global categorization to the domains of plants, furniture, kitchen utensils, tools, and musical instruments. Global categorization was found for plants, furniture, and kitchen utensils, but not for tools and musical instruments. Experiment 5 found little evidence for basic-level categorization of plants, and only suggestive evidence for basic-level categorization in the domains of furniture and utensils. The data demonstrate the presence of a number of global conceptual categories from an early age, and suggest that at least in some domains (animals, vehicles, and plants) such categories develop before true basic-level distinctions are made.},
}
@article{horne_consolidation_1984,
	abstract = {One commonly held hypothesis about the function of {REM} sleep ({RS)} concerns the consolidation of plastic processes, particularly those relating to learning and memory. The majority of the experimental data apparently supporting this hypothesis come from {RS} deprivation ({RSD)} studies. However, this review points out that: (i) there are several shortcomings with the methodology of animal {RSD} investigations, (ii) {RSD} seems to produce arousal and stereotyped behaviour which may interfere with learning etc., and consequently give artificial support to the hypothesis. The review then examines evidence outside the field of {RSD}, relating to the hypothesis, which seems further to confound or contradict it. Whilst the hypothesis is not rejected, these problems need to be addressed further by its supporters.},
}
@article{rosenbaum_amnesia_2009,
	abstract = {Autobiographical episodic recall involves active simultaneous generation and binding of various elements that were present during the initial experience. Deficits in this reconstructive process may account for some aspects of retrograde amnesia ({RA)} for personally experienced events. Constructive and reconstructive processes may involve similar mechanisms. If so, patients with extensive anterograde amnesia ({AA)} and {RA} should show deficits in non-recollective cognitive domains, such as imagining events that had never been experienced and recounting non-personal narratives, that presumably rely on constructive and re-constructive processes, respectively. To test these possibilities, patient {K.C.}, who has severe {AA} and {RA} for personal episodes, was asked to generate fictional events and to recall and recognize details of well-known fairy tales and bible stories. {K.C.'s} performance on both tasks was better than expected given his severely impaired autobiographical episodic memory ({AM)}, but significantly worse than that of control participants. {K.C.} was able to create a skeletal outline for both types of narratives, providing sufficient information to convey their gist, but the narratives were fragmented and lacking in detail. This deficit cannot be explained as resulting entirely from deficient stored semantic knowledge, because {K.C.} was able to discriminate between true and false details of non-personal semantic narratives on a recognition test, which he cannot do for personal events [Gilboa, A., Winocur, G., Rosenbaum, {R.S.}, Poreh, A., Gao, F., Black, {S.E.}, Westmacott, R., \& Moscovitch, M. (2006a). Hippocampal contributions to recollection in retrograde and anterograde amnesia. Hippocampus, 16, 966--980]. Thus, retrograde {AM} impairment may be viewed as both a loss of information as well as a deficit in reconstructive processes that hamper or prevent the binding of information to generate a cohesive, detail-rich memory.},
}
@article{bedny_concepts_2008,
	abstract = {Several regions of the posterior-lateral-temporal cortex ({PLTC)} are reliably recruited when participants read or listen to action verbs, relative to other word and nonword types. This {PLTC} activation is generally interpreted as reflecting the retrieval of visual-motion features of actions. This interpretation supports the broader theory, that concepts are comprised of sensory-motor features. We investigated an alternative interpretation of the same activations: {PLTC} activity for action verbs reflects the retrieval of modality-independent representations of event concepts, or the grammatical types associated with them, i.e., verbs. During a functional magnetic resonance imaging scan, participants made semantic-relatedness judgments on word pairs varying in amount of visual-motion information. Replicating previous results, several {PLTC} regions showed higher responses to words that describe actions versus objects. However, we found that these {PLTC} regions did not overlap with visual-motion regions. Moreover, their response was higher for verbs than nouns, regardless of visual-motion features. For example, the response of the {PLTC} is equally high to action verbs (e.g., to run) and mental verbs (e.g., to think), and equally low to animal nouns (e.g., the cat) and inanimate natural kind nouns (e.g., the rock). Thus, {PLTC} activity for action verbs might reflect the retrieval of event concepts, or the grammatical information associated with verbs. We conclude that concepts are abstracted away from sensory-motor experience and organized according to conceptual properties.},
}
@article{stickgold_sleep-dependent_2005,
	abstract = {The concept of 'sleeping on a problem' is familiar to most of us. But with myriad stages of sleep, forms of memory and processes of memory encoding and consolidation, sorting out how sleep contributes to memory has been anything but straightforward. Nevertheless, converging evidence, from the molecular to the phenomenological, leaves little doubt that offline memory reprocessing during sleep is an important component of how our memories are formed and ultimately shaped.},
}
@article{desai_activation_2010,
	abstract = {The sensory-motor account of conceptual processing suggests that modality-specific attributes play a central role in the organization of object and action knowledge in the brain. An opposing view emphasizes the abstract, amodal, and symbolic character of concepts, which are thought to be represented outside the brain's sensory-motor systems. We conducted a functional magnetic resonance imaging study in which the participants listened to sentences describing hand/arm action events, visual events, or abstract behaviors. In comparison to visual and abstract sentences, areas associated with planning and control of hand movements, motion perception, and vision were activated when understanding sentences describing actions. Sensory-motor areas were activated to a greater extent also for sentences with actions that relied mostly on hands, as opposed to arms. Visual sentences activated a small area in the secondary visual cortex, whereas abstract sentences activated superior temporal and inferior frontal regions. The results support the view that linguistic understanding of actions partly involves imagery or simulation of actions, and relies on some of the same neural substrate used for planning, performing, and perceiving actions.},
}
@article{shinkareva_commonality_2011,
}
@article{cirelli_genetic_2009,
	abstract = {It has been known for a long time that genetic factors affect sleep quantity and quality. Genetic screens identified several mutations that affect sleep across species, pointing to an evolutionary conserved regulation of sleep. Moreover, it has also been recognized that sleep affects the expression of genes. These findings have given valuable clues about the molecular underpinnings of sleep regulation and function that might lead the way to more efficient treatments for sleep disorders.},
}
@article{berlin_basic_1969,
}
@article{jimura_analyses_2012,
}
@article{hickok_dorsal_2004,
	abstract = {Despite intensive work on language-brain relations, and a fairly impressive accumulation of knowledge over the last several decades, there has been little progress in developing large-scale models of the functional anatomy of language that integrate neuropsychological, neuroimaging, and psycholinguistic data. Drawing on relatively recent developments in the cortical organization of vision, and on data from a variety of sources, we propose a new framework for understanding aspects of the functional anatomy of language which moves towards remedying this situation. The framework posits that early cortical stages of speech perception involve auditory fields in the superior temporal gyrus bilaterally (although asymmetrically). This cortical processing system then diverges into two broad processing streams, a ventral stream, which is involved in mapping sound onto meaning, and a dorsal stream, which is involved in mapping sound onto articulatory-based representations. The ventral stream projects ventro-laterally toward inferior posterior temporal cortex (posterior middle temporal gyrus) which serves as an interface between sound-based representations of speech in the superior temporal gyrus (again bilaterally) and widely distributed conceptual representations. The dorsal stream projects dorso-posteriorly involving a region in the posterior Sylvian fissure at the parietal-temporal boundary (area Spt), and ultimately projecting to frontal regions. This network provides a mechanism for the development and maintenance of "parity" between auditory and motor representations of speech. Although the proposed dorsal stream represents a very tight connection between processes involved in speech perception and speech production, it does not appear to be a critical component of the speech perception process under normal (ecologically natural) listening conditions, that is, when speech input is mapped onto a conceptual representation. We also propose some degree of bi-directionality in both the dorsal and ventral pathways. We discuss some recent empirical tests of this framework that utilize a range of methods. We also show how damage to different components of this framework can account for the major symptom clusters of the fluent aphasias, and discuss some recent evidence concerning how sentence-level processing might be integrated into the framework.},
}
@article{ryali_sparse_2010,
	abstract = {Multivariate pattern recognition methods are increasingly being used to identify multiregional brain activity patterns that collectively discriminate one cognitive condition or experimental group from another, using {fMRI} data. The performance of these methods is often limited because the number of regions considered in the analysis of {fMRI} data is large compared to the number of observations (trials or participants). Existing methods that aim to tackle this dimensionality problem are less than optimal because they either over-fit the data or are computationally intractable. Here, we describe a novel method based on logistic regression using a combination of L1 and L2 norm regularization that more accurately estimates discriminative brain regions across multiple conditions or groups. The L1 norm, computed using a fast estimation procedure, ensures a fast, sparse and generalizable solution; the L2 norm ensures that correlated brain regions are included in the resulting solution, a critical aspect of {fMRI} data analysis often overlooked by existing methods. We first evaluate the performance of our method on simulated data and then examine its effectiveness in discriminating between well-matched music and speech stimuli. We also compared our procedures with other methods which use either L1-norm regularization alone or support vector machine-based feature elimination. On simulated data, our methods performed significantly better than existing methods across a wide range of contrast-to-noise ratios and feature prevalence rates. On experimental {fMRI} data, our methods were more effective in selectively isolating a distributed fronto-temporal network that distinguished between brain regions known to be involved in speech and music processing. These findings suggest that our method is not only computationally efficient, but it also achieves the twin objectives of identifying relevant discriminative brain regions and accurately classifying {fMRI} data.},
}
@article{gerlach_structural_2001,
	abstract = {It has been suggested that category-specific impairments for natural objects may reflect that natural objects are more globally visually similar than artefacts and therefore more difficult to recognize following brain damage [Aphasiology 13 (1992) 169]. This account has been challenged by the finding that the 'normal' disadvantage claimed for natural objects may be reversed when items from the categories of natural objects and artefacts are matched for visual complexity, familiarity and name frequency [Neuropsychologia 37 (1999) 1263]. In the experiments reported here it was investigated whether category effects could be found on object decision tasks (deciding whether pictures represented real objects or not), when the stimulus material was matched across categories. In experiment 1, a disadvantage for natural objects was found on difficult object decision tasks whereas no category difference was found on easy object decision tasks. In experiment 2 an advantage for natural objects was found during object decisions performed under degraded viewing conditions (lateralized stimulus presentation). It is argued that these findings can be accounted for by assuming that natural objects are more globally visually similar than artefacts, but that this difference between categories affects performance in different ways depending on task characteristics. Thus, the greater overlap between natural objects may be a disadvantage when the demand on perceptual differentiation is high (as it is in difficult object decision tasks). However, when viewing conditions are degraded and performance tends to depend on global shape information (carried by low spatial frequency components), natural objects may fare better than artefacts because the global shape of natural objects reveals more of their identity than the global shapes of artefacts.},
}
@article{meinecke_detection_2002,
	abstract = {We carried out three experiments to investigate detection performance in pop-out tasks and analysed how performance varied as a function of display size (number of elements) and retinal eccentricity of the target. Results showed that when display size was increased from 2 to 81 elements performance first decreased and then increased (replicating Sagi and Julesz, 1987 Spatial Vision 2 39 - 49). Performance variations differed as a function of eccentricity and often were more pronounced in the periphery than in the foveal area. This retinal-eccentricity influence suggests that processes underlying detection performance in small display sizes are different from those in large display sizes. One should be careful when using the variation of display size as an instrument to analyse visual-search processes because this analysis could be based on a comparison between non-equivalent conditions.},
}
@article{goldstone_reuniting_1998,
	abstract = {Work in philosophy and psychology has argued for a dissociation between perceptually-based similarity and higher-level rules in conceptual thought. Although such a dissociation may be justified at times, our goal is to illustrate ways in which conceptual processing is grounded in perception, both for perceptual similarity and abstract rules. We discuss the advantages, power and influences of perceptually-based representations. First, many of the properties associated with amodal symbol systems can be achieved with perceptually-based systems as well (e.g. productivity). Second, relatively raw perceptual representations are powerful because they can implicitly represent properties in an analog fashion. Third, perception naturally provides impressions of overall similarity, exactly the type of similarity useful for establishing many common categories. Fourth, perceptual similarity is not static but becomes tuned over time to conceptual demands. Fifth, the original motivation or basis for sophisticated cognition is often less sophisticated perceptual similarity. Sixth, perceptual simulation occurs even in conceptual tasks that have no explicit perceptual demands. Parallels between perceptual and conceptual processes suggest that many mechanisms typically associated with abstract thought are also present in perception, and that perceptual processes provide useful mechanisms that may be co-opted by abstract thought.},
}
@article{barsalou_context-independent_1982,
	abstract = {It is proposed that concepts contain two types of properties. Context-independent properties are activated by the word for a concept on all occasions. The activation of these properties is unaffected by contextual relevance. Context-dependent properties are not activated by the respective word independent of context. Rather, these properties are activated only by relevant contexts in which the word appears. Context-independent properties form the core meanings of words, whereas context-dependent properties are a source of semantic encoding variability. This proposal lies between two opposing theories of meaning, one that argues all properties of a concept are active on all occasions and another that argues the active properties are completely determined by context. The existence of context-independent and context-dependent properties is demonstrated in two experimental settings: the property-verification task and judgments of similarity. The relevance of these property types to cross-classification, problem solving, metaphor and sentence comprehension, and the semantic-episodic distinction is discussed.},
}
@article{engel_retinotopic_1997,
	abstract = {A method of using functional magnetic resonance imaging ({fMRI)} to measure retinotopic organization within human cortex is described. The method is based on a visual stimulus that creates a traveling wave of neural activity within retinotopically organized visual areas. We measured the {fMRI} signal caused by this stimulus in visual cortex and represented the results on images of the flattened cortical sheet. We used the method to locate visual areas and to evaluate the spatial precision of {fMRI.} Specifically, we: (i) identified the borders between several retinotopically organized visual areas in the posterior occipital lobe; (ii) measured the function relating cortical position to visual field eccentricity within area V1; (iii) localized activity to within 1.1 mm of visual cortex; and (iv) estimated the spatial resolution of the {fMRI} signal and found that signal amplitude falls to 60\% at a spatial frequency of 1 cycle per 9 mm of visual cortex. This spatial resolution is consistent with a linespread whose full width at half maximum spreads across 3.5 mm of visual cortex.},
}
@article{kang_semantic_2011-1,
	abstract = {It has been intensely debated whether visual stimuli are processed to the point of semantic analysis in the absence of awareness. In the present study, we measured the extent to which the meaning of a stimulus was registered using the N400 component of human event-related potentials ({ERPs)}, a highly sensitive index of the semantic mismatch between a stimulus and the context in which it is presented. Observers judged the semantic relatedness of a context and target word while {ERPs} were recorded under continuous flash suppression (Experiments 1 and 2) and binocular rivalry (Experiment 3). Finally, we parametrically manipulated the visibility of the target word by increasing the contrast between the target word and the suppressive stimulus presented to the other eye (Experiment 4). We found that the amplitude of the N400 was attenuated with increasing suppression depth and was absent whenever the observers could not discriminate the meaning of suppressed words. We discuss these findings in the context of single-process models of consciousness, which can account for a large body of empirical evidence obtained from visual masking, attentional manipulations, and, now, interocular suppression paradigms.},
}
@article{roos_disconnect_2000,
}
@article{lambon_ralph_are_1998,
	abstract = {Abstract Perhaps the most influential view of category-specific deficits is one in which the dissociation between living and non-living kinds reflects differential reliance on, or weighting of visual or associative-functional attributes. We present data collected from two patients, which question the apparent relationship between category-specific deficits and loss of specific attribute types. One patient with dementia of Alzheimer's type presented with relatively poor performance on living things but failed to show a difference between knowledge of visual and associative-functional information. The other patient with semantic dementia demonstrated relatively poor knowledge of visual attributes but failed to exhibit a category-specific impairment for animate kinds. In fact her comprehension and naming were slightly but significantly better for living things. The data are discussed with reference to various theories of category-specific impairment. We suggest that category-specific deficits for living things probably results from a combination of atrophy to medial and neocortical temporal structures, including the inferior temporal lobe. It is proposed that at the behavioural level, category-specific deficits arise when both critical identifying attributes of knowledge are lost and the intercorrelation between features causes disintegration of the category such that each exemplar 'regresses' towards a category prototype.},
}
@article{glenberg_processing_2008,
	abstract = {Embodiment theory proposes that neural systems for perception and action are also engaged during language comprehension. Previous neuroimaging and neurophysiological studies have only been able to demonstrate modulation of action systems during comprehension of concrete language. We provide neurophysiological evidence for modulation of motor system activity during the comprehension of both concrete and abstract language. In Experiment 1, when the described direction of object transfer or information transfer (e.g., away from the reader to another) matched the literal direction of a hand movement used to make a response, speed of responding was faster than when the two directions mismatched (an action--sentence compatibility effect). In Experiment 2, we used single-pulse transcranial magnetic stimulation to study changes in the corticospinal motor pathways to hand muscles while reading the same sentences. Relative to sentences that do not describe transfer, there is greater modulation of activity in the hand muscles when reading sentences describing transfer of both concrete objects and abstract information. These findings are discussed in relation to the human mirror neuron system.},
}
@article{watson_functional_2011,
	abstract = {Our current understanding of the neural basis of semantic memory is informed primarily by studies of concrete objects. However, conceptual knowledge encompasses many other, albeit less concrete, domains. This article reviews evidence from neuroimaging and patient studies that speaks to the neural basis of action concepts and the words that refer to them. These data highlight 2 important principles governing the neural instantiation of semantic knowledge. First, the organization of conceptual representations in the brain parallels perception and action. Action concepts are at least partially represented within modality-specific areas responsible for the perception and execution of dynamic actions. Second, unimodal sensory and motor cortices act as ``points of entry'' for more abstract action knowledge. Increasingly abstract conceptual knowledge derived from these modalities is represented in brain areas located anterior and centripetal to modality-specific regions. Extending research on the neural basis of semantics to include dynamic and relational aspects of the world gives us a more complete appreciation of the range of cognitive and communication impairments that may be experienced by patients with neurologic disease.},
}
@article{kriegeskorte_representational_2008,
	abstract = {A fundamental challenge for systems neuroscience is to quantitatively relate its three major branches of research: brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging ({fMRI).} Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., {fMRI} and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices ({RDMs)}, which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis ({RSA)}, in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing {RDMs.} We demonstrate {RSA} by relating representations of visual objects as measured with {fMRI} in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The {RDMs} are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of {RSA}, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
}
@article{tyler_conceptual_2000,
	abstract = {We present a new account of the fine-grained structure of semantic categories derived from neuropsychological, behavioral, and developmental data. The account places theoretical emphasis on the functions of the referents of concepts. We claim (i) that the distinctiveness of functional features correlated with perceptual features varies across semantic domains; and (ii) that category structure emerges from the complex interaction of these variables. The representational assumptions that follow from these claims make strong predictions about what types of semantic information are preserved in patients showing category-specific deficits following brain damage. These claims are illustrated with a connectionist simulation which, when damaged, shows patterns of preservation of distinctive and shared functional and perceptual information which varies across semantic domains. The data model both dissociations between knowledge for artifacts and for living things and recent neuropsychological evidence concerning the robustness of functional information in the representation of concepts.},
}
@article{goldstein_knowing_2009,
	abstract = {Two experiments attempted to reconcile discrepant recent findings relating to children's color naming and categorization. In a replication of Franklin and colleagues (Journal of Experimental Child Psychology, 90 (2005) 114--141), Experiment 1 tested English toddlers' naming and memory for blue--green and blue--purple colors. It also found advantages for between-category presentations that could be interpreted as support for universal color categories. However, a different definition of knowing color terms led to quite different conclusions in line with the Whorfian view of Roberson and colleagues (Journal of Experimental Psychology: General, 133 (2004) 554--571). Categorical perception in recognition memory was now found only for children with a fuller understanding of the relevant terms. It was concluded that color naming can both underestimate and overestimate toddlers' knowledge of color terms. Experiment 2 replicated the between-category recognition superiority found in Himba children by Franklin and colleagues for the blue--purple range. But Himba children, whose language does not have separate terms for green and blue, did not show a cross-category advantage for that set; rather, they behaved like English children who did not know their color terms.},
}
@article{clifford_contextual_2005,
	abstract = {Summary 
}
@article{fornito_graph_2013,
	abstract = {The human brain is a complex, interconnected network par excellence. Accurate and informative mapping of this humanconnectome has become a central goal of neuroscience. At the heart of this endeavor is the notion that brain connectivity can be abstracted to a graph of nodes, representing neural elements (e.g., neurons, brain regions), linked by edges, representing some measure of structural, functional or causal interaction between nodes. Such a representation brings connectomic data into the realm of graph theory, affording a rich repertoire of mathematical tools and concepts that can be used to characterize diverse anatomical and dynamical properties of brain networks. Although this approach has tremendous potential---and has seen rapid uptake in the neuroimaging community---it also has a number of pitfalls and unresolved challenges which can, if not approached with due caution, undermine the explanatory potential of the endeavor. We review these pitfalls, the prevailing solutions to overcome them, and the challenges at the forefront of the field. ({PsycINFO} Database Record (c) 2013 {APA}, all rights reserved) (journal abstract)},
}
@article{rizzolatti_organization_1998,
	abstract = {A series of recent anatomical and functional data has radically changed our view on the organization of the motor cortex in primates. In the present article we present this view and discuss its fundamental principles. The basic principles are the following: (a) the motor cortex, defined as the agranular frontal cortex, is formed by a mosaic of separate areas, each of which contains an independent body movement representation, (b) each motor area plays a specific role in motor control, based on the specificity of its cortical afferents and descending projections, (c) in analogy to the motor cortex, the posterior parietal cortex is formed by a multiplicity of areas, each of which is involved in the analysis of particular aspects of sensory information. There are no such things as multipurpose areas for space or body schema and (d) the parieto-frontal connections form a series of segregated anatomical circuits devoted to specific sensorimotor transformations. These circuits transform sensory information into action. They represent the basic functional units of the motor system. Although these conclusions mostly derive from monkey experiments, anatomical and brain-imaging evidence suggest that the organization of human motor cortex is based on the same principles. Possible homologies between the motor cortices of humans and non-human primates are discussed.},
}
@article{jiang_processing_2007,
	abstract = {Familiar and recognizable stimuli enjoy an advantage of predominance during binocular rivalry, and this advantage is usually attributed to their enhanced processing during the dominant phase. However, do familiar and recognizable stimuli have an advantage in breaking suppression? Test images were gradually introduced to one eye to compete against a standard high-contrast dynamic noise pattern presented to the other eye. Results showed that an upright face took less time than an upside-down face to gain dominance against the identical suppression noise. Results also showed that for Chinese readers, Chinese characters were faster to gain dominance than Hebrew words, whereas for Hebrew readers, the reverse was true. These results suggest that familiar and recognizable information, even when suppressed and invisible, is processed differently from unfamiliar information. Apparently, high-level information about visual form does contribute to the strength of a stimulus during its suppressed phase.},
}
@book{young_cognitive_1994,
	abstract = {This book discusses schema-focused therapy, an integrative approach . . . to treat characterological patients including borderline, narcissistic, avoidant, dependent, obsessive-compulsive, passive-aggressive, and histrionic personality disorders. . . . [This] model is [an] integration of cognitive behavior therapy with gestalt, object relations, and psychoanalytic approaches. It expands on conventional cognitive behavior therapy by placing more emphasis on the therapeutic relationship, affective experience, and the discussion of early life experiences. In addition to presenting the rationale, theory, and practical techniques of schema-focused therapy, this book includes an extended case example, and revised editions of the Schema Questionnaire, Client's Guide, and schema listings.},
}
@article{hauk_somatotopic_2004,
	abstract = {Since the early days of research into language and the brain, word meaning was assumed to be processed in specific brain regions, which most modern neuroscientists localize to the left temporal lobe. Here we use event-related {fMRI} to show that action words referring to face, arm, or leg actions (e.g., to lick, pick, or kick), when presented in a passive reading task, differentially activated areas along the motor strip that either were directly adjacent to or overlapped with areas activated by actual movement of the tongue, fingers, or feet. These results demonstrate that the referential meaning of action words has a correlate in the somatotopic activation of motor and premotor cortex. This rules out a unified ``meaning center'' in the human brain and supports a dynamic view according to which words are processed by distributed neuronal assemblies with cortical topographies that reflect word semantics.},
}
@article{gilbert_receptive_1992,
}
@article{almeida_role_2010,
	abstract = {The dorsal visual processing stream subserves object-directed action, whereas the ventral visual processing stream subserves visual object recognition. Little is known about how information computed by dorsal-stream structures influences object recognition. We used continuous flash suppression to functionally separate information computed by the dorsal stream from that computed by the ventral stream. We show that information originating from the dorsal stream influences not only decisions requiring the selection of superordinate category labels, but also decisions that entail the selection of a basic-level object. We further show that information computed by the dorsal stream does not carry specific functional information about objects. Our results indicate that the dorsal stream, in isolation from the ventral stream, is agnostic as to the identity of the objects that it processes. We suggest that structures within the dorsal visual processing stream compute motor-relevant information (e.g., graspability), which influences the identification of manipulable objects, and is not either about the function of the object or function-specific.},
}
@article{wise_language_2003,
	abstract = {The old neurological model of language, based on the writings of Broca, Wernicke and Lichtheim in the 19th century, is now undergoing major modifications. Observations on the anatomy and physiology of auditory processing in non-human primates are giving strong indicators as to how speech perception is organised in the human brain. In the light of this knowledge, functional activation studies with positron emission tomography ({PET)} and functional magnetic resonance imaging ({fMRI)} are achieving a new level of precision in the investigation of language organisation in the human brain, in a manner not possible with observations on patients with aphasic stroke. Although the use of functional imaging to inform methods of improving aphasia rehabilitation remains underdeveloped, there are strong indicators that this methodology will provide the means to research a very imperfectly developed area of therapy.},
}
@article{watson_functional_2011-1,
	abstract = {Our current understanding of the neural basis of semantic memory is informed primarily by studies of concrete objects. However, conceptual knowledge encompasses many other, albeit less concrete, domains. This article reviews evidence from neuroimaging and patient studies that speaks to the neural basis of action concepts and the words that refer to them. These data highlight 2 important principles governing the neural instantiation of semantic knowledge. First, the organization of conceptual representations in the brain parallels perception and action. Action concepts are at least partially represented within modality-specific areas responsible for the perception and execution of dynamic actions. Second, unimodal sensory and motor cortices act as "points of entry" for more abstract action knowledge. Increasingly abstract conceptual knowledge derived from these modalities is represented in brain areas located anterior and centripetal to modality-specific regions. Extending research on the neural basis of semantics to include dynamic and relational aspects of the world gives us a more complete appreciation of the range of cognitive and communication impairments that may be experienced by patients with neurologic disease.},
}
@article{bahrami_unconscious_2010,
	abstract = {Whether high-level properties of stimuli rendered invisible by interocular competition can influence perception and behavior remains controversial. We studied whether suppressed and invisible symbolic and nonsymbolic numerical stimuli can elicit priming. First, we established that participants were objectively unable to discriminate numerical prime stimuli when interocular suppression rendered them invisible. Next, we asked participants to enumerate a visible target set of items after being exposed to a suppressed, invisible (nonsymbolic or symbolic) prime set. Both symbolic and nonsymbolic unconsciously perceived numerical primes induced robust priming effects that were specific to the numerical distance between the target and prime. Comparison with a no-prime condition revealed that primes larger than targets interfered with target enumeration and primes the same as or smaller than targets facilitated target enumeration. Taken together, our findings provide clear evidence for high-level processing of stimuli rendered invisible through interocular suppression.},
}
@article{kalenine_critical_2010,
	abstract = {A number of conflicting claims have been advanced regarding the role of the left inferior frontal gyrus, inferior parietal lobe and posterior middle temporal gyrus in action recognition, driven in part by an ongoing debate about the capacities of putative mirror systems that match observed and planned actions. We report data from 43 left hemisphere stroke patients in two action recognition tasks in which they heard and saw an action word ('hammering') and selected from two videoclips the one corresponding to the word. In the spatial recognition task, foils contained errors of body posture or movement amplitude/timing. In the semantic recognition task, foils were semantically related (sawing). Participants also performed a comprehension control task requiring matching of the same verbs to objects (hammer). Using regression analyses controlling for both the comprehension control task and lesion volume, we demonstrated that performance in the semantic gesture recognition task was predicted by per cent damage to the posterior temporal lobe, whereas the spatial gesture recognition task was predicted by per cent damage to the inferior parietal lobule. A whole-brain voxel-based lesion symptom-mapping analysis suggested that the semantic and spatial gesture recognition tasks were associated with lesioned voxels in the posterior middle temporal gyrus and inferior parietal lobule, respectively. The posterior middle temporal gyrus appears to serve as a central node in the association of actions and meanings. The inferior parietal lobule, held to be a homologue of the monkey parietal mirror neuron system, is critical for encoding object-related postures and movements, a relatively circumscribed aspect of gesture recognition. The inferior frontal gyrus, on the other hand, was not predictive of performance in any task, suggesting that previous claims regarding its role in action recognition may require refinement.},
}
@article{_continuing_????,
}
@article{ryali_sparse_2010-1,
	abstract = {Multivariate pattern recognition methods are increasingly being used to identify multiregional brain activity patterns that collectively discriminate one cognitive condition or experimental group from another, using {fMRI} data. The performance of these methods is often limited because the number of regions considered in the analysis of {fMRI} data is large compared to the number of observations (trials or participants). Existing methods that aim to tackle this dimensionality problem are less than optimal because they either over-fit the data or are computationally intractable. Here, we describe a novel method based on logistic regression using a combination of L1 and L2 norm regularization that more accurately estimates discriminative brain regions across multiple conditions or groups. The L1 norm, computed using a fast estimation procedure, ensures a fast, sparse and generalizable solution; the L2 norm ensures that correlated brain regions are included in the resulting solution, a critical aspect of {fMRI} data analysis often overlooked by existing methods. We first evaluate the performance of our method on simulated data and then examine its effectiveness in discriminating between well-matched music and speech stimuli. We also compared our procedures with other methods which use either L1-norm regularization alone or support vector machine based feature elimination. On simulated data, our methods performed significantly better than existing methods across a wide-range of contrast-to-noise ratios and feature prevalence rates. On experimental {fMRI} data, our methods were more effective in selectively isolating a distributed fronto-temporal network that distinguished between brain regions known to be involved in speech and music processing. These findings suggest that our method is not only computationally efficient, but it also achieves the twin objectives of identifying relevant discriminative brain regions and accurately classifying {fMRI} data.},
}
@article{schacter_memory_2011,
	abstract = {Memory is prone to distortions that can have serious consequences in everyday life. Here we integrate emerging evidence that several types of memory distortions -- imagination inflation, gist-based and associative memory errors, and post-event misinformation -- reflect adaptive cognitive processes that contribute to the efficient functioning of memory, but produce distortions as a consequence of doing so. We consider recent cognitive and neuroimaging studies that link these distortions with adaptive processes, including simulation of future events, semantic and contextual encoding, creativity, and memory updating. We also discuss new evidence concerning factors that can influence the occurrence of memory distortions, such as sleep and retrieval conditions, as well as conceptual issues related to the development of an adaptive perspective.},
}
@article{heberlein_cortical_2004,
	abstract = {Humans are able to use nonverbal behavior to make fast, reliable judgments of both emotional states and personality traits. Whereas a sizeable body of research has identified neural structures critical for emotion recognition, the neural substrates of personality trait attribution have not been explored in detail. In the present study, we investigated the neural systems involved in emotion and personality trait judgments. We used a type of visual stimulus that is known to convey both emotion and personality information, namely, point-light walkers. We compared the emotion and personality trait judgments made by subjects with brain damage to those made by neurologically normal subjects and then conducted a lesion overlap analysis to identify neural regions critical for these two tasks. Impairments on the two tasks dissociated: Some subjects were impaired at emotion recognition, but judged personality normally; other subjects were impaired on the personality task, but normal at emotion recognition. Moreover, these dissociations in performance were associated with damage to specific neural regions: Right somatosensory cortices were a primary focus of lesion overlap in subjects impaired on the emotion task, whereas left frontal opercular cortices were a primary focus of lesion overlap in subjects impaired on the personality task. These findings suggest that attributions of emotional states and personality traits are accomplished by partially dissociable neural systems.},
}
@article{posner_localization_1988,
	abstract = {The human brain localizes mental operations of the kind posited by cognitive theories. These local computations are integrated in the performance of cognitive tasks such as reading. To support this general hypothesis, new data from neural imaging studies of word reading are related to results of studies on normal subjects and patients with lesions. Further support comes from studies in mental imagery, timing, and memory.},
}
@article{pessoa_emotion_2010,
	abstract = {A subcortical pathway through the superior colliculus and pulvinar to the amygdala is commonly assumed to mediate the non-conscious processing of affective visual stimuli. We review anatomical and physiological data that argue against the notion that such a pathway plays a prominent part in processing affective visual stimuli in humans. Instead, we propose that the primary role of the amygdala in visual processing, like that of the pulvinar, is to coordinate the function of cortical networks during evaluation of the biological significance of affective visual stimuli. Under this revised framework, the cortex has a more important role in emotion processing than is traditionally assumed.},
}
@article{fischer_sleep_2002,
	abstract = {Practicing a motor skill triggers a process of memory consolidation that continues for hours after practice has ended, and becomes manifest in an improved skill at later testing. We used a sequential motor task (finger-to-thumb opposition task) to show that, in humans, the formation of motor skill memories essentially benefits from sleep. Independent of whether placed during daytime or nighttime, sleep after practice enhanced speed of sequence performance on average by 33.5\% and reduced error rate by 30.1\% as compared with corresponding intervals of wakefulness. The effect of sleep after learning proved to be stable when retesting was postponed for another night, to exclude effects of sleep loss and to assure that all subjects had sufficient sleep before retrieval testing. Also, the consolidating effect of sleep was specific for the motor sequence learned. It did not generalize to a similar sequence containing identical movement segments in a different order. Retention periods of wakefulness improved performance only moderately and only if placed during daytime. The observations demonstrate a critical role of sleep for storing and optimizing motor skills.},
}
@article{chow_studies_1975,
}
@article{tahmasebi_is_2011,
	abstract = {Whereas low-level sensory processes can be linked to macroanatomy with great confidence, the degree to which high-level cognitive processes map onto anatomy is less clear. If function respects anatomy, more accurate intersubject anatomical registration should result in better functional alignment. Here, we use auditory functional magnetic resonance imaging and compare the effectiveness of affine and nonlinear registration methods for aligning anatomy and functional activation across subjects. Anatomical alignment was measured using normalized cross-correlation within functionally defined regions of interest. Functional overlap was assessed using t-statistics from the group analyses and the degree to which group statistics predict high and consistent signal change in individual data sets. In regions related to early stages of auditory processing, nonlinear registration resulted in more accurate anatomical registration and stronger functional overlap among subjects compared with affine. In frontal and temporal areas reflecting high-level processing of linguistic meaning, nonlinear registration also improved the accuracy of anatomical registration. However, functional overlap across subjects was not enhanced in these regions. Therefore, functional organization, relative to anatomy, is more variable in the frontal and temporal areas supporting meaning-based processes than in areas devoted to sensory/perceptual auditory processing. This demonstrates for the first time that functional variability increases systematically between regions supporting lower and higher cognitive processes.},
}
@article{pobric_amodal_2010,
	abstract = {The key question of how the brain codes the meaning of words and pictures is the focus of vigorous debate. Is there a ``semantic hub'' in the temporal poles where these different inputs converge to form amodal conceptual representations? Alternatively, are there distinct neural circuits that underpin our comprehension of pictures and words? Understanding words might be primarily left-lateralised, linked to other language areas, while semantic representation of pictures may be more bilateral. To elucidate this debate, we used offline, low-frequency, repetitive transcranial magnetic stimulation ({rTMS)} to disrupt neural processing temporarily in the left or right temporal poles. During the induced refractory period, participants made judgements of semantic association for verbal and pictorial stimuli. The efficiency of semantic processing was reduced by {rTMS}, yet a perceptual task of comparable difficulty was unaffected. {rTMS} applied to the left or right temporal poles disrupted semantic processing for words and pictures to the same degree, while {rTMS} delivered at a control site had no impact. The results confirm that both temporal poles form a critical substrate within the neural network that supports conceptual knowledge, regardless of modality.},
}
@article{piolino_autobiographical_2003,
}
@article{martin_discrete_1995,
	abstract = {The areas of the brain that mediate knowledge about objects were investigated by measuring changes in regional cerebral blood flow ({rCBF)} using positron emission tomography ({PET).} Subjects generated words denoting colors and actions associated with static, achromatic line drawings of objects in one experiment, and with the written names of objects in a second experiment. In both studies, generation of color words selectively activated a region in the ventral temporal lobe just anterior to the area involved in the perception of color, whereas generation of action words activated a region in the middle temporal gyrus just anterior to the area involved in the perception of motion. These data suggest that object knowledge is organized as a distributed system in which the attributes of an object are stored close to the regions of the cortex that mediate perception of those attributes.},
}
@article{tononi_sleep_2003,
	abstract = {During much of sleep, the cerebral cortex is rippled by slow waves, which appear in the electroencephalogram as oscillations between 0.5 and {4.5\&\#xa0;Hz.} Slow waves are regulated as a function of previous wakefulness, being maximal at the beginning of sleep and then progressively returning to a baseline level. This paper discusses a hypothesis about the significance of slow-wave activity and its homeostatic regulation. The hypothesis is as follows:1.
}
@article{strack_inhibiting_1988,
	abstract = {We investigated the hypothesis that people's facial activity influences their affective responses. Two studies were designed to both eliminate methodological problems of earlier experiments and clarify theoretical ambiguities. This was achieved by having subjects hold a pen in their mouth in ways that either inhibited or facilitated the muscles typically associated with smiling without requiring subjects to pose in a smiling face. Study 1's results demonstrated the effectiveness of the procedure. Subjects reported more intense humor responses when cartoons were presented under facilitating conditions than under inhibiting conditions that precluded labeling of the facial expression in emotion categories. Study 2 served to further validate the methodology and to answer additional theoretical questions. The results replicated Study 1's findings and also showed that facial feedback operates on the affective but not on the cognitive component of the humor response. Finally, the results suggested that both inhibitory and facilitatory mechanisms may have contributed to the observed affective responses.},
}
@article{amihai_conscious_2011,
	abstract = {Previous studies suggested that emotions can be correctly interpreted from facial expressions in the absence of conscious awareness of the face. Our goal was to explore whether subordinate information about a face's gender and race could also become available without awareness of the face. Participants classified the race or the gender of unfamiliar faces that were ambiguous with regard to these dimensions. The ambiguous faces were preceded by face-images that unequivocally represented gender and race, rendered consciously invisible by simultaneous continuous-flash-suppression. The classification of ambiguous faces was biased away from the category of the adaptor only when it was consciously visible. The duration of subjective visibility correlated with the aftereffect strength. Moreover, face identity was consequential only if consciously perceived. These results suggest that while conscious awareness is not needed for basic level categorization, it is needed for subordinate categorization. Emotional information might be unique in this respect.},
}
@article{moroi_comparison_1975,
}
@article{baldassano_decoding_2011,
	abstract = {Contextual violations have long been known to cause deficits in object detection and recognition (Biederman et al., 1982). Incongruent objects attract earlier and longer eye fixations (Underwood \& Foulsham 2006) and evoke stronger {ERPs} (Mudrik, Lamy, and Deuoell 2010), suggesting that the brain rapidly marshals additional resources to aid in processing unexpected objects. Despite a wealth of psychophysical results on context, cortical models of contextual facilitation are still speculative (Bar, 2004). In this study, we use {MVPA} methods with {fMRI} data to explore the effects of context on neural representations. {MVPA} allows us to assess the quality of the representation as opposed to simple changes in overall activity afforded by more traditional {fMRI} analysis methods.
}
@article{chao_experience-dependent_2002,
	abstract = {Naming pictures of objects from different categories (e.g. animals or tools) evokes maximal responses in different brain regions. However, these 'category-specific' regions typically respond to other object categories as well. Here we used stimulus familiarity to further investigate category representation. Naming pictures of animals and tools elicited category-related activity in a number of previously identified regions. This activity was reduced for familiar relative to novel stimuli. Reduced activation occurred in all object responsive areas in the ventral occipito-temporal cortex, regardless of which category initially produced the maximal response. This suggests that object representations in the ventral occipito-temporal cortex are not limited to a discrete area, but rather are widespread and overlapping. In other regions (e.g. the lateral temporal and left premotor cortices), experience-dependent reductions were category specific. Together, these findings suggest that category-related activations reflect the retrieval of information about category-specific features and attributes.},
}
@article{solomon_chromatic_2005,
	abstract = {Although the response of a neuron in the visual cortex generally grows nonlinearly with contrast, the spatial tuning of the cell remains stable. This is thought to reflect the activity of a contrast gain control (``normalization'') that has very broad tuning on the relevant stimulus dimension. Contrast invariant tuning on a particular dimension is probably necessary for reliable representation of stimuli on that dimension. In the lateral geniculate nucleus ({LGN)}, V1, and V2 of anesthetized macaque, we measured chromatic tuning of neurons at several contrasts to characterize the gain controls and identify cells that might be important for representing color. We estimated separately the chromatic signature of the linear receptive field and that of the gain control. In the {LGN}, we found normalization in magnocellular cells and cells receiving excitatory S-cone input but not in parvocellular cells or those receiving inhibitory S-cone input. We found normalization in all types of cortical neurons. Among cells that preferred achromatic modulation, or modulation along intermediate directions in color space (making them responsive to both achromatic and chromatic stimuli), normalization was driven by mechanisms tuned to a restricted range of directions in color space, close to achromatic. As a result, chromatic tuning varied with contrast. Among the relatively few cells that strongly preferred chromatic modulation, normalization was driven by mechanisms sensitive to modulation along all directions in color space, especially isoluminant. As a result, chromatic tuning changed little with contrast. To the extent that contrast invariant tuning is important in representing chromaticity, relatively few cortical neurons are involved.},
}
@article{bradley_implicit_1995,
	abstract = {Implicit and explicit memory biases were assessed in clinically depressed (n = 19), clinically anxious (n = 17), and normal control (n = 18) Ss. The implicit memory test was a primed lexical decision task, with anxiety- and depression-relevant words, and suprathreshold and subthreshold primes. The explicit memory test was incidental free recall of self-referenced words. The depressed group showed greater suprathreshold and subthreshold priming effects for depression words, and recalled more depression words, than the other two groups. These results suggest that clinical depression, but not clinical anxiety, is associated with mood-congruent biases in both automatic and strategic memory processes.},
}
@article{brock_language_2007,
	abstract = {Williams syndrome is a rare genetic disorder in which, it is claimed, language abilities are relatively strong despite mild to moderate mental retardation. Such claims have, in turn, been interpreted as evidence either for modular preservation of language or for atypical constraints on cognitive development. However, this review demonstrates that there is, in fact, little evidence that syntax, morphology, phonology, or pragmatics are any better than predicted by nonverbal ability, although performance on receptive vocabulary tests is relatively good. Similarly, claims of an imbalance between good phonology and impaired or atypical lexical semantics are without strong support. There is, nevertheless, consistent evidence for specific deficits in spatial language that mirror difficulties in nonverbal spatial cognition, as well as some tentative evidence that early language acquisition proceeds atypically. Implications for modular and neuroconstructivist accounts of language development are discussed.},
}
@article{schwartz_naturalistic_1998,
	abstract = {The authors sought to determine whether errors of action committed by patients with closed head injury ({CHI)} would conform to predictions derived from frontal lobe theories. In Study 1, 30 {CHI} patients and 18 normal controls performed routine activities, such as wrapping a present, under conditions of graded complexity. {CHI} patients committed more errors even on the simplest condition; but, except for a higher proportion of omitted actions, their error profile was very similar to that of controls. Study 2 involved a subset of patients whose performance in Study 1 was within normal limits. When these high functioning patients were asked to perform the routine tasks under still more taxing conditions, they, too, committed errors in excess of the control group. Accounts based on frontal mechanisms have a difficult time explaining the overall pattern of findings. An alternative based on limited-capacity resources is suggested.},
}
@article{de_valois_spatial_1982,
	abstract = {We measured the spatial frequency contrast sensitivity of cells in the primate striate cortex at two different eccentricities to provide quantitative statistics from a large population of cells. Distributions of the peak frequencies and bandwidths are presented and examined in relationship to (a) each other, (b) absolute contrast sensitivity, (c) orientation tuning, (d) retinal eccentricity, and (e) cell type. Simple and complex cells are examined in relationship to linear/nonlinear (that is, {X/Y)} properties; a procedure is described which provides a simple, reliable and quantitative method for classifying and describing striate cells. Among other things, it is shown that (a) many striate cells have quite narrow spatial bandwidths and (b) at a given retinal eccentricity, the distribution of peak frequency covers a wide range of frequencies; these findings support the basic multiple channel notion. The orientation tuning and spatial frequency tuning which occurs at the level of striate cortex (in a positively correlated fashion) suggests that the cells might best be considered as two-dimensional spatial filters.},
}
@article{mandler_concept_1993,
	abstract = {Four experiments investigated conceptual categorization in 7- to 11-month-old infants. Experiments 1 and 2 showed that 9-and 11-month-olds differentiated the global domains of animals and vehicles. Within the animal domain no subcategorization was found: the infants did not differentiate dogs from fish or from rabbits. Within the vehicle domain infants differentiated cars from both airplanes and motorcycles. Experiment 3 showed similar, although weaker, categorization for 7-month-olds. Experiment 4 showed that categorization of animals and vehicles was unaffected by degree of between-category similarity. Birds and airplanes were treated as different even though the exemplars from both categories had similar shapes, including outstretched wings, and were of the same texture. These data, showing global differentiation of animals and vehicles, with lack of differentiation of ``basic-level'' categories within the animal domain, contrast with data from studies designed to assess perceptual categorization. Even younger infants differentiate various animal subcategories perceptually. However, the results presented here suggest that infants may not respond to such perceptual differences as being conceptually relevant.},
}
@article{maquet_experience-dependent_2000,
}
@inproceedings{wang_training_2003,
	abstract = {We consider learning to classify cognitive states of human subjects,  based on their brain activity observed via functional Magnetic Resonance  Imaging ({fMRI).} This problem is important because such classifiers constitute  "virtual sensors" of hidden cognitive states, which may be useful  in cognitive science research and clinical applications. In recent work,  Mitchell, et al. [6,7,9] have demonstrated the feasibility of training such  classifiers for individual human subjects (e.g., to distinguish whether the  subject is reading an ambiguous or unambiguous sentence, or whether  they are reading a noun or a verb). Here we extend that line of research,  exploring how to train classifiers that can be applied across multiple human  subjects, including subjects who were not involved in training the  classifier. We describe the design of several machine learning approaches  to training multiple-subject classifiers, and report experimental results  demonstrating the success of these methods in learning cross-subject  classifiers for two different {fMRI} data sets.},
}
@article{hanazawa_neural_2000,
	abstract = {In the inferior temporal ({IT)} cortex of monkeys, which has been shown to play a critical role in colour discrimination, there are neurons sensitive to a narrow range of hues and saturation. By contrast, neurons in the retina and the parvocellular layer of the lateral geniculate nucleus ({pLGN)} encode colours in a way that does not provide explicit representation of hue or saturation, and the process by which hue- and saturation-selectivity is elaborated remains unknown. We therefore tested the colour-selectivity of neurons in the primary visual cortex (V1) and compared it with those of {pLGN} and {IT} neurons. Quantitative analysis was performed using a standard set of colours, systematically distributed within the {CIE} (Commission Internationale de {l'Eclairage)-xy} chromaticity diagram. Selectivity for hue and saturation was characterized by analysing response contours reflecting the overall distribution of responses across the chromaticity diagram. We found that the response contours of almost all {pLGN} neurons were linear and broadly tuned for hue. Many V1 neurons behaved similarly; nonetheless, a considerable number of V1 neurons had clearly curved response contours and were selective for a narrow range of hues or saturation. The relative frequencies of neurons exhibiting various selectivities for hue and saturation were remarkably similar in the V1 and {IT} cortex, but were clearly different in the {pLGN.} Thus, V1 apparently plays a very important role in the conversion of colour signals necessary for generating the elaborate colour selectivity observed in the {IT} cortex.},
}
@incollection{patterson_connections_1989,
	abstract = {describe a new, parallel distributed processing ({PDP)} model of visual word recognition and pronunciation, the acquisition of these skills, and their breakdown following brain injury / the model consists of a working, computational simulation of the process of learning to recognize and pronounce written words provide an overview of the model, describing its basic structure and operation / summarize the model's account of the task of naming words aloud / main focus of this paper concerns our initial explorations of the model's potential to account for certain reading disorders that are observed following brain injury model provides a plausible account of some basic phenomena concerning normal performance / sought to determine whether aspects of pathological performance could be captured in terms of damage to this system},
}
@article{hino_ambiguity_2002,
	abstract = {In this article, ambiguity and synonymy effects were examined in lexical decision, naming, and semantic categorization tasks. Whereas the typical ambiguity advantage was observed in lexical decision and naming, an ambiguity disadvantage was observed in semantic categorization. In addition, a synonymy effect (slower latencies for words with many synonyms than for words with few synonyms) was observed in lexical decision and naming but not in semantic categorization. These results suggest that (a) an ambiguity disadvantage arises only when a task requires semantic processing, (b) the ambiguity advantage and the synonymy disadvantage in lexical decision and naming are due to semantic feedback, and (c) these effects are determined by the nature of the feedback relationships from semantics to orthography and phonology. ({PsycINFO} Database Record (c) 2010 {APA}, all rights reserved)},
}
@article{turner_generating_1999,
	abstract = {Tasks of fluency tap the ability to generate multiple responses spontaneously following a single cue or instruction. The present study compared the fluency performance of subjects with autism and clinical control subjects at two diffierent levels of ability (high-functioning subjects with a verbal {IQ} of 76 or greater, and globally learning disabled subjects with a verbal {IQ} of 74 or below). A battery of tasks was employed to assess subjects' word fluency (for letters and semantic categories), ideational fluency (for uses of objects and interpretations of meaningless line drawings), and design fluency (for abstract meaningless designs). Subjects with autism showed reduced fluency for both the word and ideational fluency tasks, generating significantly fewer responses than the clinical control {subjects.Results} were particularly striking for the ideational fluency tasks. On these tasks, autistic subjects produced very low response totals, with the performance of the high-functioning subjects with autism equivalent to that of the learning disabled subjects with autism and significantly inferior to that of the learning disabled control individuals. In contrast, the results of the design fluency paradigm paint a different picture. This paradigm revealed no significant difference in the quantity of designs generated by the subjects with autism and the control subjects but a clear qualitative difference, with the autistic group producing significantly higher rates of disallowed and perseverative responses. Whilst the results of the word and ideational fluency tasks are suggested to support the hypothesis that individuals with autism are impaired in the generation of novel responses and behaviour, the results of the design fluency task are equally consistent with an impairment in the regulation of behaviour through inhibition and/or monitoring. The implications of these findings for the study of executive function abilities in autism are discussed.},
}
@article{pelekanos_effects_2012,
	abstract = {Binocular rivalry ({BR)} is a phenomenon in which visual perception alternates between two different monocular stimuli. There has been a long debate regarding its nature, with a special emphasis on whether low- or high-level mechanisms are involved. Prior adaptation to one of the two monocular stimuli is known to affect initial dominance in the subsequent dichoptic presentation. In the present work, we have used three different types of adaptation in order to investigate how each one affects initial dominance during {BR.} In the first adaptation type, adapting to a stimulus identical to the one used during rivalry has led to its consequent suppression, verifying previous findings. The binocular presentation which we have used excludes the possibility of eye-adaptation, suggesting that it is the specific stimulus that the brain adapts to. In the second adaptation type, we find suppression effects following adaptation to stimuli belonging to the same category (face or house) but are different from the specific ones used in the following {BR} presentation. In the final adaptation type, in which the words ``face'' or ``house'' are used as adaptors, no statistically significant effect was found. These results suggest that perceptual selection can be directly influenced by the prior presentation of visual stimuli different to the ones used during {BR}, and thus support a higher-level, cognitive influence on the latter.},
}
@article{goldin-meadow_gestures_2013,
	abstract = {When speakers talk, they gesture. The goal of this chapter is to understand the contribution that these gestures make to how we communicate and think. Gesture can play a role in communication and thought at many timespans. We explore, in turn, gesture's contribution to how language is produced and understood in the moment; its contribution to how we learn language and other cognitive skills; and its contribution to how language is created over generations, over childhood, and on-the-spot. We find that the gestures speakers produce when they talk are integral to communication and can be harnessed in a number of ways. (1) Gesture reflects speakers' thoughts, often their unspoken thoughts, and thus can serve as a window onto cognition. Encouraging speakers to gesture can thus provide another route for teachers, clinicians, interviewers, etc., to better understand their communication partners. (2) Gesture can change speakers' thoughts. Encouraging gesture thus has the potential to change how students, patients, witnesses, etc., think about a problem and, as a result, alter the course of learning, therapy, or an interchange. (3) Gesture provides building blocks that can be used to construct a language. By watching how children and adults who do not already have a language put those blocks together, we can observe the process of language creation first hand. Our hands are with us at all times and thus provide researchers and learners with an ever-present tool for understanding how we talk and think.},
}
@article{dave_song_2000,
	abstract = {Songbirds learn a correspondence between vocal-motor output and auditory feedback during development. For neurons in a motor cortex analog of adult zebra finches, we show that the timing and structure of activity elicited by the playback of song during sleep matches activity during daytime singing. The motor activity leads syllables, and the matching sensory response depends on a sequence of typically up to three of the preceding syllables. Thus, sensorimotor correspondence is reflected in temporally precise activity patterns of single neurons that use long sensory memories to predict syllable sequences. Additionally, ``spontaneous'' activity of these neurons during sleep matches their sensorimotor activity, a form of song ``replay.'' These data suggest a model whereby sensorimotor correspondences are stored during singing but do not modify behavior, and off-line comparison (e.g., during sleep) of rehearsed motor output and predicted sensory feedback is used to adaptively shape motor output.},
}
@article{patterson_where_2007,
}
@article{wnuczko_when_2012-1,
}
@article{heider_probabilities_1972,
}
@article{kersten_object_2004,
	abstract = {We perceive the shapes and material properties of objects quickly and reliably despite the complexity and objective ambiguities of natural images. Typical images are highly complex because they consist of many objects embedded in background clutter. Moreover, the image features of an object are extremely variable and ambiguous owing to the effects of projection, occlusion, background clutter, and illumination. The very success of everyday vision implies neural mechanisms, yet to be understood, that discount irrelevant information and organize ambiguous or noisy local image features into objects and surfaces. Recent work in Bayesian theories of visual perception has shown how complexity may be managed and ambiguity resolved through the task-dependent, probabilistic integration of prior object knowledge with image features.},
}
@article{devlin_anatomic_2002,
	abstract = {Many cognitive theories of semantic organization stem from reports of patients with selective, category-specific deficits for particular classes of objects (e.g., fruit). The anatomical assumptions underlying the competing claims can be evaluated with functional neuroimaging but the findings to date have been inconsistent and insignificant when standard statistical criteria are adopted. We hypothesized that category differences in functional brain responses might be small and task dependent. To test this hypothesis, we entered data from seven {PET} studies into a single multifactorial design which crossed category (living vs man-made) with a range of tasks. Reliable category-specific effects were observed but only for word retrieval and semantic decision tasks. Living things activated medial aspects of the anterior temporal poles bilaterally while tools activated a left posterior middle temporal region. These category-by-task interactions provide robust evidence for an anatomical double dissociation according to category and place strong constraints on cognitive theories of the semantic system. Furthermore they reconcile some of the apparent inconsistencies between lesion studies and functional neuroimaging data.},
}
@article{xu_mapping_2010,
	abstract = {Pattern recognition methods have become increasingly popular in {fMRI} data analysis, which are powerful in discriminating between multi-voxel patterns of brain activities associated with different mental states. However, when they are used in functional brain mapping, the location of discriminative voxels varies significantly, raising difficulties in interpreting the locus of the effect. Here we proposed a hierarchical framework of multivariate approach that maps informative clusters rather than voxels to achieve reliable functional brain mapping without compromising the discriminative power. In particular, we first searched for local homogeneous clusters that consisted of voxels with similar response profiles. Then, a multi-voxel classifier was built for each cluster to extract discriminative information from the multi-voxel patterns. Finally, through multivariate ranking, outputs from the classifiers were served as a multi-cluster pattern to identify informative clusters by examining interactions among clusters. Results from both simulated and real {fMRI} data demonstrated that this hierarchical approach showed better performance in the robustness of functional brain mapping than traditional voxel-based multivariate methods. In addition, the mapped clusters were highly overlapped for two perceptually equivalent object categories, further confirming the validity of our approach. In short, the hierarchical framework of multivariate approach is suitable for both pattern classification and brain mapping in {fMRI} studies.},
}
@article{tong_decoding_2012,
	abstract = {Considerable information about mental states can be decoded from noninvasive measures of human brain activity. Analyses of brain activity patterns can reveal what a person is seeing, perceiving, attending to, or remembering. Moreover, multidimensional models can be used to investigate how the brain encodes complex visual scenes or abstract semantic information. Such feats of ``brain reading'' or ``mind reading,'' though impressive, raise important conceptual, methodological, and ethical issues. What does successful decoding reveal about the cognitive functions performed by a brain region? How should brain signals be spatially selected and mathematically combined to ensure that decoding reflects inherent computations of the brain rather than those performed by the decoder? We highlight recent advances and describe how multivoxel pattern analysis can provide a window into mind-brain relationships with unprecedented specificity, when carefully applied. However, as brain-reading technology advances, issues of neuroethics and mental privacy will be important to consider.},
}
@article{pereira_machine_2009,
	abstract = {Interpreting brain image experiments requires analysis of complex, multivariate data. In recent years, one analysis approach that has grown in popularity is the use of machine learning algorithms to train classifiers to decode stimuli, mental states, behaviours and other variables of interest from {fMRI} data and thereby show the data contain information about them. In this tutorial overview we review some of the key choices faced in using this approach as well as how to derive statistically significant results, illustrating each point from a case study. Furthermore, we show how, in addition to answering the question of 'is there information about a variable of interest' (pattern discrimination), classifiers can be used to tackle other classes of question, namely 'where is the information' (pattern localization) and 'how is that information encoded' (pattern characterization).},
}
@article{schmoldt_digitoxin_1975,
}
@article{howard_direct_1996,
	abstract = {Background Physiological studies of the macaque brain have shown that there is a large expanse of visual cortex, the V5 complex, which is specialized for visual motion, and that several areas within V5 are specialized for different kinds of visual motion. In continuing work on motion-related visual cortex, we wished to chart the specialized visual motion areas in the human brain and to determine their anatomical relationship. Human subjects viewed different motion displays, and the cortical location of the increased activity produced by each stimulus was recorded. The technique of functional magnetic resonance imaging ({fMRI)} was used, in order to image the same subjects repeatedly. Results We found that each of the three motion stimuli activated specific parts of the V5 complex. These sites of activation overlap with V5 and, to a smaller extent, with each other. Unexpectedly, the three motion stimuli also activated neighbouring, but nonoverlapping, regions of auditory cortex that are normally activated by the perception of speech. Conclusions The three sites of activation produced by the visual motion stimuli occupy adjacent territories within the V5 complex. Components of the V5 complex are specifically connected to regions within auditory cortex.},
}
@article{sugita_experience_2004,
	abstract = {Early visual experience is indispensable to shape the maturation of cortical circuits during development [1]. Monocular deprivation in infancy, for instance, leads to an irreversible reduction of visually driven activity in the visual cortex through the deprived eye and a loss of binocular depth perception [2--4]. It was tested whether or not early experience is also necessary for color perception. Infant monkeys were reared for nearly a year in a separate room where the illumination came from only monochromatic lights. After extensive training, they were able to perform color matching. But, their judgment of color similarity was quite different from that of normal animals. Furthermore, they had severe deficits in color constancy; their color vision was very much wavelength dominated, so they could not compensate for the changes in wavelength composition. These results indicate that early visual experience is also indispensable for normal color perception.},
}
@article{barbieri_executive_1988,
	abstract = {Fifty six left brain-damaged ({LBD)} patients and 38 right brain-damaged ({RBD)} patients were requested to perform two measures of praxis using the hand ipsilateral to the side of lesion. One task required the accurate imitation of actions made by the examiner and taxed executive abilities; the other task required the patient to pantomime the use of objects that were shown, but not handed, and it also involved an ideational component, i.e., the evocation of gestures. The cut-off point discriminating a normal from a pathological performance was set at the level of the poorest score found in 60 control patients. On both tests apraxia was found to be associated primarily with left brain-damage. However, while on the use of objects test practically only {LBD} patients failed, on the imitation test there was also a sizeable proportion of {RBD} patients who showed a mild apraxia. When the performance on the two tests was contrasted, there were as many {LBD} patients as {RBD} patients who scored remarkably lower on movement imitation than on pantomiming the use of objects, whereas the opposite dissociation was found almost exclusively in {LBD} patients. We infer from these data that the left hemisphere dominance for praxis is more marked at the ideational stage and that there is also a minor right hemisphere participation in the control of the executive stage of gesture.},
}
@article{ozgen_acquisition_2002,
	abstract = {Color perception can be categorical: Between-category discriminations are more accurate than equivalent within-category discrimination. The effects could be inherited, learned, or both. The authors provide evidence that supports the possibility of learned categorical perception ({CP).} Experiment 1 demonstrated that observers' color discrimination is flexible and improves through repeated practice. Experiment 2 demonstrated that category learning simulates effects of "natural" color categories on color discrimination. Experiment 3 investigated the time course of acquired {CP.} Experiment 4 found that {CP} effects are acquired through hue- and lightness-based category learning and obtained interesting data on the dimensional perception of color. The data are consistent with the possibility that language may shape color perception and suggest a plausible mechanism for the linguistic relativity hypothesis.},
}
@article{walsh_effects_1992,
	abstract = {Monkeys with V4 lesions and unoperated controls were tested behaviourally for their perception of the colour categories red, green, blue and yellow. As expected, the monkeys with V4 lesions took longer to acquire the colour discriminations. However, the pattern of learning was the same in the two groups of animals. Both the lesioned and the control animals made more errors when the stimuli to be discriminated belonged to the same colour category than when they belonged to different categories and thus showed normal colour categorization. The results suggest that monkeys with V4 lesions perceive the colour spectrum according to the same fundamental perceptual categories as normal monkeys and humans, and thus support the view that, in the colour domain, the four basic perceptual categories are constructed by chromatic mechanisms operating earlier than visual area V4.},
}
@article{uchikawa_influence_1989,
	abstract = {Color samples selected from the {OSA} Uniform Color Scales set were seen isolated in a dark field, illuminated by hidden projectors. These appeared as self-luminous aperture colors when thus isolated. We employed a categorical color-naming procedure to assess color appearance. Achromatic surrounds of 33 min width, if adjacent to samples subtending about 2.2 deg, were sufficient to render normal categorical surface-color perception. As the size of surrounds decreased, color naming shifted from that normally observed in the surface-color mode to that appropriate to the aperture-color mode. For isolated samples, brown was almost never seen, being most often replaced by orange; a white border less than one-sixtieth the width of the color samples was sufficient to restore its perception in an otherwise dark field. The reflectance of the surround and the gap between test and surround stimuli were also examined and found to be important factors in surface color perception, whereas the overall luminance level was not.},
}
@article{mcclelland_rules_2002,
	abstract = {Pinker and colleagues propose two mechanisms -- a rule system and a lexical memory -- to form past tenses and other inflections. They predict that children's acquisition of the regular inflection is sudden; that the regular inflection applies uniformly regardless of phonological, semantic or other factors; and that the rule system is separably vulnerable to disruption. A connectionist account makes the opposite predictions. Pinker has taken existing evidence as support for his theory, but the review of the evidence presented here contradicts this assessment. Instead, it supports all three connectionist predictions: gradual acquisition of the past tense inflection; graded sensitivity to phonological and semantic content; and a single, integrated mechanism for regular and irregular forms, dependent jointly on phonology and semantics.},
}
@article{hoffman_ventrolateral_2010,
	abstract = {Neuroimaging studies reliably reveal ventrolateral prefrontal cortex ({VLPFC)} activation for processing of abstract relative to concrete words, but the cause of this effect is unclear. Here, in a convergent neuropsychological and repetitive transcranial magnetic stimulation ({rTMS)} investigation, we tested the hypothesis that abstract words require {VLPFC} because they depend heavily on the semantic--executive control processes mediated by this region. Specifically, we hypothesized that accessing the meanings of abstract words require more executive regulation because they have variable, context-dependent meanings. In the neuropsychology component of the study, aphasic patients with multimodal semantic deficits following {VLPFC} lesions had impaired comprehension of abstract words, but this deficit was ameliorated by providing a sentence cue that placed the word in a specific context. Concrete words were better comprehended and showed more limited benefit from the cues. In the second part of the study, {rTMS} applied to left {VLPFC} in healthy subjects slowed reaction times to abstract but not concrete words, but only when words were presented out of context. {TMS} had no effect when words were preceded by a contextual cue. These converging results indicate that {VLPFC} plays an executive regulation role in the processing of abstract words. This role is less critical when words are presented with a context that guides the system toward a particular meaning or interpretation. Regulation is less important for concrete words because their meanings are constrained by their physical referents and do not tend to vary with context.},
}
@article{martens_specifying_2009,
	abstract = {Classical theories assume that unconscious automatic processes are autonomous and
}
@article{rodd_making_2002,
	abstract = {There have been several reports in the literature of faster visual lexical decisions to words that are semantically ambiguous. All current models of this ambiguity advantage assume that it is the presence of multiple unrelated meanings that produce this benefit. A set of three lexical decision experiments reported here challenge this assumption. We contrast the ambiguity seen in words like bark, which have multiple unrelated meanings, with words that have multiple related word senses (e.g., twist). In all three experiments we find that while multiple word senses do produce faster responses, ambiguity between multiple meanings delays recognition. These results suggest that, while competition between the multiple meanings of ambiguous words delays their recognition, the rich semantic representations associated with words with many senses facilitate their recognition.},
}
@article{gehler_mannosidosis:_1975,
}
@article{eichenbaum_what_2012,
	abstract = {Studies on {H.M.} generated five main findings: that memory is a distinct psychological function, that amnesia spares short-term and working memory, that amnesia is an impairment of declarative and episodic memory, that the hippocampus is a core brain structure supporting memory, and that the hippocampus supports the permanent consolidation of memories. Each of these basic findings has recently been challenged, but a consideration of these studies suggests the new observations serve to support the original findings on {H.M.} and improve our understanding of the memory functions of the hippocampal system.},
}
@article{smith_metal_1975-1,
}
@article{walker_sleep_2006,
	abstract = {Although the functions of sleep remain largely unknown, one of the most exciting hypotheses is that sleep contributes importantly to processes of memory and brain plasticity. Over the past decade, a large body of work, spanning most of the neurosciences, has provided a substantive body of evidence supporting this role of sleep in what is becoming known as sleep-dependent memory processing. We review these findings, focusing specifically on the role of sleep in (a) memory encoding, (b) memory consolidation, (c) brain plasticity, and (d) memory reconsolidation; we finish with a summary of the field and its potential future directions.},
}
@book{rogers_semantic_2004,
}
@article{schindler_automatic_2004,
	abstract = {When we reach out to pick something up, our arm is directed to the target by visuomotor networks in the cortical dorsal stream. However, our reach trajectories are influenced also by nontarget objects, which might be construed as potential obstacles. We tested two patients with bilateral dorsal-stream (parietal lesions, both of whom were impaired at pointing to visual stimuli (optic ataxia). We asked them to reach between two cylinders, which varied in location from trial to trial. We found that the patients' reaches remained invariant with changes in obstacle location. In a control task when they were asked to point midway between the two objects, however, their responses shifted in an orderly fashion. We conclude that the dorsal stream provides the visual guidance we automatically build into our movements to avoid potential obstacles, as well as that required to ensure arrival at the target.},
}
@article{moss_weighing_2003,
}
@incollection{glenberg_mental_1997,
	abstract = {language comprehension is a creative act; there is little that is transparent between words and meaning / instead, meaning is the result of a creative, constructive process / begin by justifying this claim / take 2 swipes at figuring out how meanings are created from words / both of these swipes are based on the notion of mental models as cognitive constructions that underlie comprehension / the 1st swipe treats mental models as constructions in an analog of Euclidean space / this sort of mental model provides a type of inference engine for some creative acts involved in language comprehension / the 2nd swipe considers mental models to be embodied / on an embodied account of meaning, understanding is in terms of the bodily, physical actions available to animals living in a 3-dimensional world},
}
@article{gottesmann_neurophysiological_1999,
	abstract = {The aim of this review was to try to establish the current neurophysiological knowledge capable of explaining the differences of mental functioning during the different stages of sleep and waking. The analysis focused on the cortical state. Waking is characterized by electrophysiological activities (low voltage and gamma range {EEG} field patterns, unitary activities) and cerebral blood flow reflecting an activated state. On the contrary, neurochemical influences are marked by inhibitory afferent processes since dopamine, noradrenaline, serotonine and histamine tend, for the most part, to inhibit cortical neurons by diffuse release at the level of varicosities. During slow wave sleep, all these brain stem influences sustaining the cortical state decrease and transiently disappear just prior to onset of {REM} sleep. During {REM} sleep, pontine and mesopontine ascending activating influences invade the cortex in their turn while neurochemical inhibitory influences disappear with the exception of dopaminergic ones. We hypothesize that the activating influences acting on the cortex allow the latter to function, just as petrol makes an engine run, but that the diffuse inhibitory influences somehow regulate cortex functioning. Therefore, it is understandable that, during waking, mental activity is reflective and rational, and that psychological content is less intense during slow wave sleep. During {REM} sleep, the activated and mostly disinhibited state might induce the characteristic dream activity which appear to be rather ill-considered and illogical. Persistent dopaminergic input combined with the absence of noradrenergic input may induce psychological activities somewhat similar to those related to psychotic syndromes. Deactivation of part of the prefrontal cortex could contribute to this unusual mental activity.},
}
@article{carota_body-part-specific_2012,
	abstract = {Word meaning processing in the brain involves ventrolateral temporal cortex, but a semantic contribution of the dorsal stream, especially frontocentral sensorimotor areas, has been controversial. We here examine brain activation during passive reading of object-related nouns from different semantic categories, notably animal, food, and tool words, matched for a range of psycholinguistic features. Results show ventral stream activation in temporal cortex along with category-specific activation patterns in both ventral and dorsal streams, including sensorimotor systems and adjacent {pFC.} Precentral activation reflected action-related semantic features of the word categories. Cortical regions implicated in mouth and face movements were sparked by food words, and hand area activation was seen for tool words, consistent with the actions implicated by the objects the words are used to speak about. Furthermore, tool words specifically activated the right cerebellum, and food words activated the left orbito-frontal and fusiform areas. We discuss our results in the context of category-specific semantic deficits in the processing of words and concepts, along with previous neuroimaging research, and conclude that specific dorsal and ventral areas in frontocentral and temporal cortex index visual and affective--emotional semantic attributes of object-related nouns and action-related affordances of their referent objects.},
}
@article{grossman_category-specific_2013,
	abstract = {Abstract 
}
@article{tranel_neural_2001,
	abstract = {Although much has been learned in recent years about the neural basis for retrieving words denoting concrete entities, the neural basis for retrieving words denoting actions remains poorly understood. We addressed this issue by testing two specific anatomical hypotheses. (1) Naming of actions depends not only on the classical implementation structures of the left frontal operculum, but also on mediational structures located in left premotor/prefrontal areas. (2) The neural systems subserving naming of actions and naming of concrete entities are segregated. The study used the lesion method and involved 75 subjects with focal, stable lesions in the left or right hemispheres, whose magnetic resonance data were analysed with a three-dimensional reconstruction method. The experimental tasks were standardised procedures for measuring action and object naming. The findings offered partial support for the hypotheses, in that: (1) lesions related to impaired action naming overlapped maximally in the left frontal operculum and in the underlying white matter and anterior insula; and (2) lesions of the left anterior temporal and inferotemporal regions, which produce impairments in naming of concrete entities, did not cause action naming deficits. A follow-up analysis indicated that action naming impairments, especially when they were disproportionate relative to concrete entity naming impairments, were not only associated with premotor/prefrontal lesions, but also with lesions of the left mesial occipital cortex and of the paraventricular white matter underneath the supramarginal and posterior temporal regions.},
}
@article{gagnon_origins_1997,
	abstract = {Accounts of spoken word production differ on whether aphasics' formal paraphasias derive solely from segmental distortion or whether some derive instead from whole word substitution. Form-related paraphasias produced by nine aphasics during picture naming were examined for evidence of lexical effects (word, frequency, and grammatical class biases) and for the manner in which target phonemes and word shape were preserved. Preservation patterns were consistent with previous descriptions of aphasic and nonaphasic form-related speech errors. Evidence for word and frequency biases was found, as well as a grammatical class bias sensitive to the degree of target--response segmental overlap. In conjunction, the results indicate that formal paraphasias arise, at least in part, via word substitution. The findings are supportive of interactive models with phonological-to-lemma feedback and/or modular models with a grammatically organized lexeme level.},
}
@article{zubairov_[blood_1976,
	abstract = {Trypsin, thrombin, fibrinolysin, papain, chymothrypsin and urokinase were immobilized on aminopolystyrene resin by the reaction of diazocoupling. An activation of prothrombin and plasminogen and also hydrolysis of fibrin by immobilized enzymes were studied. The immobilized enzymes hydrolyzed N-benzoyl-1-arginine ethyl ester and L-tyrosine ethyl ester. The only preparation of immobilized thrombin possessed the coagulational activity. After the covalent binding trypsin and plasmin maintained the capacity to cause a fibrinolysis. Immobilized trypsin, plasmin, papain, chymotrypsin and urokinase exhibited the fibrinolytic effect due to convertion of plasminogen into plasmin.},
}
@article{buxbaum_subtypes_1997,
	abstract = {Abstract Optic ataxia ({OA)} is a disorder of visually guided reaching which is usually attributed to a disconnection of visual information from motor systems. The traditional disconnection account, however, cannot explain the most common form of the disorder, in which misreaching occurs only when targets are presented in non-foveal vision and not when they are viewed directly. On the basis of data from two subjects, as well as recent physiological evidence, we offer a new account which can accommodate the 'non-foveal' subtype of {OA.} We suggest that the fundamental deficit in {OA} is a failure to transform spatio-motor information into frames of reference appropriate to the reaching apparatus, that is, to code locations and actions within shoulder-, arm-, and hand-centered coordinate systems. We suggest that in the absence of normal spatio-motor transcoding, the accurate foveal reaching of some patients with {OA} may be accomplished by a pathologic linkage of systems mediating spatio-motor transformations for the eye and hand. This linkage permits patients with 'non-foveal' {OA} to reach accurately to locations at which they gaze, but not elsewhere.},
}
@article{friston_mixed-effects_2005,
	abstract = {This note concerns mixed-effect ({MFX)} analyses in multisession functional magnetic resonance imaging ({fMRI)} studies. It clarifies the relationship between mixed-effect analyses and the two-stage ``summary statistics'' procedure (Holmes, {A.P.}, Friston, {K.J.}, 1998. Generalisability, random effects and population inference. {NeuroImage} 7, S754) that has been adopted widely for analyses of {fMRI} data at the group level. We describe a simple procedure, based on restricted maximum likelihood ({ReML)} estimates of covariance components, that enables full mixed-effects analyses in the context of statistical parametric mapping. Using this procedure, we compare the results of a full mixed-effects analysis with those obtained from the simpler two-stage procedure and comment on the situations when the two approaches may give different results.},
}
@article{mummery2000voxel,
}
@article{mummery_voxel-based_2000,
	abstract = {The cortical anatomy of 6 patients with semantic dementia (the temporal lobe variant of frontotemporal dementia) was contrasted with that of a group of age-matched normal subjects by using voxel-based morphometry, a technique that identifies changes in gray matter volume on a voxel-by-voxel basis. Among the circumscribed regions of neuronal loss, the left temporal pole (Brodmann area 38) was the most significantly and consistently affected region. Cortical atrophy in the left hemisphere also involved the inferolateral temporal lobe (Brodmann area 20/21) and fusiform gyrus. In addition, the right temporal pole (Brodmann area 38), the ventromedial frontal cortex (Brodmann area 11/32) bilaterally, and the amygdaloid complex were affected, but no significant atrophy was measured in the hippocampus, entorhinal, or caudal perirhinal cortex. The degree of semantic memory impairment across the 6 cases correlated significantly with the extent of atrophy of the left anterior temporal lobe but not with atrophy in the adjacent ventromedial frontal cortex. These results confirm that the anterior temporal lobe is critically involved in semantic processing, and dissociate its function from that of the adjacent frontal region.},
}
@article{stein_breaking_2011,
	abstract = {Until recently, it has been thought that under interocular suppression high-level visual processing is strongly inhibited if not abolished. With the development of continuous flash suppression ({CFS)}, a variant of binocular rivalry, this notion has now been challenged by a number of reports showing that even high-level aspects of visual stimuli, such as familiarity, affect the time stimuli need to overcome {CFS} and emerge into awareness. In this ``breaking continuous flash suppression'' (b-{CFS)} paradigm, differential unconscious processing during suppression is inferred when (a) speeded detection responses to initially invisible stimuli differ, and (b) no comparable differences are found in non-rivalrous control conditions supposed to measure non-specific threshold differences between stimuli. The aim of the present study was to critically evaluate these assumptions. In six experiments we compared the detection of upright and inverted faces. We found that not only under {CFS}, but also in control conditions upright faces were detected faster and more accurately than inverted faces, although the effect was larger during {CFS.} However, reaction time ({RT)} distributions indicated critical differences between the {CFS} and the control condition. When {RT} distributions were matched, similar effect sizes were obtained in both conditions. Moreover, subjective ratings revealed that {CFS} and control conditions are not perceptually comparable. These findings cast doubt on the usefulness of non-rivalrous control conditions to rule out non-specific threshold differences as a cause of shorter detection latencies during {CFS.} Thus, at least in its present form, the b-{CFS} paradigm cannot provide unequivocal evidence for unconscious processing under interocular suppression. Nevertheless, our findings also demonstrate that the b-{CFS} paradigm can be fruitfully applied as a highly sensitive device to probe differences between stimuli in their potency to gain access to awareness.},
}
@article{bose_delineation_1975,
}
@article{klein_representation_2001,
	abstract = {Words that have a number of related senses are polysemous. For example, paper refers to both a substance and a publication printed on that substance. Five experiments investigated whether different senses are represented distinctly in the lexicon or if there is a common, core meaning. In all experiments, a polysemous word was used twice, in phrases that selected the same or different senses. Experiment 1 showed that sense consistency aided memory for the polysemous word. Experiment 2 extended this result to a timed sensicality judgment task. Experiment 3 demonstrated that the effects for polysemous words were very similar to those for homonyms. Experiment 4 ruled out the possibility of modifier-modifier priming. Experiment 5 showed that sense consistency facilitates comprehension relative to a neutral baseline, while sense inconsistency inhibits comprehension. These experiments provide evidence that polysemous words have separate representations for each sense and that any core meaning is minimal.},
}
@article{mirmiran_effects_1983,
	abstract = {In order to test the hypothesis that active sleep ({AS)} is important for the normal development of the central nervous system. 3 different deprivation methods were applied to male Wistar rat pups during the first month of life. Daily injection of clomipramine from 8 to 21 days of age reduced the high level of {AS} to less than the adult value throughout most of the experimental period. Administration of clonidine from 8 to 21 days of life induced an almost total suppression of {AS.} Instrumental deprivation, using the 'pendulum' method, led to a significant (but less severe) {AS} reduction during 2--4 weeks of postnatal age.
}
@article{warrington_category_1983,
}
@article{plaut_understanding_1996-1,
	abstract = {A connectionist approach to processing in quasi-regular domains, as exemplified by English word reading, is developed. Networks using appropriately structured orthographic and phonological representations were trained to read both regular and exception words, and yet were also able to read pronounceable nonwords as well as skilled readers. A mathematical analysis of a simplified system clarifies the close relationship of word frequency and spelling--sound consistency in influencing naming latencies. These insights were verified in subsequent simulations, including an attractor network that accounted for latency data directly in its time to settle on a response. Further analyses of the ability of networks to reproduce data on acquired surface dyslexia support a view of the reading system that incorporates a graded division of labor between semantic and phonological processes, and contrasts in important ways with the standard dual-route account.},
}
@article{cirelli_is_2008,
}
@article{lambon_ralph_coherent_2010,
	abstract = {In his Philosophical Investigations, Wittgenstein famously noted that the formation of semantic representations requires more than a simple combination of verbal and nonverbal features to generate conceptually based similarities and differences. Classical and contemporary neuroscience has tended to focus upon how different neocortical regions contribute to conceptualization through the summation of modality-specific information. The additional yet critical step of computing coherent concepts has received little attention. Some computational models of semantic memory are able to generate such concepts by the addition of modality-invariant information coded in a multidimensional semantic space. By studying patients with semantic dementia, we demonstrate that this aspect of semantic memory becomes compromised following atrophy of the anterior temporal lobes and, as a result, the patients become increasingly influenced by superficial rather than conceptual similarities.},
}
@article{doyon_distinct_2003,
	abstract = {This review paper focuses on studies in healthy human subjects that examined the functional neuroanatomy and cerebral plasticity associated with the learning, consolidation and retention phases of motor skilled behaviors using modern brain imaging techniques. Evidence in support of a recent model proposed by Doyon and Ungerleider [Functional Anatomy of Motor Skill Learning. In: Squire {LR}, Schacter {DL}, editors. Neuropsychology of Memory. New York: Guilford Press, 2002.] is also discussed. The latter suggests that experience-dependent changes in the brain depend not only on the stage of learning, but also on whether subjects are required to learn a new sequence of movements (motor sequence learning) or learn to adapt to environmental perturbations (motor adaptation). This model proposes that the cortico-striatal and cortico-cerebellar systems contribute differentially to motor sequence learning and motor adaptation, respectively, and that this is most apparent during the slow learning phase (i.e. automatization) when subjects achieve asymptotic performance, as well as during reactivation of the new skilled behavior in the retention phase.},
}
@article{olson_connectionist_1997,
	abstract = {Artificial neural networks ('connectionist models') embody aspects of real neuronal systems. But does studying the breakdown of performance in such models help us to understand cognitive impairments in humans following brain damage? Here we review recent attempts to capture different neuropsychological disorders using connectionist models with simulated lesions. We show how such lesion studies can be used to evaluate some of the standard assumptions made in neuropsychological research, concerning both double dissociations and associations between patterns of impairment. We also illustrate how lesioned models, like humans, can sometimes be more impaired on the easier of two tasks and demonstrate that connectionist models can incorporate forms of internal structure. Finally we discuss the utility of the models for understanding and predicting the effectiveness of different rehabilitation strategies. Future questions concern the role and possible development of internal structure within these models, whether the models can be generalized to larger-scale simulations, and whether they can accommodate higher-order linguistic disorders.},
}
@article{randerath_different_2010,
	abstract = {Tool use engages a left hemispheric network including frontal, temporal and parietal regions. Patients with left brain lesions ({LBD} patients) exhibit deficits when demonstrating use of a single tool (apraxia). When attempting to use a tool, some apraxic patients show errors in the preceding grasping movement. Forty-two {\{LBD\}} patients and 18 healthy controls grasped individual tools and demonstrated their typical use. For patients with a tool use impairment (22), lesion analysis revealed a large area of overlap in the left hemisphere, mainly in the supramarginal gyrus ({SMG).} For patients with erroneous grasping (12), the lesion overlay showed overlaps in the left frontal and parietal cortices, especially in the inferior frontal gyrus ({IFG)} and the angular gyrus ({ANG).} However, contrasting lesions associated with impaired grasping versus tool use impairments reveal little overlap, limited to the inferior parietal cortex. Presumably the left {\{IFG\}} is involved in selection processes in the context of tool use, such as choosing a functional or non-functional grasping movement depending on the task and the online information about the tool's structure and orientation. The {\{ANG\}} might provide this grasp related information, which is relevant for the specific action. The contribution of the {\{SMG\}} to tool use involves more general principals, such as integrating online and learned tool use information into the action plan for the use movement.},
}
@article{aminoff_role_2013,
	abstract = {The parahippocampal cortex ({PHC)} has been associated with many cognitive processes, including visuospatial processing and episodic memory. To characterize the role of {PHC} in cognition, a framework is required that unifies these disparate processes. An overarching account was proposed whereby the {PHC} is part of a network of brain regions that processes contextual associations. Contextual associations are the principal element underlying many higher-level cognitive processes, and thus are suitable for unifying the {PHC} literature. Recent findings are reviewed that provide support for the contextual associations account of {PHC} function. In addition to reconciling a vast breadth of literature, the synthesis presented expands the implications of the proposed account and gives rise to new and general questions about context and cognition.},
}
@article{lewis_overlapping_2011,
	abstract = {Sleep enhances integration across multiple stimuli, abstraction of general rules, insight into hidden solutions and false memory formation. Newly learned information is better assimilated if compatible with an existing cognitive framework or schema. This article proposes a mechanism by which the reactivation of newly learned memories during sleep could actively underpin both schema formation and the addition of new knowledge to existing schemata. Under this model, the overlapping replay of related memories selectively strengthens shared elements. Repeated reactivation of memories in different combinations progressively builds schematic representations of the relationships between stimuli. We argue that this selective strengthening forms the basis of cognitive abstraction, and explain how it facilitates insight and false memory formation.},
}
@article{yu_spatial_2010,
	abstract = {In light of anatomical evidence suggesting differential connection patterns in central vs. peripheral representations of cortical areas, we investigated the extent to which the response properties of cells in the primary visual area (V1) of the marmoset change as a function of eccentricity. Responses to combinations of the spatial and temporal frequencies of visual stimuli were quantified for neurons with receptive fields ranging from 3 degrees to 70 degrees eccentricity. Optimal spatial frequencies and stimulus speeds reflected the expectation that the responses of cells throughout V1 are essentially uniform, once scaled according to the cortical magnification factor. In addition, temporal frequency tuning was similar throughout V1. However, spatial frequency tuning curves depended both on the cell's optimal spatial frequency and on the receptive field eccentricity: cells with peripheral receptive fields showed narrower bandwidths than cells with central receptive fields that were sensitive to the same optimal spatial frequency. Although most V1 cells had separable spatial and temporal frequency tuning, the proportion of neurons displaying significant spatiotemporal interactions increased in the representation of far peripheral vision ({\textgreater} 50 degrees). In addition, of the fewer than 5\% of V1 cells that showed robust (spatial frequency independent) selectivity to stimulus speed, most were concentrated in the representation of the far periphery. Spatiotemporal interactions in the responses of many cells in the peripheral representation of V1 reduced the ambiguity of responses to high-speed ({\textgreater} 30 degrees/s) signals. These results support the notion of a relative specialization for motion processing in the far peripheral representations of cortical areas, including V1.},
}
@article{williams_physiological_1973,
}
@article{dozois_core_2012,
}
@article{chomsky_review_1959,
}
@article{gauthier_expertise_2000,
	abstract = {Expertise with unfamiliar objects ('greebles') recruits face-selective areas in the fusiform gyrus ({FFA)} and occipital lobe ({OFA).} Here we extend this finding to other homogeneous categories. Bird and car experts were tested with functional magnetic resonance imaging during tasks with faces, familiar objects, cars and birds. Homogeneous categories activated the {FFA} more than familiar objects. Moreover, the right {FFA} and {OFA} showed significant expertise effects. An independent behavioral test of expertise predicted relative activation in the right {FFA} for birds versus cars within each group. The results suggest that level of categorization and expertise, rather than superficial properties of objects, determine the specialization of the {FFA.}},
}
@article{humphreys_cascade_1988,
	abstract = {Abstract The naming of pictures is typically thought to require sequential access to stored structural knowledge about objects, to semantic knowledge, and to a stored phonological description. Access to these different types of knowledge may constitute discrete processing stages; alternatively, it may be that information is transmitted continuously (in cascade) from one type of description to the next. The discrete stage and the cascade accounts make different predictions about the effects of structural and semantic similarity between objects on picture naming. The discrete stage account maintains that the effects of structural similarity should be confined to the process of accessing an object's structural description, and the effects of semantic similarity should be confined to the process of accessing semantic knowledge. The cascade account predicts that the effect of both variables may be passed on to subsequent processing stages. We present evidence drawn from both normal observers and from a patient with an acquired disorder of picture naming, which supports the cascade model. The implications of such a model for understanding acquired disorders of visual object processing are discussed.},
}
@article{beauchamp_fmri_2003,
	abstract = {We used {fMRI} to study the organization of brain responses to different types of complex visual motion. In a rapid eventrelated design, subjects viewed video clips of humans performing different whole-body motions, video clips of manmade manipulable objects (tools) moving with their characteristic natural motion, point-light displays of human whole-body motion, and point-light displays of manipulable objects.},
}
@article{mcmurray_individual_2010,
	abstract = {Thirty years of research has uncovered the broad principles that characterize spoken word processing across listeners. However, there have been few systematic investigations of individual differences. Such an investigation could help refine models of word recognition by indicating which processing parameters are likely to vary, and could also have important implications for work on language impairment. The present study begins to fill this gap by relating individual differences in overall language ability to variation in online word recognition processes. Using the visual world paradigm, we evaluated online spoken word recognition in adolescents who varied in both basic language abilities and non-verbal cognitive abilities. Eye movements to target, cohort and rhyme objects were monitored during spoken word recognition, as an index of lexical activation. Adolescents with poor language skills showed fewer looks to the target and more fixations to the cohort and rhyme competitors. These results were compared to a number of variants of the {TRACE} model ({McClelland} \&amp; Elman, 1986) that were constructed to test a range of theoretical approaches to language impairment: impairments at sensory and phonological levels; vocabulary size, and generalized slowing. None of the existing approaches were strongly supported, and variation in lexical decay offered the best fit. Thus, basic word recognition processes like lexical decay may offer a new way to characterize processing differences in language impairment.},
}
@article{brualla_auditory_1998,
	abstract = {The present study uses the N400 component of event-related potentials ({ERPs)} as a processing marker of single spoken words presented during sleep. Thirteen healthy volunteers participated in the study. The auditory {ERPs} were registered in response to a semantic priming paradigm made up of pairs of words (50\% related, 50\% unrelated) presented in the waking state and during sleep stages {II}, {III--IV} and {REM.} The amplitude, latency and scalp distribution parameters of the negativity observed during stage {II} and the {REM} stage were contrasted with the results obtained in the waking state. The {`N400-like'} effect elicited in these stages of sleep showed a mean amplitude for pairs of unrelated words significantly greater than for related pairs and an increment of latency. These results suggest that during these sleep stages a semantic priming effect is maintained actively although the lexical processing time increases.},
}
@techreport{lammens_computational_1994,
	abstract = {{"June} 1994.".                                                                     
}
@article{marniemi_radiochemical_1975,
}
@article{huber_local_2004,
	abstract = {Human sleep is a global state whose functions remain unclear. During much of sleep, cortical neurons undergo slow oscillations in membrane potential, which appear in electroencephalograms as slow wave activity ({SWA)} of {\textless}4 Hz1. The amount of {SWA} is homeostatically regulated, increasing after wakefulness and returning to baseline during sleep2. It has been suggested that {SWA} homeostasis may reflect synaptic changes underlying a cellular need for sleep3. If this were so, inducing local synaptic changes should induce local {SWA} changes, and these should benefit neural function. Here we show that sleep homeostasis indeed has a local component, which can be triggered by a learning task involving specific brain regions. Furthermore, we show that the local increase in {SWA} after learning correlates with improved performance of the task after sleep. Thus, sleep homeostasis can be induced on a local level and can benefit performance.},
}
@article{barsalou_grounding_2003,
}
@article{tunik_virtual_2005,
	abstract = {Adaptive motor behavior requires efficient error detection and correction. The posterior parietal cortex is critical for on-line control of reach-to-grasp movements. Here we show a causal relationship between disruption of cortical activity within the anterior intraparietal sulcus ({aIPS)} by transcranial magnetic stimulation ({TMS)} and disruption of goal-directed prehensile actions (either grip size or forearm rotation, depending on the task goal, with reaching preserved in either case). Deficits were elicited by applying {TMS} within 65 ms after object perturbation, which attributes a rapid control process on the basis of visual feedback to {aIPS.} No aperture deficits were produced when {TMS} was applied to a more caudal region within the intraparietal sulcus, to the parieto-occipital complex (putative V6, {V6A)} or to the hand area of primary motor cortex. We contend that {aIPS} is critical for dynamic error detection during goal-dependent reach-to-grasp action that is visually guided.},
}
@inproceedings{rish_sparse_2012,
}
@article{koenigs_superior_2009,
	abstract = {In recent years, theoretical perspectives on posterior parietal function have evolved beyond the traditional visuospatial processing models to include more diverse cognitive operations, such as long-term and working memory. However, definitive neuropsychological evidence supporting the superior parietal lobule's purported role in working memory has been lacking. Here, we studied human brain lesion patients to determine whether the superior parietal lobule is indeed necessary for working memory. We assessed a wide range of memory functions in three participant groups: superior parietal lesions (n = 19), lesions not involving superior parietal cortex (n = 146), and no brain lesions (n = 55). Superior parietal damage was reliably associated with deficits on tests involving the manipulation and rearrangement of information in working memory, but not on working memory tests requiring only rehearsal and retrieval processes, nor on tests of long-term memory. These results indicate that superior parietal cortex is critically important for the manipulation of information in working memory.},
}
@article{forster_influence_1996,
	abstract = {The present article reports 3 studies that demonstrate the influence of overt behavior on recognition and elucidates the theoretical basis for such an influence. In 2 experiments it was found that participants who were induced to nod while incidentally encoding positive and negative adjectives were more likely to recognize positive adjectives, whereas participants who were induced to shake their heads were more likely to recognize negative words. In a third experiment, with a double-task procedure, it was shown that when encoding was accompanied by head movements that were compatible with words, participants were better at performing the secondary task than when words and head movements were incompatible. These findings suggest that performing incompatible motoric and conceptual tasks concurrently requires more cognitive capacity. Where this capacity is allocated and when it is withdrawn depends on the characteristics of the task. Implications of this mechanism for different phenomena in social psychology (e.g., facial feedback and masking of emotional displays) are discussed.},
}
@article{gerfo_influence_2008,
	abstract = {We investigated the differential role of two frontal regions in the processing of grammatical and semantic knowledge. Given the documented specificity of the prefrontal cortex for the grammatical class of verbs, and of the primary motor cortex for the semantic class of action words, we sought to investigate whether the prefrontal cortex is also sensitive to semantic effects, and whether the motor cortex is also sensitive to grammatical class effects. We used repetitive transcranial magnetic stimulation ({rTMS)} to suppress the excitability of a portion of left prefontal cortex (first experiment) and of the motor area (second experiment). In the first experiment we found that {rTMS} applied to the left prefrontal cortex delays the processing of action verbs' retrieval, but is not critical for retrieval of state verbs and state nouns. In the second experiment we found that {rTMS} applied to the left motor cortex delays the processing of action words, both name and verbs, while it is not critical for the processing of state words. These results support the notion that left prefrontal and motor cortex are involved in the process of action word retrieval. Left prefrontal cortex subserves processing of both grammatical and semantic information, whereas motor cortex contributes to the processing of semantic representation of action words without any involvement in the representation of grammatical categories.},
}
@article{brouwer_decoding_2009,
	abstract = {How is color represented by spatially distributed patterns of activity in visual cortex? Functional magnetic resonance imaging responses to several stimulus colors were analyzed with multivariate techniques: conventional pattern classification, a forward model of idealized color tuning, and principal component analysis ({PCA).} Stimulus color was accurately decoded from activity in V1, V2, V3, V4, and {VO1} but not {LO1}, {LO2}, {V3A/B}, or {MT+.} The conventional classifier and forward model yielded similar accuracies, but the forward model (unlike the classifier) also reliably reconstructed novel stimulus colors not used to train (specify parameters of) the model. The mean responses, averaged across voxels in each visual area, were not reliably distinguishable for the different stimulus colors. Hence, each stimulus color was associated with a unique spatially distributed pattern of activity, presumably reflecting the color selectivity of cortical neurons. Using {PCA}, a color space was derived from the covariation, across voxels, in the responses to different colors. In V4 and {VO1}, the first two principal component scores (main source of variation) of the responses revealed a progression through perceptual color space, with perceptually similar colors evoking the most similar responses. This was not the case for any of the other visual cortical areas, including V1, although decoding was most accurate in V1. This dissociation implies a transformation from the color representation in V1 to reflect perceptual color space in V4 and {VO1.}},
}
@article{conway_advances_2010,
	abstract = {Color has become a premier model system for understanding how information is processed by neural circuits, and for investigating the relationships among genes, neural circuits, and perception. Both the physical stimulus for color and the perceptual output experienced as color are quite well characterized, but the neural mechanisms that underlie the transformation from stimulus to perception are incompletely understood. The past several years have seen important scientific and technical advances that are changing our understanding of these mechanisms. Here, and in the accompanying minisymposium, we review the latest findings and hypotheses regarding color computations in the retina, primary visual cortex, and higher-order visual areas, focusing on non-human primates, a model of human color vision.},
}
@article{bird_deficits_2003,
	abstract = {Neuropsychological dissociations between regular and irregular past tense verb processing have been explained in two ways: (a) separate mechanisms of a rule-governed process for regular verbs and a lexical-associative process for irregular verbs; (b) a single system drawing on phonological and semantic knowledge. The latter account invokes phonological impairment as the basis of poorer performance for regular than irregular past tense forms, due to greater phonological complexity of the regular past. In 10 nonfluent aphasic patients, the apparent disadvantage for the production of regular past tense forms disappeared when phonological complexity was controlled. In a same-different judgment task on spoken words, all patients were impaired at judging regular stem and past-tense verbs like man/manned to be different, but equally poor at phonologically matched non-morphological discriminations like men/mend. These results indicate a central phonological deficit that is not limited to speech output nor to morphological processing; under such a deficit, distinctions lacking phonological salience, as typified by regular past tense English verbs, become especially vulnerable.},
}
@article{manns_semantic_2003,
	abstract = {It has been unclear whether the hippocampus is uniquely important for episodic memory (memory for events that are specific to time and place) or whether the hippocampus is also important for learning and remembering facts (semantic memory). In two studies, we assessed the capacity for semantic memory in patients with bilateral damage thought to be restricted primarily to the hippocampal region who developed memory impairment at a known time. Since the onset of their memory impairment, the patients have acquired less factual knowledge than controls. The patients also exhibit temporally limited retrograde amnesia for factual information from the several years preceding the onset of memory impairment. Remote memory for factual knowledge (from 11--30 years before amnesia) is intact. The results show that the hippocampal region supports semantic memory as well as episodic memory and that its role in the acquisition and storage of semantic knowledge is time limited.},
}
@article{olcese_sleep_2010,
	abstract = {Recent evidence indicates that net synaptic strength in cortical and other networks increases during wakefulness and returns to a baseline level during sleep. These homeostatic changes in synaptic strength are accompanied by corresponding changes in sleep slow wave activity ({SWA)} and in neuronal firing rates and synchrony. Other evidence indicates that sleep is associated with an initial reactivation of learned firing patterns that decreases over time. Finally, sleep can enhance performance of learned tasks, aid memory consolidation, and desaturate the ability to learn. Using a large-scale model of the corticothalamic system equipped with a spike-timing dependent learning rule, in agreement with experimental results, we demonstrate a net increase in synaptic strength in the waking mode associated with an increase in neuronal firing rates and synchrony. In the sleep mode, net synaptic strength decreases accompanied by a decline in {SWA.} We show that the interplay of activity and plasticity changes implements a control loop yielding an exponential, self-limiting renormalization of synaptic strength. Moreover, when the model "learns" a sequence of activation during waking, the learned sequence is preferentially reactivated during sleep, and reactivation declines over time. Finally, sleep-dependent synaptic renormalization leads to increased signal-to-noise ratios, increased resistance to interference, and desaturation of learning capabilities. Although the specific mechanisms implemented in the model cannot capture the variety and complexity of biological substrates, and will need modifications in line with future evidence, the present simulations provide a unified, parsimonious account for diverse experimental findings coming from molecular, electrophysiological, and behavioral approaches.},
}
@article{adolphs_dissociable_2003,
	abstract = {This study tested the hypothesis that the recognition of emotions would draw upon anatomically separable brain regions, depending on whether the stimuli were static or explicitly conveyed information regarding actions. We investigated the hypothesis in a rare subject with extensive bilateral brain lesions, patient B., by administering tasks that assessed recognition and naming of emotions from visual and verbal stimuli, some of which depicted actions and some of which did not. B. could not recognize any primary emotion other than happiness, when emotions were shown as static images or given as single verbal labels. By contrast, with the notable exception of disgust, he correctly recognized primary emotions from dynamic displays of facial expressions as well as from stories that described actions. Our findings are consistent with the idea that information about actions is processed in occipitoparietal and dorsal frontal cortices, all of which are intact in B.'s brain. Such information subsequently would be linked to knowledge about emotions that depends on structures mapping somatic states, many of which are also intact in B.'s brain. However, one of these somatosensory structures, the insula, is bilaterally damaged, perhaps accounting for B.'s uniformly impaired recognition of disgust (from both static and action stimuli). Other structures that are damaged in B.'s brain, including bilateral inferior and anterior temporal lobe and medial frontal cortices, appear to be critical for linking perception of static stimuli to recognition of emotions. Thus the retrieval of knowledge regarding emotions draws upon widely distributed and partly distinct sets of neural structures, depending on the attributes of the stimulus.},
}
@article{harnad_symbol_1990,
	abstract = {There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the ``symbol grounding problem'': How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a {Chinese/Chinese} dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) iconic representations, which are analogs of the proximal sensory projections of distal objects and events, and (2) categorical representations, which are learned and innate feature detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) symbolic representations, grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g. {``An} X is a Y that is Z''). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic ``module,'' however; the symbolic functions would emerge as an intrinsically ``dedicated'' symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded.},
}
@article{hubel_receptive_1962,
	abstract = {Images
}
@article{arguin1996shape,
}
@article{weisberg_neural_2007,
	abstract = {Does our ability to visually identify everyday objects rely solely on access to information about their appearance or on a more distributed representation incorporating other object properties? Using functional magnetic resonance imaging, we addressed this question by having subjects visually match pictures of novel objects before and after extensive training to use these objects to perform specific tool-like tasks. After training, neural activity emerged in regions associated with the motion (left middle temporal gyrus) and manipulation (left intraparietal sulcus and premotor cortex) of common tools, whereas activity became more focal and selective in regions representing their visual appearance (fusiform gyrus). These findings indicate that this distributed network is automatically engaged in support of object identification. Moreover, the regions included in this network mirror those active when subjects retrieve information about tools and their properties, suggesting that, as a result of training, these previously novel objects have attained the conceptual status of "tools."},
}
@article{rogers_precis_2008,
	abstract = {In this pr{\'e}cis of our recent book, Semantic Cognition: A Parallel Distributed Processing Approach (Rogers \& McClelland 2004), we present a parallel distributed processing theory of the acquisition, representation, and use of human semantic knowledge. The theory proposes that semantic abilities arise from the flow of activation among simple, neuron-like processing units, as governed by the strengths of interconnecting weights; and that acquisition of new semantic information involves the gradual adjustment of weights in the system in response to experience. These simple ideas explain a wide range of empirical phenomena from studies of categorization, lexical acquisition, and disordered semantic cognition. In this pr{\'e}cis we focus on phenomena central to the reaction against similarity-based theories that arose in the 1980s and that subsequently motivated the ``theory-theory'' approach to semantic knowledge. Specifically, we consider (1) how concepts differentiate in early development, (2) why some groupings of items seem to form ``good'' or coherent categories while others do not, (3) why different properties seem central or important to different concepts, (4) why children and adults sometimes attest to beliefs that seem to contradict their direct experience, (5) how concepts reorganize between the ages of 4 and 10, and (6) the relationship between causal knowledge and semantic knowledge. The explanations our theory offers for these phenomena are illustrated with reference to a simple feed-forward connectionist model. The relationships between this simple model, the broader theory, and more general issues in cognitive science are discussed.},
}
@article{goodale_separate_1992,
	abstract = {Accumulating neuropsychological, electrophysiological and behavioural evidence suggests that the neural substrates of visual perception may be quite distinct from those underlying the visual control of actions. In other words, the set of object descriptions that permit identification and recognition may be computed independently of the set of descriptions that allow an observer to shape the hand appropriately to pick up an object. We propose that the ventral stream of projections from the striate cortex to the inferotemporal cortex plays the major role in the perceptual identification of objects, while the dorsal stream projecting from the striate cortex to the posterior parietal region mediates the required sensorimotor transformations for visually guided actions directed at such objects.},
}
@article{jiang_cortical_2006,
	abstract = {Summary 
}
@book{fodor_modularity_1983,
}
@article{kellenbach_visual_2000,
	abstract = {There has been conflicting evidence to date regarding the existence of non-strategic semantic priming based on semantic similarity, and in particular on visual--perceptual semantic features (e.g., button--coin: words refer to objects with the same global shape). Both event-related potential ({ERP)} and reaction time ({RT)} measures were employed to investigate visual--perceptual semantic priming in a word-pair lexical decision task designed to minimise the contribution of conscious strategic processing. While no {RT} priming effect was observed, a robust priming effect was obtained on the N400 component of the {ERP.} This result shows that semantic priming, as indexed by the N400 component, can be supported by nonassociative visual--perceptual semantic relations. The data are consistent with perceptual form information being accessed during the processing of concrete words, and provide support for models of semantic representation which incorporate semantic features and form information.},
}
@article{loftus_spreading_1975,
	abstract = {Applies a spreading-activation theory of semantic processing to data from a series of experiments by E. Rosch (see record 1975-20006-001) in which Ss were shown 2 category members (e.g., orange, pear) and were asked to press a same key if both members belonged to the same natural category and a different key if they did not. In some cases, the pair to be judged was preceded or accompanied by a priming stimulus (e.g., the word fruit) which informed S that at least 1 of the 2 stimuli would be a fruit. ({PsycINFO} Database Record (c) 2010 {APA}, all rights reserved)},
}
@article{karnath_cortical_2005,
	abstract = {The dorsal stream of visual information processing connecting V1 to the parietal cortex is thought to provide a fast control of visually guided reaching. Important for this assumption was the observation that in both the monkey and the human, parietal lesions may provoke disturbance of visually goal-directed hand movements. In the human, severe misreaching termed 'optic ataxia' has been ascribed to lesions of the superior parietal lobule ({SPL)} and/or the intraparietal sulcus. Using new tools for lesion analysis, here we re-evaluated this view investigating the typical lesion location in a large group of unilateral stroke patients with optic ataxia, collected over a time period of 15 years. We found no evidence for the assumption that disruption of visually guided reaching in humans is associated with a lesion typically centering on the {SPL} on the convexity. In both left and right hemispheres, we found optic ataxia associated with a lesion overlap that affected the lateral cortical convexity at the occipito-parietal junction, i.e. the junction between the inferior parietal lobule ({IPL)} and superior occipital cortex and --- in the left hemisphere even more posteriorly --- also the junction between occipital cortex and the {SPL.} Via the underlying parietal white matter, the lesion overlap extended in both hemispheres to the medial cortical aspect, where it affected the precuneus close to the occipito-parietal junction. These lateral and medial structures seem to be integral to the fast control of visually guided reaching in humans.},
}
@article{damasio_neural_1996,
	abstract = {Conducted 2 parallel lexical retrieval studies using positron emission tomography in adult neurological patients with brain lesions and in normal individuals. A relationship was found between category-related word-retrieval deficits and neural sites in the left temporal lobe for Ss with brain lesions. Normal Ss showed differential activation of left temporal sites, comparable to those in the Ss with brain lesions. Results indicate that the normal process of retrieving words that denote concrete entities depends in part on multiple regions of the left cerebral hemisphere, located outside the classic language areas. Moreover, anatomically separable regions tend to process words for distinct kinds of items.},
}
@article{fedorenko_new_2010,
}
@article{genzel_slow_2009,
	abstract = {Study Objectives:
}
@article{anderson_maturation_1975,
}
@article{sporns_organization_2004,
	abstract = {Recent research has revealed general principles in the structural and functional organization of complex networks which are shared by various natural, social and technological systems. This review examines these principles as applied to the organization, development and function of complex brain networks. Specifically, we examine the structural properties of large-scale anatomical and functional brain networks and discuss how they might arise in the course of network growth and rewiring. Moreover, we examine the relationship between the structural substrate of neuroanatomy and more dynamic functional and effective connectivity patterns that underlie human cognition. We suggest that network analysis offers new fundamental insights into global and integrative aspects of brain function, including the origin of flexible and coherent cognitive states within the neural architecture.},
}
@article{motter_neural_1994,
	abstract = {Rhesus monkeys were trained on a conditional orientation discrimination task in order to assess whether attentive selection for a color or luminance stimulus feature would affect visual processing in extrastriate area V4. The task required monkeys to select a bar stimulus based on its color or luminance and then to discriminate the angular tilt of the selected stimulus. The majority of neurons (74\%) were selectively activated when the color or luminance of the stimulus in the receptive field matched the color or luminance of the cue. The activity was attenuated when there was not a match between the stimulus and the cue. The differential activation was based on the presence or absence of the stimulus feature and was independent of spatial location. Across the population of V4 neurons, optimal stimuli that matched the selected color or luminance elicited about twice the activity as stimuli that did not match the selected feature. The feature-selective changes in activity were observed to develop beginning about 200 msec after the stimulus onset and were maintained over the remainder of the behavioral trial. In this task the activity of V4 neurons reflected a selection based on the cued feature and not simply the physical color or luminance of the receptive field stimulus. Under these conditions, the topographic representation of the neural activity in area V4 highlights the potential targets in the visual scene at the expense of background objects. These observations offer a physiological counterpart to psychophysical studies suggesting that stimuli can be preferentially selected in parallel across the visual field on the basis of a unique color or luminance feature},
}
@article{gerlach_category-specificity_2009,
	abstract = {Are all categories of objects recognized in the same manner visually? Evidence from neuropsychology suggests they are not: some brain damaged patients are more impaired in recognizing natural objects than artefacts whereas others show the opposite impairment. Category-effects have also been demonstrated in neurologically intact subjects, but the findings are contradictory and there is no agreement as to why category-effects arise. This article presents a pre-semantic account of category-effects ({PACE)} in visual object recognition. {PACE} assumes two processing stages: shape configuration (the binding of shape elements into elaborate shape descriptions) and selection (among competing representations in visual long-term memory), which are held to be differentially affected by the structural similarity between objects. Drawing on evidence from clinical studies, experimental studies with neurologically intact subjects and functional imaging studies, it is argued that {PACE} can account for category-effects at both behavioural and neural levels in patients and neurologically intact subjects. The theory also accounts for the way in which category-effects are affected by different task parameters (the degree of perceptual differentiation called for), stimulus characteristics (whether stimuli are presented as silhouettes, full line-drawings, or fragmented forms), stimulus presentation (stimulus exposure duration and position) as well as interactions between these parameters.},
}
@article{noppeney_neural_2008,
	abstract = {This review discusses the contributions of functional imaging ({fMRI/PET)} to our understanding of how action and tool concepts are represented and processed in the human brain. Category-selective deficits in neuropsychological patients have suggested a fine-grained functional specialization within the neural systems of semantics. However, the underlying principles of semantic organization remain controversial. The feature-based account of semantic memory (or 'sensory-motor theory') predicates category-selective effects (e.g. tool vs. animals) on anatomical segregation for different semantic features (e.g. action vs. visual). Within this framework, we will review functional imaging evidence that semantic processing of tools and actions may rely on activations within the visuo-motor system.},
}
@article{gorno-tempini_category_2000,
	abstract = {Differences in the neural processing of six categories of pictorial stimuli (maps, body parts, objects, animals, famous faces and colours) were investigated using positron emission tomography. Stimuli were presented either with or without the written name of the picture, thereby creating a naming condition and a reading condition. As predicted, naming increased the demands on lexical processes. This was demonstrated by activation of the left temporal lobe in a posterior region associated with name retrieval in several previous studies. This lexical effect was common to all meaningful stimuli and no categoryspecific effects were observed for naming relative to reading. Nevertheless, category differences were found when naming and reading were considered together. Stimuli with greater visual complexity (animals, faces and maps) enhanced activation in the left extrastriate cortex. Furthermore, map recognition, which requires greater spatio--topographical processing, also activated the right occipito--parietal and parahippocampal cortices. These effects in the visuo--patial regions emphasize inevitable differences in the perceptual properties of pictorial stimuli. In the semantic temporal regions, famous faces and objects enhanced activation in the left antero--lateral and postero--lateral cortices, respectively. In addition, we showed that the same posterior left temporal region is also activated by body parts. We conclude that category--specific brain activations depend more on differential processing at the perceptual and semantic levels rather than at the lexical retrieval level.},
}
@book{kay_world_2007,
	abstract = {The 1969 publication of Paul Kay and Brent Berlin's Basic Color Terms proved explosive and controversial. Contrary to the then-popular doctrine of random language variation, Kay and Berlin's multilingual study of color nomenclature indicated a cross-cultural and almost universal pattern in the selection of colors that received abstract names in each language. The ensuing debate helped reform the views of anthropologists, linguists, and biologists {alike.After} three decades in print, Basic Color Terms now has a sequel: in this book, Kay, Berlin, Luisa Maffi, and William R. Merrifield authoritatively defend and complete the original survey, studying ninety more languages in detail with the help of native collaborators. The results are presented even more clearly than before, with charts showing the overall palette of color terms within each language as well as the levels of agreement among speakers. Their raw data are also available online, ready to fuel or settle a new round of disputes.},
}
@article{snowden_semantic_1989,
	abstract = {Presents case reports of a 67-yr-old man and 2 women (aged 60 and 66 yrs) with primary cerebral atrophy in whom progressive breakdown in language and visual perception are attributed to loss of semantic information. This form of dementia is distinct from that of Alzheimer's disease and is assumed to represent a form of circumscribed cerebral atrophy with emphasis of pathology in temporal rather than frontal regions of the brain.},
}
@article{binkofski_tactile_2007,
	abstract = {In the haptic domain, a double dissociation can be proposed on the basis of neurological deficits between tactile information for action, represented by tactile apraxia, and tactile information for perception, represented by tactile agnosia. We suggest that this dissociation comes from different networks, both involving the anterior intraparietal area of the posterior parietal cortex.},
}
@article{kamitani_decoding_2005,
	abstract = {The potential for human neuroimaging to read out the detailed contents of a person's mental state has yet to be fully explored. We investigated whether the perception of edge orientation, a fundamental visual feature, can be decoded from human brain activity measured with functional magnetic resonance imaging ({fMRI).} Using statistical algorithms to classify brain states, we found that ensemble {fMRI} signals in early visual areas could reliably predict on individual trials which of eight stimulus orientations the subject was seeing. Moreover, when subjects had to attend to one of two overlapping orthogonal gratings, feature-based attention strongly biased ensemble activity toward the attended orientation. These results demonstrate that {fMRI} activity patterns in early visual areas, including primary visual cortex (V1), contain detailed orientation information that can reliably predict subjective perception. Our approach provides a framework for the readout of fine-tuned representations in the human brain and their subjective contents.},
}
@incollection{greer_emergence_2001,
	abstract = {This paper presents a computational model of semantic memory, trained with behaviourally inspired vectors. The results are consistent with the conceptual structure account (Tyler, Moss, Durrant-Peatfield \& Levy, 2000), which claims that concepts can be understood, and the effects of random damage predicted, based on (i) the number of correlations its features make, and (ii) the distinctiveness of those correlated features; the former indicating category membership, the latter distinguishing between concepts. The model shows a changing direction of domain-specific deficits as damage accumulates (animals concepts lost first, then objects upon severe lesioning). Also, the pattern of error differs between domains; animals tend to be confused for other members of the same category, whilst object errors disperse more widely across categories and domain. Recent neuropsychological evidence demonstrates a similar pattern for semantically impaired patients. For both patients and the model, this can be attributed to the timing of featural loss: distinctive features are lost earlier than shared features. The model demonstrates that the relative timing of feature loss differs between domains, resulting in the emergence of domain-specific effects.},
}
@article{kruschke_toward_2001,
	abstract = {Two connectionist models of attention in associative learning, previously used to model human category learning, are shown to have special cases that are essentially equivalent to N. J. Mackintosh's (1975, Psychological Review, 82, 276--298) classic model of attention in animal learning. The models unify formulas for associative weight change with formulas for attentional change, under a common goal of error reduction. Error-driven attentional shifting accelerates learning of new associations but also protects previously learned associations from retroactive interference. The models are fit to data from a recent experiment in human associative learning (J. K. Kruschke \&amp; N. J. Blair, 2000, Psychonomic Bulletin \&amp; Review, 7, 636--645), which shows that blocking of learning involves learned inattention. The approach also provides a novel and unifying theory of latent inhibition (the preexposure effect) in terms of blocking. The discussion summarizes how the approach accounts for a variety of other ``irrational'' phenomena in associative learning, including base rate effects, perseveration of attention through relevance shifts, overshadowing, and the extrapolation of rules near exceptions.},
}
@book{rohde_lens:_1999,
}
@article{moss_weighing_2003-1,
}
@article{canessa_different_2008,
}
@article{hauk_imagery_2008,
	abstract = {Category-specific brain activation distinguishing between semantic word types has imposed challenges on theories of semantic representations and processes. However, existing metabolic imaging data are still ambiguous about whether these category-specific activations reflect processes involved in accessing the semantic representation of the stimuli, or secondary processes such as deliberate mental imagery. Further information about the response characteristics of category-specific activation is still required. Our study for the first time investigated the differential impact of word frequency on functional magnetic resonance imaging ({fMRI)} responses to action-related words and visually related words, respectively. First, we corroborated previous results showing that action-relatedness modulates neural responses in action-related areas, while word imageability modulates activation in object processing areas. Second, we provide novel results showing that activation negatively correlated with word frequency in the left fusiform gyrus was specific for visually related words, while in the left middle temporal gyrus word frequency effects emerged only for action-related words. Following the dominant view in the literature that effects of word frequency mainly reflect access to lexico-semantic information, we suggest that category-specific brain activation reflects distributed neuronal ensembles, which ground language and concepts in perception-action systems of the human brain. Our approach can be applied to any event-related data using single-stimulus presentation, and allows a detailed characterization of the functional role of category-specific activation patterns.},
}
@article{sirigu_role_1991,
	abstract = {Object recognition was studied in a 19-yr-old male patient who presented severe multimodal amnesia and agnosia without significant intellectual, linguistic or perceptual deficits. Bilateral temporal lobe lesions involved medial, polar and anterior infero-temporal structures. Although visual recognition was impaired to various extents for all categories of objects, preservation of certain capacities were demonstrated. In particular, the patient was able to determine specifically how to manipulate certain objects, in spite of his incapacity to define their function or their context of utilization. It is argued that object recognition involves different processing modes such that when direct access to representations of an object is impaired, sensorimotor information activated via alternative cortical and subcortical pathways may provide a limited mechanism for recognition.},
}
@article{seidenberg_distributed_1989,
	abstract = {The model described consists of sets of orthographic and phonological units and an interlevel of hidden units. Weights on connections between units were modified during a training phase using the back-propagation learning algorithm. The model simulates many aspects of human performance, including (a) differences between words in terms of processing difficulty, (b) pronunciation of novel items, (c) differences between readers in terms of word recognition skill, (d) transitions from beginning to skilled reading, and (e) differences in performance on lexical decisions and naming tasks. The model's behavior early in the learning phase corresponds to that of children acquiring word recognition skills. Training with a smaller number of hidden units produces output characteristic of many dyslexic readers. Naming is simulated without pronunciation rules, and lexical decisions are simulated without assessing word-level representations. The performance of the model is largely determined by three factors: the nature of the input, a significant fragment of written English; the learning rule, which encodes the implicit structure of the orthography in the weights on connections; and the architecture of the system, which influences the scope of what can be learned.},
}
@article{marshall_contribution_2007,
	abstract = {There is now compelling evidence that sleep promotes the long-term consolidation of declarative and procedural memories. Behavioral studies suggest that sleep preferentially consolidates explicit aspects of these memories, which during encoding are possibly associated with activation in prefrontal--hippocampal circuitry. Hippocampus-dependent declarative memory benefits particularly from slow-wave sleep ({SWS)}, whereas rapid-eye-movement ({REM)} sleep seems to benefit procedural aspects of memory. Consolidation of hippocampus-dependent memories relies on a dialog between the neocortex and hippocampus. Crucial features of this dialog are the neuronal reactivation of new memories in the hippocampus during {SWS}, which stimulates the redistribution of memory representations to neocortical networks; and the neocortical slow ({\&lt;1\&\#xa0;Hz)} oscillation that synchronizes hippocampal-to-neocortical information transfer to activity in other brain structures.},
}
@article{astle_spatial_2010,
	abstract = {Perceptual learning effects demonstrate that the adult visual system retains neural plasticity. If perceptual learning holds any value as a treatment tool for amblyopia, trained improvements in performance must generalise. Here we investigate whether spatial frequency discrimination learning generalises within task to other spatial frequencies, and across task to contrast sensitivity. Before and after training, we measured contrast sensitivity and spatial frequency discrimination (at a range of reference frequencies 1, 2, 4, 8, 16 c/deg). During training, normal and amblyopic observers were divided into three groups. Each group trained on a spatial frequency discrimination task at one reference frequency (2, 4, or 8 c/deg). Normal and amblyopic observers who trained at lower frequencies showed a greater rate of within task learning (at their reference frequency) compared to those trained at higher frequencies. Compared to normals, amblyopic observers showed greater within task learning, at the trained reference frequency. Normal and amblyopic observers showed asymmetrical transfer of learning from high to low spatial frequencies. Both normal and amblyopic subjects showed transfer to contrast sensitivity. The direction of transfer for contrast sensitivity measurements was from the trained spatial frequency to higher frequencies, with the bandwidth and magnitude of transfer greater in the amblyopic observers compared to normals. The findings provide further support for the therapeutic efficacy of this approach and establish general principles that may help develop more effective protocols for the treatment of developmental visual deficits.},
}
@article{golestani_semantic_2013,
	abstract = {Native listeners make use of higher-level, context-driven semantic and linguistic information during the perception of speech-in-noise. In a recent behavioral study, using a new paradigm that isolated the semantic level of speech by using words, we showed that this native-language benefit is at least partly driven by semantic context (Golestani et al., 2009). Here, we used the same paradigm in a functional magnetic resonance imaging ({fMRI)} experiment to study the neural bases of speech intelligibility, as well as to study the neural bases of this semantic context effect in the native language. A forced-choice recognition task on the first of two auditorily presented semantically related or unrelated words was employed, where the first, 'target' word was embedded in different noise levels. Results showed that activation in components of the brain language network, including Broca's area and the left posterior superior temporal sulcus, as well as brain regions known to be functionally related to attention and task difficulty, was modulated by stimulus intelligibility. In line with several previous studies examining the role of linguistic context in the intelligibility of degraded speech at the sentence level, we found that activation in the angular gyrus of the left inferior parietal cortex was modulated by the presence of semantic context, and further, that this modulation depended on the intelligibility of the speech stimuli. Our findings help to further elucidate neural mechanisms underlying the interaction of context-driven and signal-driven factors during the perception of degraded speech, and this specifically at the semantic level.},
}
@article{buxbaum_function_2000,
	abstract = {Abstract Several accounts of the semantic system posit that function information plays a critical role in the representations of man-made objects. Alternative possibilities are that man-made objects such as tools are organized according to manner of manipulation, or that both function and manipulation information figure importantly and distinctly in man-made object representations. An agnosic patient, {FB}, reported by Sirigu et al. (Brain 1991; 114: 727-41) provides support for the latter view. {FB} was able to demonstrate how to manipulate objects whose function he did not recognize. We now report two severely apraxic patients whose performance, together with that of {FBI} indicates that function and manipulation information may doubly dissociate. On 'declarative' semantic tests not requiring gesture production, our subjects demonstrate severely impaired manipulation knowledge in the context of relatively intact (and, in one subject, perfectly unimpaired) function knowledge. The double dissociation provides further support for the notion that function and manipulation knowledge are critical and distinct features of the representations of manipulable man-made objects.},
}
@article{born_awareness_2004,
	abstract = {Sleep is crucial to the 'off-line' consolidation of procedural memory. A recent study by Robertson et al. shows that this might hold true only if the task is trained explicitly, that is, with the subject being aware of the task structure. These new data add to emerging evidence that sleep-related memory consolidation involves an interaction between different memory systems.},
}
@article{rissman_detecting_2010,
	abstract = {A wealth of neuroscientific evidence indicates that our brains respond differently to previously encountered than to novel stimuli. There has been an upswell of interest in the prospect that functional {MRI} ({fMRI)}, when coupled with multivariate data analysis techniques, might allow the presence or absence of individual memories to be detected from brain activity patterns. This could have profound implications for forensic investigations and legal proceedings, and thus the merits and limitations of such an approach are in critical need of empirical evaluation. We conducted two experiments to investigate whether neural signatures of recognition memory can be reliably decoded from {fMRI} data. In Exp. 1, participants were scanned while making explicit recognition judgments for studied and novel faces. Multivoxel pattern analysis ({MVPA)} revealed a robust ability to classify whether a given face was subjectively experienced as old or new, as well as whether recognition was accompanied by recollection, strong familiarity, or weak familiarity. Moreover, a participant's subjective mnemonic experiences could be reliably decoded even when the classifier was trained on the brain data from other individuals. In contrast, the ability to classify a face's objective old/new status, when holding subjective status constant, was severely limited. This important boundary condition was further evidenced in Exp. 2, which demonstrated that mnemonic decoding is poor when memory is indirectly (implicitly) probed. Thus, although subjective memory states can be decoded quite accurately under controlled experimental conditions, {fMRI} has uncertain utility for objectively detecting an individual's past experiences.},
}
@article{bedny_typical_2012,
}
@article{phillips_can_2002,
}
@article{belayachi_individual_2013,
	abstract = {Goal representations play a key role in various psychological processes, including behavioral regulation, self-perception and social understanding. Research on cognitive representations of action has identified individual differences in the general tendency to construe actions in terms of their goal (vs. movement parameters), which can be reliably assessed with the Behavior Identification Form ({BIF).} The aim of the present study was to examine how individual differences in action identification, as measured by the {BIF}, affect online processing of action in a laboratory study. The main results showed that the level of action identification predicted participants' performance in a task designed to implicitly assess people's automatic processing of action regarding goal features. We discussed the possible role of impaired goal processing in psychological dysfunctions. ({PsycINFO} Database Record (c) 2013 {APA}, all rights reserved) (journal abstract)},
}
@article{riggall_relationship_2012,
	abstract = {Does the sustained, elevated neural activity observed during working memory tasks reflect the short-term retention of information? Functional magnetic resonance imaging ({fMRI)} data of delayed recognition of visual motion in human participants were analyzed with two methods: a general linear model ({GLM)} and multivoxel pattern analysis. Although the {GLM} identified sustained, elevated delay-period activity in superior and lateral frontal cortex and in intraparietal sulcus, pattern classifiers were unable to recover trial-specific stimulus information from these delay-active regions. The converse---no sustained, elevated delay-period activity but successful classification of trial-specific stimulus information---was true of posterior visual regions, including area {MT+} (which contains both middle temporal area and medial superior temporal area) and calcarine and pericalcarine cortex. In contrast to stimulus information, pattern classifiers were able to extract trial-specific task instruction-related information from frontal and parietal areas showing elevated delay-period activity. Thus, the elevated delay-period activity that is measured with {fMRI} may reflect processes other than the storage, per se, of trial-specific stimulus information. It may be that the short-term storage of stimulus information is represented in patterns of (statistically) ``subthreshold'' activity distributed across regions of low-level sensory cortex that univariate methods cannot detect.},
}
@article{alitto_corticothalamic_2003,
	abstract = {Although nearly half of the synaptic input to neurons in the dorsal thalamus comes from the cerebral cortex, the role of corticothalamic projections in sensory processing remains elusive. Although sensory afferents certainly establish the basic receptive field properties of thalamic neurons, increasing evidence indicates that feedback from the cortex plays a crucial role in shaping thalamic responses. Here, we review recent work on the corticothalamic pathways associated with the visual, auditory, and somatosensory systems. Collectively, these studies demonstrate that sensory responses of thalamic neurons result from dynamic interactions between feedforward and feedback pathways.},
}
@article{tulving_episodic_2002,
	abstract = {Episodic memory is a neurocognitive (brain/mind) system, uniquely different from other memory systems, that enables human beings to remember past experiences. The notion of episodic memory was first proposed some 30 years ago. At that time it was defined in terms of materials and tasks. It was subsequently refined and elaborated in terms of ideas such as self, subjective time, and autonoetic consciousness. This chapter provides a brief history of the concept of episodic memory, describes how it has changed (indeed greatly changed) since its inception, considers criticisms of it, and then discusses supporting evidence provided by (a) neuropsychological studies of patterns of memory impairment caused by brain damage, and (b) functional neuroimaging studies of patterns of brain activity of normal subjects engaged in various memory tasks. I also suggest that episodic memory is a true, even if as yet generally unappreciated, marvel of nature.},
}
@article{tong_neural_2006,
}
@article{pessoa_emotion_2010-1,
	abstract = {A subcortical pathway through the superior colliculus and pulvinar to the amygdala is commonly assumed to mediate the non-conscious processing of affective visual stimuli. We review anatomical and physiological data that argue against the notion that such a pathway plays a prominent part in processing affective visual stimuli in humans. Instead, we propose that the primary role of the amygdala in visual processing, like that of the pulvinar, is to coordinate the function of cortical networks during evaluation of the biological significance of affective visual stimuli. Under this revised framework, the cortex has a more important role in emotion processing than is traditionally assumed.},
}
@article{martin_semantic_2001,
	abstract = {Recent functional brain imaging studies suggest that object concepts may be represented, in part, by distributed networks of discrete cortical regions that parallel the organization of sensory and motor systems. In addition, different regions of the left lateral prefrontal cortex, and perhaps anterior temporal cortex, may have distinct roles in retrieving, maintaining and selecting semantic information.},
}
@article{binder_neurobiology_2011,
	abstract = {Semantic memory includes all acquired knowledge about the world and is the basis for nearly all human activity, yet its neurobiological foundation is only now becoming clear. Recent neuroimaging studies demonstrate two striking results: the participation of modality-specific sensory, motor, and emotion systems in language comprehension, and the existence of large brain regions that participate in comprehension tasks but are not modality-specific. These latter regions, which include the inferior parietal lobe and much of the temporal lobe, lie at convergences of multiple perceptual processing streams. These convergences enable increasingly abstract, supramodal representations of perceptual experience that support a variety of conceptual functions including object recognition, social cognition, language, and the remarkable human capacity to remember the past and imagine the future.},
}
@incollection{comon_independent_1992,
	abstract = {The Independent Component Analysis ({ICA)} of a random vector consists of searching for the linear transformation that minimizes the statistical dependence between its components. In order to design a practical optimization criterion, the expression of mutual information is being resorted to, as a function of cumulants. The concept of {ICA} may be seen as an extension of Principal Component Analysis, which only imposes independence up to second order and consequently defines directions that are orthogonal. Applications of {ICA} include data compression, detection and localization of sources, or blind identification and deconvolution.},
}
@article{binkofski_two_2012,
	abstract = {The distinction between dorsal and ventral visual processing streams, first proposed by Ungerleider and Mishkin (1982) and later refined by Milner and Goodale (1995) has been elaborated substantially in recent years, spurred by two developments. The first was proposed in large part by Rizzolatti and Matelli (2003) and is a more detailed description of the multiple neural circuits connecting the frontal, temporal, and parietal cortices. Secondly, there are a number of behavioral observations that the classic "two visual systems" hypothesis is unable to accommodate without additional assumptions. The notion that the Dorsal stream is specialized for "where" or "how" actions and the Ventral stream for {"What"} knowledge cannot account for two prominent disorders of action, limb apraxia and optic ataxia, that represent a double dissociation in terms of the types of actions that are preserved and impaired. A growing body of evidence, instead, suggests that there are at least two distinct Dorsal routes in the human brain, referred to as the {"Grasp"} and {"Use"} systems. Both of these may be differentiated from the Ventral route in terms of neuroanatomic localization, representational specificity, and time course of information processing.},
}
@article{tranel_neural_1997,
	abstract = {Both clinical reports and systematic neuropsychological studies have shown that patients with damage to selected brain sites develop defects in the retrieval of conceptual knowledge for various concrete entities, leading to the hypothesis that the retrieval of knowledge for entities from different conceptual categories depends on partially segregated large-scale neural systems. To test this hypothesis, 116 subjects with focal, unilateral lesions to various sectors of the telencephalon, and 55 matched controls, were studied with a procedure which required the visual recognition of entities from three categories---unique persons, non-unique animals and non-unique tools. Defective recognition of persons was associated with maximal lesion overlap in right temporal polar region; defective recognition of animals was associated with maximal lesion overlap in right mesial occipital/ventral temporal region and also in left mesial occipital region; and defective recognition of tools was associated with maximal lesion overlap in the occipital-temporal-parietal junction of the left hemisphere. The findings support the hypothesis that the normal retrieval of knowledge for concrete entities from different conceptual domains depends on partially segregated neural systems. These sites may operate as catalysts for the retrieval of the multidimensional aspects of knowledge which are necessary and sufficient for the mental representation of a concept of a given entity.},
}
@article{fahle_no_1996,
	abstract = {Background: Recent experiments have demonstrated a remarkable amount of specificity in the learning of simple visual tasks in humans, as well as considerable plasticity of receptive fields in the visual cortex of adult monkeys. Here, we tested the specificity of improvement through learning in the performance of human observers on two tasks using almost identical stimuli. Results Two groups, of six observers each, were trained in two hyperacuity tasks---three-dot bisection and three-dot vernier discrimination. The groups started with different tasks, and switched tasks after one hour of training. Training improved performance significantly, in spite of considerable variability between observers, but improvement did not generalize from one of these tasks to the other. This result indicates that perceptual learning can be extremely stimulus specific, and that deviations from the same standard but in orthogonal directions require completely new training. Conclusion Learning is not based on the development of a more exact map of positional information, or on training to fixate or accommodate the eye, but on a better discrimination between the stimuli using one specific stimulus dimension. We also demonstrate that observers differ considerably, not only in their speed of learning, but also in their relative level of performance on the two similar tasks.},
}
@article{milner_two_2008,
	abstract = {The model proposed by the authors of two cortical systems providing 'vision for action' and 'vision for perception', respectively, owed much to the inspiration of Larry Weiskrantz. In the present article some essential concepts inherent in the model are summarized, and certain clarifications and refinements are offered. Some illustrations are given of recent experiments by ourselves and others that have prompted us to sharpen these concepts. Our explicit hope in writing our book in 1995 was to provide a theoretical framework that would stimulate research in the field. Conversely, well-designed empirical contributions conceived within the framework of the model are the only way for us to progress along the route towards a fully fleshed-out specification of its workings.},
}
@article{chen_linear_2013-1,
	abstract = {Conventional group analysis is usually performed with Student-type t-test, regression, or standard {AN(C)OVA} in which the variance--covariance matrix is presumed to have a simple structure. Some correction approaches are adopted when assumptions about the covariance structure is violated. However, as experiments are designed with different degrees of sophistication, these traditional methods can become cumbersome, or even be unable to handle the situation at hand. For example, most current {FMRI} software packages have difficulty analyzing the following scenarios at group level: (1) taking within-subject variability into account when there are effect estimates from multiple runs or sessions; (2) continuous explanatory variables (covariates) modeling in the presence of a within-subject (repeated measures) factor, multiple subject-grouping (between-subjects) factors, or the mixture of both; (3) subject-specific adjustments in covariate modeling; (4) group analysis with estimation of hemodynamic response ({HDR)} function by multiple basis functions; (5) various cases of missing data in longitudinal studies; and (6) group studies involving family members or twins.
}
@article{hoenig_conceptual_2008,
	abstract = {Traditionally, concepts are assumed to be situational invariant mental knowledge entities (conceptual stability), which are represented in a unitary brain system distinct from sensory and motor areas (amodality). However, accumulating evidence suggests that concepts are embodied in perception and action in that their conceptual features are stored within modality-specific semantic maps in the sensory and motor cortex. Nonetheless, the first traditional assumption of conceptual stability largely remains unquestioned. Here, we tested the notion of flexible concepts using functional magnetic resonance imaging and event-related potentials ({ERPs)} during the verification of two attribute types (visual, action-related) for words denoting artifactual and natural objects. Functional imaging predominantly revealed crossover interactions between category and attribute type in visual, motor, and motion-related brain areas, indicating that access to conceptual knowledge is strongly modulated by attribute type: Activity in these areas was highest when nondominant conceptual attributes had to be verified. {ERPs} indicated that these category-attribute interactions emerged as early as 116 msec after stimulus onset, suggesting that they reflect rapid access to conceptual features rather than postconceptual processing. Our results suggest that concepts are situational-dependent mental entities. They are composed of semantic features which are flexibly recruited from distributed, yet localized, semantic maps in modality-specific brain regions depending on contextual constraints.},
}
@article{van_dam_context-dependent_2012,
}
@article{convento_neuromodulation_2012,
	abstract = {Merging information derived from different sensory channels allows the brain to amplify minimal signals to reduce their ambiguity, thereby improving the ability of orienting to, detecting, and identifying environmental events. Although multisensory interactions have been mostly ascribed to the activity of higher-order heteromodal areas, multisensory convergence may arise even in primary sensory-specific areas located very early along the cortical processing stream. In three experiments, we investigated early multisensory interactions in lower-level visual areas, by using a novel approach, based on the coupling of behavioral stimulation with two noninvasive brain stimulation techniques, namely {TMS} and transcranial direct current stimulation. First, we showed that redundant multisensory stimuli can increase visual cortical excitability, as measured by means of phosphene induction by occipital {TMS;} such physiological enhancement is followed by a behavioral facilitation through the amplification of signal intensity in sensory-specific visual areas. The more sensory inputs are combined (i.e., trimodal vs. bimodal stimuli), the greater are the benefits on phosphene perception. Second, neuroelectrical activity changes induced by transcranial direct current stimulation in the temporal and in the parietal cortices, but not in the occipital cortex, can further boost the multisensory enhancement of visual cortical excitability, by increasing the auditory and tactile inputs from temporal and parietal regions, respectively, to lower-level visual areas.},
}
@article{fang_cortical_2005,
	abstract = {The primate visual system is believed to comprise two main pathways: a ventral pathway for conscious perception and a dorsal pathway that can process visual information and guide action without accompanying conscious knowledge. Evidence for this theory has come primarily from studies of neurological patients and animals. Using {fMRI}, we show here that even though observers are completely unaware of test object images owing to interocular suppression, their dorsal cortical areas demonstrate substantial activity for different types of visual objects, with stronger responses to images of tools than of human faces. This result also suggests that in binocular rivalry, substantial information in the suppressed eye can escape the interocular suppression and reach dorsal cortex.},
}
@article{mahon_what_2011,
	abstract = {Various forms of category-specificity have been described at both the cognitive and neural levels, inviting the inference that different semantic domains are processed by distinct, dedicated mechanisms. In this paper, we argue for an extension of a domain-specific interpretation to these phenomena that is based on network-level analyses of functional coupling among brain regions. On this view, domain-specificity in one region of the brain emerges because of innate connectivity with a network of regions that also process information about that domain. Recent findings are reviewed that converge with this framework, and a new direction is outlined for understanding the neural principles that shape the organization of conceptual knowledge.},
}
@article{huber_tms-induced_2007,
	abstract = {{BACKGROUND}
}
@article{himmelbach_dorsal_2005,
	abstract = {In monkeys and humans, two functionally specialized cortical streams of visual processing emanating from V1 have been proposed: a dorsal, action-related system and a ventral, perception-related pathway. Traditionally, a separate organization of the two streams is assumed; the extent of functional interaction is unknown. After lesions of the dorsal stream in patients with optic ataxia, it has recently been shown that the ventral perception-related system might contribute to visuo-motor processing if movements rely on remembered target positions. The ventral pathway thus seemed to participate in goal-directed movements, a function that previously has been assigned exclusively to the dorsal stream. We wondered whether different types of pointing movements are controlled by switching between two separated cortical pathways or whether a variable interaction of interconnected systems should be assumed. Our study investigated two acute stroke patients with optic ataxia following lesions of the dorsal stream in a delayed pointing task. The delays ranged from 0 to 10 sec. The patients' pointing error decreased in a linear manner with the length of time. The finding suggests a gradual change between dorsal and ventral control of reaching behavior, rather than a sudden switch between two separated cortical processing streams. Although our observations with two patients require further validation, the results suggest that the ventral and dorsal systems interact closely in the sensorimotor control of reaching behavior.},
}
@article{voss_neural_2007,
	abstract = {During episodic recognition tests, meaningful stimuli such as words can engender both conscious retrieval (explicit memory) and facilitated access to meaning that is distinct from the awareness of remembering (conceptual implicit memory). Neuroimaging investigations of one type of memory are frequently subject to the confounding influence of the other type of memory, thus posing a serious impediment to theoretical advances in this area. We used minimalist visual shapes (squiggles) to attempt to overcome this problem. Subjective ratings of squiggle meaningfulness varied idiosyncratically, and behavioral indications of conceptual implicit memory were evident only for stimuli given higher ratings. These effects did not result from perceptual-based fluency or from explicit remembering. Distinct event-related brain potentials were associated with conceptual implicit memory and with explicit memory by virtue of contrasts based on meaningfulness ratings and memory judgments, respectively. Frontal potentials from 300 to 500 msec after the onset of repeated squiggles varied systematically with perceived meaningfulness. Explicit memory was held constant in this contrast, so these potentials were taken as neural correlates of conceptual implicit memory. Such potentials can contaminate putative neural correlates of explicit memory, in that they are frequently attributed to the expression of explicit memory known as familiarity. These findings provide the first neural dissociation of these two memory phenomena during recognition testing and underscore the necessity of taking both types of memory into account in order to obtain valid neural correlates of specific memory functions.},
}
@article{marcel_conscious_1983,
	abstract = {Five experiments are presented which explore the relation of masking to consciousness and visual word processing. In Experiment 1 a single word or blank field was followed by a pattern mask. Subjects had to make one of three decisions: Did anything precede the mask? To which of two probe words was what preceded the mask more similar graphically? To which of two probe words was it more similar semantically? As word-mask stimulus onset asynchrony ({SOA)} was reduced, subjects reached chance performance on the detection, graphic, and semantic decisions in that order. In Experiment 2, subjects again had to choose which of two words was more similar either graphically or semantically to a nondetectable masked word, but the forced-choice stimuli now covaried negatively on graphic and semantic similarity. Subjects were now unable to choose selectively on each dimension, suggesting that their ability to choose in Experiment 1 was passively rather than intentionally mediated. In Experiment 3 subjects had to make manual identification responses to color patches which were either accompanied or preceded by words masked to prevent awareness. Color-congruent words facilitated reaction time ({RT)}, color-incongruent words delayed {RT.} Experiment 4 used a lexical decision task where a trial consisted of the critical letter string following another not requiring a response. When both were words they were either semantically associated or not. The first letter string was either left unmasked, energy masked monoptically, or pattern masked dichoptically to prevent awareness. The effect of association was equal in the unmasked and pattern masked cases, but absent with energy masking. In Experiment 5 repeating a word-plus-mask (where the {SOA} precluded detection) from 1 to 20 times (a) increased the association effect on a subsequent lexical decision, but had no effect on (b) detectability or (c) the semantic relatedness of forced guesses of the masked word. It is proposed that central pattern masking has little effect on visual processing itself (while peripheral energy masking does), but affects availability of records of the results of those processes to consciousness. Perceptual processing itself is unconscious and automatically proceeds to all levels of analysis and redescription available to the perceiver. The general importance of these findings is to cast doubt on the paradigm assumption that representations yielded by perceptual analysis are identical to and directly reflected by phenomenal percepts.},
}
@article{buxbaum_function_2000-1,
	abstract = {Abstract Several accounts of the semantic system posit that function information plays a critical role in the representations of man-made objects. Alternative possibilities are that man-made objects such as tools are organized according to manner of manipulation, or that both function and manipulation information figure importantly and distinctly in man-made object representations. An agnosic patient, {FB}, reported by Sirigu et al. (Brain 1991; 114: 727-41) provides support for the latter view. {FB} was able to demonstrate how to manipulate objects whose function he did not recognize. We now report two severely apraxic patients whose performance, together with that of {FBI} indicates that function and manipulation information may doubly dissociate. On 'declarative' semantic tests not requiring gesture production, our subjects demonstrate severely impaired manipulation knowledge in the context of relatively intact (and, in one subject, perfectly unimpaired) function knowledge. The double dissociation provides further support for the notion that function and manipulation knowledge are critical and distinct features of the representations of manipulable man-made objects.},
}
@article{liu_language_2010,
}
@article{gaffan_spurious_1993,
	abstract = {Patients with visual associative agnosia have a particular difficulty in identifying visually presented living things (plants and animals) as opposed to nonliving things. It has been claimed that this effect cannot be explained by differences in the inherent visual discriminability of living and nonliving things. To test this claim further, we performed two experiments with normal subjects. In Experiment 1 normal human observers were asked to identify objects in tachistoscopically presented line drawings. They made more errors with living things than with nonliving things. In Experiment 2 normal monkeys learned to discriminate among the same line drawings for food reward. They made many more errors in discriminating among living things than nonliving things. Agnosic patients' responses to the same line drawings were made available to us for correlative analysis with the subjects' responses to these drawings in Experiments 1 and 2. We conclude that a category-specific visual agnosia for living things can arise as a consequence of a modality-specific but not category-specific impairment in visual representation, since living things are more similar to each other visually than nonliving things are.},
}
@article{devlin_category-specific_1998,
	abstract = {Category-specific semantic impairments have been explained in terms of preferential damage to different types of features (e.g., perceptual vs. functional). This account is compatible with cases in which the impairments were the result of relatively focal lesions, as in herpes encephalitis. Recently, however, there have been reports of category-specific impairments associated with Alzheimer's disease, in which there is more widespread, patchy damage. We present experiments with a connectionist model that show how ficategory-specificfl impairments can arise in cases of both localized and wide-spread damage; in this model, types of features are topographically organized, but specific categories are not. These effects mainly depend on differences between categories in the distribution of correlated features. The model's predictions about degree of impairment on natural kinds and artifacts over the course of semantic deterioration are shown to be consistent with existing patient data. The model shows how the probabilistic nature of damage in Alzheimer's disease interacts with the structure of semantic memory to yield different patterns of impairment between patients and categories over time.},
}
@article{witzel_is_2011,
	abstract = {According to the lateralized category effect for color, the influence of color category borders on color perception in fast reaction time tasks is significantly stronger in the right visual field than in the left. This finding has directly related behavioral category effects to the hemispheric lateralization of language. Multiple succeeding articles have built on these findings. We ran ten different versions of the two original experiments with overall 230 naive observers. We carefully controlled the rendering of the stimulus colors and determined the genuine color categories with an appropriate naming method. Congruent with the classical pattern of a category effect, reaction times in the visual search task were lower when the two colors to be discriminated belonged to different color categories than when they belonged to the same category. However, these effects were not lateralized: They appeared to the same extent in both visual fields.},
}
@article{brodersen_model-based_2011,
	abstract = {Conventional decoding methods in neuroscience aim to predict discrete brain states from multivariate correlates of neural activity. This approach faces two important challenges. First, a small number of examples are typically represented by a much larger number of features, making it hard to select the few informative features that allow for accurate predictions. Second, accuracy estimates and information maps often remain descriptive and can be hard to interpret. In this paper, we propose a model-based decoding approach that addresses both challenges from a new angle. Our method involves (i) inverting a dynamic causal model of neurophysiological data in a trial-by-trial fashion; (ii) training and testing a discriminative classifier on a strongly reduced feature space derived from trial-wise estimates of the model parameters; and (iii) reconstructing the separating hyperplane. Since the approach is model-based, it provides a principled dimensionality reduction of the feature space; in addition, if the model is neurobiologically plausible, decoding results may offer a mechanistically meaningful interpretation. The proposed method can be used in conjunction with a variety of modelling approaches and brain data, and supports decoding of either trial or subject labels. Moreover, it can supplement evidence-based approaches for model-based decoding and enable structural model selection in cases where Bayesian model selection cannot be applied. Here, we illustrate its application using dynamic causal modelling ({DCM)} of electrophysiological recordings in rodents. We demonstrate that the approach achieves significant above-chance performance and, at the same time, allows for a neurobiological interpretation of the results.},
}
@article{epstein_parahippocampal_1999,
	abstract = {The parahippocampal place area ({PPA)} has been demonstrated to respond more strongly in {fMRI} to scenes depicting places than to other kinds of visual stimuli. Here, we test several hypotheses about the function of the {PPA.} We find that {PPA} activity (1) is not affected by the subjects' familiarity with the place depicted, (2) does not increase when subjects experience a sense of motion through the scene, and (3) is greater when viewing novel versus repeated scenes but not novel versus repeated faces. Thus, we find no evidence that the {PPA} is involved in matching perceptual information to stored representations in memory, in planning routes, or in monitoring locomotion through the local or distal environment but some evidence that it is involved in encoding new perceptual information about the appearance and layout of scenes.},
}
@article{schwartz_analysis_1995,
	abstract = {Abstract We present a patient, {JK}, who developed a profound disturbance of routine action production subsequent to closed head injury. Part I of the study describes the disorder as it was expressed in tasks of everyday living. {JK} demonstrated the features of frontal apraxia, including extreme vulnerability to object substitution and object misuse. In Part {II} we carried out a neuro-psychological assessment targeted at {JK's} recognition and understanding of objects and implements. This assessment showed a surprising preservation of low- and high-level vision, as well as semantic knowledge relevant to everyday tasks. It also revealed some areas of weakness, notably in access to semantic memory and gesture recall. It is widely accepted that everyday action tasks are planned and executed automatically, that is, with minimal involvement of executive control processes. {JK's} defects in the areas of semantic memory and gesture recall may have compromised the automaticity of his action planning, but this alone cannot account for his flagrant everyday-action disorder. We speculate, without direct evidence, that the executive control processes (supervisory attention/working memory) that support non-automatic action planning might also have been compromised in {JK.} If so, it suggests a new account of frontal apraxia, which rests on a combination of deficits: (1) disruption of the fast, automatic retrieval of information from memory stores relevant to action planning; and (2) pathological depletion of executive resources necessary to plan and execute routine behaviour when automaticity fails.},
}
@article{dilkina_conceptual_2012,
	abstract = {Current views of semantic memory share the assumption that conceptual representations are based on multimodal experience, which activates distinct modality-specific brain regions. This proposition is widely accepted, yet little is known about how each modality contributes to conceptual knowledge and how the structure of this contribution varies across these multiple information sources. We used verbal feature lists, features from drawings, and verbal co-occurrence statistics from latent semantic analysis to examine the informational structure in four domains of knowledge: perceptual, functional, encyclopedic, and verbal. The goals of the analysis were three-fold: (1) to assess the structure within individual modalities; (2) to compare structures between modalities; and (3) to assess the degree to which concepts organize categorically or randomly. Our results indicated significant and unique structure in all four modalities: perceptually, concepts organize based on prominent features such as shape, size, color, and parts; functionally, they group based on use and interaction; encyclopedically, they arrange based on commonality in location or behavior; and verbally, they group associatively or relationally. Visual/perceptual knowledge gives rise to the strongest hierarchical organization and is closest to classic taxonomic structure. Information is organized somewhat similarly in the perceptual and encyclopedic domains, which differs significantly from the structure in the functional and verbal domains. Notably, the verbal modality has the most unique organization, which is not at all categorical but also not random. The idiosyncrasy and complexity of conceptual structure across modalities raise the question of how all of these modality-specific experiences are fused together into coherent, multifaceted yet unified concepts. Accordingly, both methodological and theoretical implications of the present findings are discussed.},
}
@article{puce_temporal_1998,
	abstract = {We sought to determine whether regions of extrastriate visual cortex could be activated in subjects viewing eye and mouth movements that occurred within a stationary face. Eleven subjects participated in three to five functional magnetic resonance imaging sessions in which they viewed moving eyes, moving mouths, or movements of check patterns that occurred in the same spatial location as the eyes or mouth. In each task, the stimuli were superimposed on a radial background pattern that continually moved inward to control for the effect of movement per se. Activation evoked by the radial background was assessed in a separate control task. Moving eyes and mouths activated a bilateral region centered in the posterior superior temporal sulcus ({STS).} The moving check patterns did not appreciably activate the {STS} or surrounding regions. The activation by moving eyes and mouths was distinct from that elicited by the moving radial background, which primarily activated the posterior-temporal-occipital fossa and the lateral occipital sulcus---a region corresponding to area {MT/V5.} Area {MT/V5} was also strongly activated by moving eyes and to a lesser extent by other moving stimuli. These results suggest that a superior temporal region centered in the {STS} is preferentially involved in the perception of gaze direction and mouth movements. This region of the {STS} may be functionally related to nearby superior temporal regions thought to be involved in lip-reading and in the perception of hand and body movement.},
}
@article{caramazza_domain-specific_1998,
	abstract = {We claim that the animate and inanimate conceptual categories represent evolutionarily adapted domain-specific knowledge systems that are subserved by distinct neural mechanisms, thereby allowing for their selective impairment in conditions of brain damage. On this view, (some of) the category-specific deficits that have recently been reported in the cognitive neuropsychological literature---for example, the selective damage or sparing of knowledge about animals---are truly categorical effects. Here, we articulate and defend this thesis against the dominant, reductionist theory of category-specific deficits, which holds that the categorical nature of the deficits is the result of selective damage to noncategorically organized visual or functional semantic subsystems. On the latter view, the sensory/functional dimension provides the fundamental organizing principle of the semantic system. Since, according to the latter theory, sensory and functional properties are differentially important in determining the meaning of the members of different semantic categories, selective damage to the visual or the functional semantic subsystem will result in a category-like deficit. A review of the literature and the results of a new case of category-specific deficit will show that the domain-specific knowledge framework provides a better account of category-specific deficits than the sensory/functional dichotomy theory.},
}
@article{plunkett_connectionist_1999,
	abstract = {The acquisition of English noun and verb morphology is modeled using a single-system connectionist network. The network is trained to produce the plurals and past tense forms of a large corpus of monosyllabic English nouns and verbs. The developmental trajectory of network performance is analyzed in detail and is shown to mimic a number of important features of the acquisition of English noun and verb morphology in young children. These include an initial error-free period of performance on both nouns and verbs followed by a period of intermittent over-regularization of irregular nouns and verbs. Errors in the model show evidence of phonological conditioning and frequency effects. Furthermore, the network demonstrates a strong tendency to regularize denominal verbs and deverbal nouns and masters the principles of voicing assimilation. Despite their incorporation into a single-system network, nouns and verbs exhibit some important differences in their profiles of acquisition. Most importantly, noun inflections are acquired earlier than verb inflections. The simulations generate several empirical predictions that can be used to evaluate further the suitability of this type of cognitive architecture in the domain of inflectional morphology.},
}
@article{dilkina_conceptual_2013-1,
	abstract = {Current views of semantic memory share the assumption that conceptual representations are based on multimodal experience, which activates distinct modality-specific brain regions. This proposition is widely accepted, yet little is known about how each modality contributes to conceptual knowledge and how the structure of this contribution varies across these multiple information sources. We used verbal feature lists, features from drawings, and verbal co-occurrence statistics from latent semantic analysis to examine the informational structure in four domains of knowledge: perceptual, functional, encyclopedic, and verbal. The goals of the analysis were three-fold: (1) to assess the structure within individual modalities; (2) to compare structures between modalities; and (3) to assess the degree to which concepts organize categorically or randomly. Our results indicated significant and unique structure in all four modalities: perceptually, concepts organize based on prominent features such as shape, size, color, and parts; functionally, they group based on use and interaction; encyclopedically, they arrange based on commonality in location or behavior; and verbally, they group associatively or relationally. Visual/perceptual knowledge gives rise to the strongest hierarchical organization and is closest to classic taxonomic structure. Information is organized somewhat similarly in the perceptual and encyclopedic domains, which differs significantly from the structure in the functional and verbal domains. Notably, the verbal modality has the most unique organization, which is not at all categorical but also not random. The idiosyncrasy and complexity of conceptual structure across modalities raise the question of how all of these modality-specific experiences are fused together into coherent, multifaceted yet unified concepts. Accordingly, both methodological and theoretical implications of the present findings are discussed.},
}
@article{tomasino_introducing_2013,
	abstract = {This editorial discusses the role of sensory and motor information in representing the conceptual knowledge in the brain. Indeed, the extent to which conceptual representations are held to be grounded in sensory and motor systems has yielded different hypotheses as to how conceptual knowledge is organized. In order to promote the development of the neuroscientific investigation and discussion on how conceptual knowledge is represented, this Frontiers Research Topic aimed at bringing together contributions from researchers whose interests focus on the action-related and abstract concepts processing. Studies using {fMRI} also evidenced that the sensorimotor activation is not solely triggered bottom-up by action word stimuli. Flexibility is characterized by the relative presence or absence of activation in motor and perceptual brain areas. In addition, the involvement of sensorimotor areas may be subject to a top-down modulation which explicitly or automatically select the type of strategy adopted while processing language. ({PsycINFO} Database Record (c) 2013 {APA}, all rights reserved)},
}
@book{shallice_neuropsychology_1988,
	abstract = {As a neuropsychologist, Tim Shallice considers the general question of what can be learned about the operation of the normal cognitive system--including perception, memory, and language--from the study of the cognitive difficulties arising from neurological damage and disease. He distinguishes two type of theories of normal function--primarily modular and primarily non-modular--and argues that the problems of making valid inferences about normal function from studies of brain-damaged subjects are more severe in the latter. He first analyzes five areas in which modularity can be assumed. He then examines these inferences, from group studies, from individual case studies, and from group studies, and from non-modular systems, more theoretically. Finally he considers five areas where theories of normal function are relatively undeveloped and neuropsychologists provide counter-intuitive phenomena and guides to theory-building.},
}
@book{moore_proceedings_2001,
	abstract = {This volume features the complete text of the material presented at the Twenty-Third Annual Conference of the Cognitive Science Society. As in previous years, the symposium included an interesting mixture of papers on many topics from researchers with diverse backgrounds and different goals, presenting a multifaceted view of cognitive science. This volume includes all papers, posters, and summaries of symposia presented at the leading conference that brings cognitive scientists together. The 2001 Cognitive Science meeting dealt with issues of representing and modeling cognitive processes, as they appeal to scholars in all subdisciplines that comprise cognitive science: psychology, computer science, neuroscience, linguistics, and philosophy.},
}
@article{liu_choice-related_2013,
	abstract = {Functional links between neuronal activity and perception are studied by examining trial-by-trial correlations (choice probabilities) between neural responses and perceptual decisions. We addressed fundamental issues regarding the nature and origin of choice probabilities by recording from subcortical (brainstem and cerebellar) neurons in rhesus monkeys during a vestibular heading discrimination task. Subcortical neurons showed robust choice probabilities that exceeded those seen in cortex (area {MSTd)} under identical conditions. The greater choice probabilities of subcortical neurons could be predicted by a stronger dependence of correlated noise on tuning similarity, as revealed by population decoding. Significant choice probabilities were observed almost exclusively for neurons that responded selectively to translation, whereas neurons that represented net gravito-inertial acceleration did not show choice probabilities. These findings suggest that the emergence of choice probabilities in the vestibular system depends on a critical signal transformation that occurs in subcortical pathways to distinguish translation from orientation relative to gravity.},
}
@article{acosta-cabronero_atrophy_2011,
	abstract = {Semantic dementia, in which there is progressive deterioration of semantic knowledge, is associated with focal, typically asymmetric, temporal lobe degeneration. The ventrorostral temporal lobe is most severely affected and there is concordance between atrophy and reduced metabolic activity. In this study, we confirmed the veracity of this claim using {18F-fluorodeoxyglucose} positron emission tomography and anatomical magnetic resonance images. The principal aim, however, was to understand the impact on neuronal projections from the ventrorostral temporal cortex lesion by studying the full extent of white matter changes, with no a priori assumptions about the nature or spatial location of the tracts involved. Using an unbiased voxel-wise approach known as tract-based spatial statistics, we compared results of whole-brain diffusion tensor imaging---absolute metrics of axial, radial and mean diffusion as well as fractional anisotropy---from 10 patients with mild/moderate semantic dementia and 21 matched controls. Distributions of increased absolute diffusivity and reduced fractional anisotropy for patients with semantic dementia were spatially concordant with each other. Abnormalities in all metrics were highly statistically significant in ventrorostral temporal white matter, more extreme on the left side, thus closely matching results from structural and functional imaging of grey matter. The most sensitive marker of change was radial diffusion. Local white matter tract abnormalities extended rostrally towards the frontal lobe and dorsocaudally towards the superior temporal and supramarginal gyri. To examine more remote changes, we performed a skeletonized probabilistic tractography analysis---'seeding' the rostral temporal voxels identified as abnormal in the patient group---in a healthy control group. Three major neural pathways were found to emanate from this 'seed region': uncinate, arcuate and inferior longitudinal fasciculi. At a less conservative threshold, tensor abnormalities in the semantic dementia group mapped onto the tractographies for the uncinate and arcuate bundles well beyond the rostral temporal lobe; this was not the case for the inferior longitudinal bundle, where abnormalities in semantic dementia did not extend caudal to the atrophic/hypometabolic zone. The results offer direct evidence for how the ventrorostral temporal lesion, proposed to be responsible for deteriorating semantic knowledge in semantic dementia and separate from 'classic' language areas, is associated with degeneration of efferent white matter projections to such language areas.},
}
@article{roffwarg_ontogenetic_1966,
	url = {http://www.sciencemag.org.ezproxy.library.wisc.edu/search?volume=152&firstpage=604&submit=yes&submit.x=0&submit.y=0&submit=Search&doi=&submit=yes&fulltext=&andorexactfulltext=and&titleabstract=&andorexacttitleabs=and&title=&andorexacttitle=and&author1=&author2=&fmonth=&fyear=&tmonth=&tyear=&hits=10&sortspec=relevance&submit=yes&resourcetype=HWCIT%7CHWELTR&tocsectionid=all&submit=yes},
}
@article{ryali_sparse_2010-2,
	abstract = {Multivariate pattern recognition methods are increasingly being used to identify multiregional brain activity patterns that collectively discriminate one cognitive condition or experimental group from another, using {fMRI} data. The performance of these methods is often limited because the number of regions considered in the analysis of {fMRI} data is large compared to the number of observations (trials or participants). Existing methods that aim to tackle this dimensionality problem are less than optimal because they either over-fit the data or are computationally intractable. Here, we describe a novel method based on logistic regression using a combination of L1 and L2 norm regularization that more accurately estimates discriminative brain regions across multiple conditions or groups. The L1 norm, computed using a fast estimation procedure, ensures a fast, sparse and generalizable solution; the L2 norm ensures that correlated brain regions are included in the resulting solution, a critical aspect of {fMRI} data analysis often overlooked by existing methods. We first evaluate the performance of our method on simulated data and then examine its effectiveness in discriminating between well-matched music and speech stimuli. We also compared our procedures with other methods which use either L1-norm regularization alone or support vector machine based feature elimination. On simulated data, our methods performed significantly better than existing methods across a wide-range of contrast-to-noise ratios and feature prevalence rates. On experimental {fMRI} data, our methods were more effective in selectively isolating a distributed fronto-temporal network that distinguished between brain regions known to be involved in speech and music processing. These findings suggest that our method is not only computationally efficient, but it also achieves the twin objectives of identifying relevant discriminative brain regions and accurately classifying {fMRI} data.},
}
@article{campanella_semantic_2009,
}
@article{kalenine_critical_2010-1,
	abstract = {A number of conflicting claims have been advanced regarding the role of the left inferior frontal gyrus, inferior parietal lobe and posterior middle temporal gyrus in action recognition, driven in part by an ongoing debate about the capacities of putative mirror systems that match observed and planned actions. We report data from 43 left hemisphere stroke patients in two action recognition tasks in which they heard and saw an action word ('hammering') and selected from two videoclips the one corresponding to the word. In the spatial recognition task, foils contained errors of body posture or movement amplitude/timing. In the semantic recognition task, foils were semantically related (sawing). Participants also performed a comprehension control task requiring matching of the same verbs to objects (hammer). Using regression analyses controlling for both the comprehension control task and lesion volume, we demonstrated that performance in the semantic gesture recognition task was predicted by per cent damage to the posterior temporal lobe, whereas the spatial gesture recognition task was predicted by per cent damage to the inferior parietal lobule. A whole-brain voxel-based lesion symptom-mapping analysis suggested that the semantic and spatial gesture recognition tasks were associated with lesioned voxels in the posterior middle temporal gyrus and inferior parietal lobule, respectively. The posterior middle temporal gyrus appears to serve as a central node in the association of actions and meanings. The inferior parietal lobule, held to be a homologue of the monkey parietal mirror neuron system, is critical for encoding object-related postures and movements, a relatively circumscribed aspect of gesture recognition. The inferior frontal gyrus, on the other hand, was not predictive of performance in any task, suggesting that previous claims regarding its role in action recognition may require refinement.},
}
@article{rish_schizophrenia_2013,
	abstract = {Schizophrenia is a psychiatric disorder that has eluded characterization in terms of local abnormalities of brain activity, and is hypothesized to affect the collective, ``emergent'' working of the brain. Indeed, several recent publications have demonstrated that functional networks in the schizophrenic brain display disrupted topological properties. However, is it possible to explain such abnormalities just by alteration of local activation patterns? This work suggests a negative answer to this question, demonstrating that significant disruption of the topological and spatial structure of functional {MRI} networks in schizophrenia (a) cannot be explained by a disruption to area-based task-dependent responses, i.e. indeed relates to the emergent properties, (b) is global in nature, affecting most dramatically long-distance correlations, and (c) can be leveraged to achieve high classification accuracy (93\%) when discriminating between schizophrenic vs control subjects based just on a single {fMRI} experiment using a simple auditory task. While the prior work on schizophrenia networks has been primarily focused on discovering statistically significant differences in network properties, this work extends the prior art by exploring the generalization (prediction) ability of network models for schizophrenia, which is not necessarily captured by such significance tests.},
}
@article{buxbaum_knowledge_2002,
	abstract = {An influential account of selective semantic deficits posits that visual features are heavily weighted in the representations of animals, whereas information about function is central in the representations of tools (e.g., Warrington \&amp; Shallice, 1984). An alternative account proposes that information about all types of objects---animate and inanimate alike---is represented in a distributed semantic architecture by verbal--propositional, tactile, visual, and proprioceptive--motor nodes, reflecting the degree to which these systems were activated when the knowledge was acquired (e.g., Allport, 1985). We studied a group of left hemisphere chronic stroke patients, some of whom were apraxic, with measures of declarative tool and animal knowledge, body part knowledge, and function and manipulation knowledge of artifacts. Apraxic (n=7) and nonapraxic (n=6) subjects demonstrated a double dissociation of performance on tests of tool and animal knowledge, suggesting that the apraxic group was not simply more severely impaired overall. Apraxics were relatively impaired in manipulation knowledge, whereas nonapraxics tended to be relatively impaired in function knowledge. Apraxics were also more impaired with body parts than nonapraxics. The association of gestural praxis, tool knowledge, body part knowledge, and manipulation knowledge suggests a coherent basis for the organization of semantic artifact knowledge in frontoparietal cortical regions specialized for sensorimotor functions, and thus provides support for the distributed architecture account of the semantic system.},
}
@article{rogers_semantic_2006,
	abstract = {Using semantic dementia ({SD)} as a reference point, the authors assessed semantic memory in four other neurodegenerative disorders: progressive nonfluent aphasia ({PNFA)}, frontal variant frontotemporal dementia ({fvFTD)}, Alzheimer's disease ({AD)}, and posterior cortical atrophy ({PCA).} Individuals with {SD} were more impaired than other groups on semantic measures and showed a characteristic pattern across tasks: category fluency ({CF)} worse than letter fluency ({LF)}, naming worse than comprehension, and visual and verbal comprehension equally affected, suggesting disruption to an amodal semantic system. Individuals with {AD} demonstrated a similar pattern to a milder degree. Although {PNFA}, {fvFTD}, and {PCA} groups had abnormal scores (relative to controls) on most semantic measures, their differing patterns across measures indicate that the apparent semantic impairment in these conditions is largely secondary to other factors. ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved). (journal abstract)},
}
@article{pelphrey_functional_2005,
	abstract = {Passive viewing of biological motion engages extensive regions of the posterior temporal-occipital cortex in humans, particularly within and nearby the superior temporal sulcus ({STS).} Relatively little is known about the functional specificity of this area. Some recent studies have emphasized the perceived intentionality of the motion as a potential organizing principle, while others have suggested the existence of a somatotopy based upon the limb perceived in motion. Here we conducted an event-related functional magnetic resonance imaging experiment to compare activity elicited by movement of the eyes, mouth or hand. Each motion evoked robust activation in the right posterior temporal-occipital cortex. While there was substantial overlap of the activation maps in this region, the spatial distribution of hemodynamic response amplitudes differentiated the movements. Mouth movements elicited activity along the mid-posterior {STS} while eye movements elicited activity in more superior and posterior portions of the right posterior {STS} region. Hand movements activated more inferior and posterior portions of the {STS} region within the posterior continuing branch of the {STS.} Hand-evoked activity also extended into the inferior temporal, middle occipital and lingual gyri. This topography may, in part, reflect the role of particular body motions in different functional activities.},
}
@article{yang_deconstructing_2012,
	abstract = {In this paper, we asked to what extent the depth of interocular suppression engendered by continuous flash suppression ({CFS)} varies depending on spatiotemporal properties of the suppressed stimulus and {CFS} suppressor. An answer to this question could have implications for interpreting the results in which {CFS} influences the processing of different categories of stimuli to different extents. In a series of experiments, we measured the selectivity and depth of suppression (i.e., elevation in contrast detection thresholds) as a function of the visual features of the stimulus being suppressed and the stimulus evoking suppression, namely, the popular {``Mondrian''} {CFS} stimulus (N. Tsuchiya \& C. Koch, 2005). First, we found that {CFS} differentially suppresses the spatial components of the suppressed stimulus: Observers' sensitivity for stimuli of relatively low spatial frequency or cardinally oriented features was more strongly impaired in comparison to high spatial frequency or obliquely oriented stimuli. Second, we discovered that this feature-selective bias primarily arises from the spatiotemporal structure of the {CFS} stimulus, particularly within information residing in the low spatial frequency range and within the smooth rather than abrupt luminance changes over time. These results imply that this {CFS} stimulus operates by selectively attenuating certain classes of low-level signals while leaving others to be potentially encoded during suppression. These findings underscore the importance of considering the contribution of low-level features in stimulus-driven effects that are reported under {CFS.}},
}
@article{pessoa_fate_2005,
	abstract = {The evidence for amygdala processing of emotional items outside the focus of attention is mixed. We hypothesized that differences in attentional demands may, at least in part, explain prior discrepancies. In the present study, attention was manipulated by parametrically varying the difficulty of a central task, allowing us to compare responses evoked by unattended emotion-laden faces while the attentional load of a central task was varied. Reduced responses to unattended emotional stimuli may also reflect an active suppression of amygdala responses during difficult non-emotional tasks (cognitive modulation). To explicitly assess cognitive modulation, an experimental condition was used in which subjects performed the central task without the presence of irrelevant emotional stimuli. Our findings revealed that amygdala responses were modulated by the focus of attention. Stronger responses were evoked during a sex task (when faces were attended) relative to a bar-orientation task (when faces were unattended). Critically, a valence effect was observed in the right amygdala during low attentional demand conditions, but not during medium or high demand conditions. Moreover, performing a difficult non-emotional task alone was associated with signal decreases in a network of brain regions, including the amygdala. Such robust decreases demonstrate that cognitive modulation comprises a powerful factor in determining amygdala responses. Collectively, our findings reveal that both attentional resources and cognitive modulation govern the fate of unattended fearful faces in the amygdala.},
}
@article{bbockmole_semantic_2010,
	abstract = {When encountering familiar scenes, observers can use item-specific memory to facilitate the guidance of attention to objects appearing in known locations or configurations. Here, we investigated how memory for relational contingencies that emerge across different scenes can be exploited to guide attention. Participants searched for letter targets embedded in pictures of bedrooms. In a between-subjects manipulation, targets were either always on a bed pillow or randomly positioned. When targets were systematically located within scenes, search for targets became more efficient. Importantly, this learning transferred to bedrooms without pillows, ruling out learning that is based on perceptual contingencies. Learning also transferred to living room scenes, but it did not transfer to kitchen scenes, even though both scene types contained pillows. These results suggest that statistical regularities abstracted across a range of stimuli are governed by semantic expectations regarding the presence of target-predicting local landmarks. Moreover, explicit awareness of these contingencies led to a central tendency bias in recall memory for precise target positions that is similar to the spatial category effects observed in landmark memory. These results broaden the scope of conditions under which contextual cuing operates and demonstrate how semantic memory plays a causal and independent role in the learning of associations between objects in real-world scenes. ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved) (journal abstract)},
}
@article{himmelbach_dorsal_2005-1,
	abstract = {In monkeys and humans, two functionally specialized cortical streams of visual processing emanating from V1 have been proposed: a dorsal, action-related system and a ventral, perception-related pathway. Traditionally, a separate organization of the two streams is assumed; the extent of functional interaction is unknown. After lesions of the dorsal stream in patients with optic ataxia, it has recently been shown that the ventral perception-related system might contribute to visuo-motor processing if movements rely on remembered target positions. The ventral pathway thus seemed to participate in goal-directed movements, a function that previously has been assigned exclusively to the dorsal stream. We wondered whether different types of pointing movements are controlled by switching between two separated cortical pathways or whether a variable interaction of interconnected systems should be assumed. Our study investigated two acute stroke patients with optic ataxia following lesions of the dorsal stream in a delayed pointing task. The delays ranged from 0 to 10 sec. The patients' pointing error decreased in a linear manner with the length of time. The finding suggests a gradual change between dorsal and ventral control of reaching behavior, rather than a sudden switch between two separated cortical processing streams. Although our observations with two patients require further validation, the results suggest that the ventral and dorsal systems interact closely in the sensorimotor control of reaching behavior.},
}
@article{vandenberghe_functional_1996,
}
@article{buxbaum_action_2010,
	abstract = {Scientific interest in the relationship between cognition and action has increased markedly in the past several years, fueled by the discovery of mirror neurons in monkey prefrontal and parietal cortex and by the emergence of a movement in cognitive psychology, termed the embodied cognition framework, which emphasizes the role of simulation in cognitive representations. Guided by a functional neuroanatomic model called the Two Action Systems account, which posits numerous points of differentiation between structure- and function-based actions, we focus on two of the major issues under recent scrutiny: the relationship between representations for action production and recognition, and the role of action in object representations. We suggest that mirror neurons in humans are not critical for full action understanding, and that only function-based (and not structure-based) action is a component of embodied object concepts.},
}
@article{rolls_neurophysiology_1999,
	abstract = {Backward masking can potentially provide evidence of the time needed for visual processing, a fundamental constraint that must be incorporated into computational models of vision. Although backward masking has been extensively used psychophysically, there is little direct evidence for the effects of visual masking on neuronal responses. To investigate the effects of a backward masking paradigm on the responses of neurons in the temporal visual cortex, we have shown that the response of the neurons is interrupted by the mask. Under conditions when humans can just identify the stimulus, with stimulus onset asynchronies ({SOA)} of 20 msec, neurons in macaques respond to their best stimulus for approximately 30 msec. We now quantify the information that is available from the responses of single neurons under backward masking conditions when two to six faces were shown. We show that the information available is greatly decreased as the mask is brought closer to the stimulus. The decrease is more marked than the decrease in firing rate because it is the selective part of the firing that is especially attenuated by the mask, not the spontaneous firing, and also because the neuronal response is more variable at short {SOAs.} However, even at the shortest {SOA} of 20 msec, the information available is on average 0.1 bits. This compares to 0.3 bits with only the 16-msec target stimulus shown and a typical value for such neurons of 0.4 to 0.5 bits with a 500-msec stimulus. The results thus show that considerable information is available from neuronal responses even under backward masking conditions that allow the neurons to have their main response in 30 msec. This provides evidence for how rapid the processing of visual information is in a cortical area and provides a fundamental constraint for understanding how cortical information processing operates.},
}
@article{van_gerven_interpreting_2009-1,
}
@article{rogers_object_2003,
	abstract = {Although patients with semantic deficits can sometimes show good performance on tests of object decision, we present evidence that this pattern applies when nonsense-objects do not respect the regularities of the domain. In a newly designed test of object-decision, 20 patients with semantic dementia viewed line drawings of a real and chimeric animal side-by-side, and were asked to decide which was real. The real animal was either more typical (real {\textgreater} nonreal) or less typical (nonreal {\textgreater} real) than the chimera. Performance was significantly better in the real {\textgreater} nonreal condition, and success in both conditions was modulated by patients' degree of semantic impairment. A similar effect of item typicality was revealed in a subset of items selected from a standard test battery. Object-decision scores were highly correlated with other pictorial and verbal assessments of conceptual knowledge, suggesting that impaired performance on all tasks resulted from the degradation of a unitary underlying system.},
}
@book{hastie_elements_2005,
}
@article{conway_sequential_2001,
	abstract = {Sequential learning plays a role in a variety of common tasks, such as human language processing, animal communication, and the learning of action sequences. In this article, we investigate sequential learning in non-human primates from a comparative perspective, focusing on three areas: the learning of arbitrary, fixed sequences; statistical learning; and the learning of hierarchical structure. Although primates exhibit many similarities to humans in their performance on sequence learning tasks, there are also important differences. Crucially, non-human primates appear to be limited in their ability to learn and represent the hierarchical structure of sequences. We consider the evolutionary implications of these differences and suggest that limitations in sequential learning may help explain why non-human primates lack human-like language.},
}
@article{tomasino_at_2013,
	abstract = {Classical cognitive theories hold that word representations in the brain are abstract and amodal, and are independent of the objects' sensorimotor properties they refer to. An alternative hypothesis emphasizes the importance of bodily processes in cognition: the representation of a concept appears to be crucially dependent upon perceptual-motor processes that relate to it. Thus, understanding action-related words would rely upon the same motor structures that also support the execution of the same actions. In this context, motor simulation represents a key component. Our approach is to draw parallels between the literature on mental rotation and the literature on action verb/sentence processing. Here we will discuss recent studies on mental imagery, mental rotation, and language that clearly demonstrate how motor simulation is neither automatic nor necessary to language understanding. These studies have shown that motor representations can or cannot be activated depending on the type of strategy the participants adopt to perform tasks involving motor phrases. On the one hand, participants may imagine the movement with the body parts used to carry out the actions described by the verbs (i.e., motor strategy); on the other, individuals may solve the task without simulating the corresponding movements (i.e., visual strategy). While it is not surprising that the motor strategy is at work when participants process action-related verbs, it is however striking that sensorimotor activation has been reported also for imageable concrete words with no motor content, for "non-words" with regular phonology, for pseudo-verb stimuli, and also for negations. Based on the extant literature, we will argue that implicit motor imagery is not uniquely used when a body-related stimulus is encountered, and that it is not the type of stimulus that automatically triggers the motor simulation but the type of strategy. Finally, we will also comment on the view that sensorimotor activations are subjected to a top-down modulation.},
}
@article{gainotti_organization_2011,
	abstract = {In recent years, the anatomical and functional bases of conceptual activity have attracted a growing interest. In particular, Patterson and Lambon-Ralph have proposed the existence, in the anterior parts of the temporal lobes, of a mechanism (the 'amodal semantic hub') supporting the interactive activation of semantic representations in all modalities and for all semantic categories. The aim of then present paper is to discuss this model, arguing against the notion of an 'amodal' semantic hub, because we maintain, in agreement with the Damasio's construct of 'higher-order convergence zone', that a continuum exists between perceptual information and conceptual representations, whereas the 'amodal' account views perceptual informations only as a channel through which abstract semantic knowledge can be activated. According to our model, semantic organization can be better explained by two orthogonal higher-order convergence systems, concerning, on one hand, the right vs. left hemisphere and, on the other hand, the ventral vs. dorsal processing pathways. This model posits that conceptual representations may be mainly based upon perceptual activities in the right hemisphere and upon verbal mediation in the left side of the brain. It also assumes that conceptual knowledge based on the convergence of highly processed visual information with other perceptual data (and mainly concerning living categories) may be bilaterally represented in the anterior parts of the temporal lobes, whereas knowledge based on the integration of visual data with action schemata (namely knowledge of actions, body parts and artefacts) may be more represented in the left fronto-temporo-parietal areas.},
}
@article{disner_neural_2011,
	abstract = {In the 40 years since Aaron Beck first proposed his cognitive model of depression, the elements of this model--biased attention, biased processing, biased thoughts and rumination, biased memory, and dysfunctional attitudes and schemas--have been consistently linked with the onset and maintenance of depression. Although numerous studies have examined the neural mechanisms that underlie the cognitive aspects of depression, their findings have not been integrated with Beck's cognitive model. In this Review, we identify the functional and structural neurobiological architecture of Beck's cognitive model of depression. Although the mechanisms underlying each element of the model differ, in general the negative cognitive biases in depression are facilitated by increased influence from subcortical emotion processing regions combined with attenuated top-down cognitive control.},
}
@article{stickgold_visual_2000,
	abstract = {Performance on a visual discrimination task shows longterm improvement after a single training session. When tested within 24 hr of training, improvement, was not observed unless subjects obtained at least 6 hr of postraining sleep prior to retesting, in which case improvement was proportional to the amount of sleep in excess of 6 hr. For subjects averaging 8 hr of sleep, overnight improvement was proportional to the amount of slow wave sleep ({SWS)} in the first quarter of the night, as well as the amount of rapid eye movement sleep ({REM)} in the last quarter. {REM} during the intervening 4 hr did not appear to contribute to improvement. A two-step process, modeling throughput as the product of the amount of early {SWS} and late {REM}, accounts for 80 percent of intersubject variance. These results suggest that, in the case of this visual discrimination task, both {SWS} and {REM} are required to consolidate experience-dependent neuronal changes into a form that supports improved task performance.},
}
@article{cardoso_neuroimaging_2012,
	abstract = {Neuroimaging (for example, functional magnetic resonance imaging) signals are taken as a uniform proxy for local neural activity. By simultaneously recording electrode and neuroimaging (intrinsic optical imaging) signals in alert, task-engaged macaque visual cortex, we recently observed a large anticipatory trial-related neuroimaging signal that was poorly related to local spiking or field potentials. We used these same techniques to study the interactions of this trial-related signal with stimulus-evoked responses over the full range of stimulus intensities, including total darkness. We found that the two signals could be separated, and added linearly over this full range. The stimulus-evoked component was related linearly to local spiking and, consequently, could be used to obtain precise and reliable estimates of local neural activity. The trial-related signal likely has a distinct neural mechanism, however, and failure to account for it properly could lead to substantial errors when estimating local neural spiking from the neuroimaging signal.},
}
@article{chen_glucocorticoid_2012,
	abstract = {Emotionally important events are well remembered. Although memories of emotional experiences are known to be mediated and modulated by stress hormones such as glucocorticoids, little is known about the underlying molecular mechanisms. We found that the hippocampal glucocorticoid receptors that are critically engaged during the formation of long-term inhibitory avoidance memory in rats were coupled to the activation of {CaMKII$alpha$}, {TrkB}, {ERK}, Akt, {PLC$_\Gamma$} and {CREB}, as well as a to a substantial induction of Arc and synaptic {GluA1.} Most of these changes, which are initiated by a nongenomic effect of glucocorticoid receptors, were also downstream of the activation of brain-derived neurotrophic factor ({BDNF).} Hippocampal administration of {BDNF}, but not of other neurotrophins, selectively rescued both the amnesia and the molecular impairments produced by glucocorticoid receptor inhibition. Thus, glucocorticoid receptors mediate long-term memory formation by recruiting the {CaMKII$alpha$-BDNF-CREB--dependent} neural plasticity pathways.},
}
@article{kriegeskorte_circular_2009-1,
	abstract = {A neuroscientific experiment typically generates a large amount of data, of which only a small fraction is analyzed in detail and presented in a publication. However, selection among noisy measurements can render circular an otherwise appropriate analysis and invalidate results. Here we argue that systems neuroscience needs to adjust some widespread practices to avoid the circularity that can arise from selection. In particular, 'double dipping', the use of the same dataset for selection and selective analysis, will give distorted descriptive statistics and invalid statistical inference whenever the results statistics are not inherently independent of the selection criteria under the null hypothesis. To demonstrate the problem, we apply widely used analyses to noise data known to not contain the experimental effects in question. Spurious effects can appear in the context of both univariate activation analysis and multivariate pattern-information analysis. We suggest a policy for avoiding circularity.},
}
@article{maddock_posterior_2003,
	abstract = {Functional imaging studies consistently find that emotional stimuli activate the posterior cingulate cortex, a region that appears to have memory-related functions. However, prior imaging studies have not controlled for non-emotional stimulus features that might activate this region by engaging memory processes unrelated to emotion. This study examined whether emotional words activated the posterior cingulate cortex when these potentially confounding factors were controlled. Sixty-four pleasant and 64 unpleasant words were matched with neutral words on non-emotional features known to influence memory. Eight subjects underwent block-designed functional magnetic resonance imaging scans while evaluating the valence of these words. The posterior cingulate cortex was significantly activated bilaterally during both unpleasant and pleasant compared to neutral words. The strongest activation peak with both unpleasant and pleasant words was observed in the left subgenual cingulate cortex. Anteromedial orbital and left inferior and middle frontal cortices were also activated by both pleasant and unpleasant words. Right amygdala and auditory cortex were activated only by unpleasant words, while left frontal pole was activated only by pleasant words. The results show that activation of the posterior cingulate cortex by emotional stimuli cannot be attributed to the memory-enhancing effects of non-emotional stimulus features. The findings are consistent with the suggestion that this region may mediate interactions of emotional and memory-related processes. The results also extend prior findings that evaluating emotional words consistently activates the subgenual cingulate cortex, and suggest a means of probing this region in patients with mood disorders. Hum. Brain Mapping 18:30--41, 2003. \copywrite 2002 Wiley-Liss, Inc.},
}
@phdthesis{iyer_candidneurodynamical_2013,
	abstract = {Idea generation is a central cognitive activity in humans, and studying the mechanisms of idea generation is important both to understand the creative process better and to produce applications that mimic human creativity. The goal of this research is to explore the neural basis of idea generation in individuals through computational connectionist modeling, and to use the resulting framework to study broader aspects of higher level cognition. The product of this is a model called Context-Adaptive {NeuroDynamical} {IDeation} ({CANDID).} While there have been other models of ideation, {CANDID} attempts to incorporate known information about the actual structures and processes of the brain---at least at an abstract level. Following widely accepted theories of ideation, the model postulates that ideas are conceptual combinations, and that the combinations arise naturally from the dynamics of the neurocognitive system under the influence of contextual information. Concepts, which constitute the fundamental semantic elements of the model, are represented in the system in two ways: 1) amodally via the activity of neural units in a Concept Network ({CN);} and 2) in terms of their sensory, functional and abstract attributes, or features, which are encoded in a neural network termed the Feature Layer ({FL).} Concepts are grouped together into categories based on their functional and/or attribute similarity. The categories are represented as distributed patterns of neural activity in the Dynamic Selector Network ({DSN)}, which confines the ideational dynamics to a context-appropriate cognitive space through a dynamic biasing mechanism---termed ``neurocognitive spotlights'' due to its usage. The system receives information about the context as input, which interacts with the intrinsic dynamics of the {DSN-CN-FL}  idea generation system to generate an itinerant sequence of ideas. These are evaluated by a critic, which models both internal and external evaluative processes. Based on its evaluation, the critic generates a reward signal, which feeds back to the generation system to improve ideation by reinforcing connections and modulating the dynamics. The proposed mechanism for the generation of ideas involves three concurrent and interacting processes: 1) Selecting a context-specific subspace of the overall concept space within which ideas will be sought; 2) Searching productively through this subspace via itinerant neural dynamics; and 3) Modulating and reconfiguring the search process through learning based on evaluative feedback. The system is driven by a context input representing the context and/or goal of ideation, which activates appropriate categories in the {DSN}, biasing the associated concepts in the {CN} to create a context-specific search space. Itinerant dynamics in the biased {CN} generate a productive search path to produce ideas, which are evaluated by the critic. The research in this thesis makes two main contributions: 1) The first comprehensive, biologically plausible neural model of context-dependent ideation---and thinking in general; and 2) A neurodynamical model for constructing context-specific cognitive spaces through the spotlight mechanism. In addition to these, the work also addresses other important issues such as the neural representation of semantic knowledge, the emergence of ideas as metastable attractors, and the formation of category representation. ({PsycINFO} Database Record (c) 2013 {APA}, all rights reserved)},
}
@article{rommers_context-dependent_2012,
	abstract = {Language comprehension involves activating word meanings and integrating them with the sentence context. This study examined whether these routines are carried out even when they are theoretically unnecessary, namely in the case of opaque idiomatic expressions, for which the literal word meanings are unrelated to the overall meaning of the expression. Predictable words in sentences were replaced by a semantically related or unrelated word. In literal sentences, this yielded previously established behavioral and electrophysiological signatures of semantic processing: semantic facilitation in lexical decision, a reduced N400 for semantically related relative to unrelated words, and a power increase in the gamma frequency band that was disrupted by semantic violations. However, the same manipulations in idioms yielded none of these effects. Instead, semantic violations elicited a late positivity in idioms. Moreover, gamma band power was lower in correct idioms than in correct literal sentences. It is argued that the brain's semantic expectancy and literal word meaning integration operations can, to some extent, be ``switched off'' when the context renders them unnecessary. Furthermore, the results lend support to models of idiom comprehension that involve unitary idiom representations.},
}
@article{mesulam_neurology_2009,
}
@article{shapley_r._neural_2002,
}
@inproceedings{rish_sparse_2012-1,
}
@article{dehaene_cerebral_2001,
	abstract = {We used functional magnetic resonance imaging ({fMRI)} and event-related potentials ({ERPs)} to visualize the cerebral processing of unseen masked words. Within the areas associated with conscious reading, masked words activated left extrastriate, fusiform and precentral areas. Furthermore, masked words reduced the amount of activation evoked by a subsequent conscious presentation of the same word. In the left fusiform gyrus, this repetition suppression phenomenon was independent of whether the prime and target shared the same case, indicating that case-independent information about letter strings was extracted unconsciously. In comparison to an unmasked situation, however, the activation evoked by masked words was drastically reduced and was undetectable in prefrontal and parietal areas, correlating with participants' inability to report the masked words.},
}
@article{connolly_representation_2012,
	abstract = {Evidence of category specificity from neuroimaging in the human visual system is generally limited to a few relatively coarse categorical distinctions---e.g., faces versus bodies, or animals versus artifacts---leaving unknown the neural underpinnings of fine-grained category structure within these large domains. Here we use {fMRI} to explore brain activity for a set of categories within the animate domain, including six animal species---two each from three very different biological classes: primates, birds, and insects. Patterns of activity throughout ventral object vision cortex reflected the biological classes of the stimuli. Specifically, the abstract representational space---measured as dissimilarity matrices defined between species-specific multivariate patterns of brain activity---correlated strongly with behavioral judgments of biological similarity of the same stimuli. This biological class structure was uncorrelated with structure measured in retinotopic visual cortex, which correlated instead with a dissimilarity matrix defined by a model of V1 cortex for the same stimuli. Additionally, analysis of the shape of the similarity space in ventral regions provides evidence for a continuum in the abstract representational space---with primates at one end and insects at the other. Further investigation into the cortical topography of activity that contributes to this category structure reveals the partial engagement of brain systems active normally for inanimate objects in addition to animate regions.},
}
@article{chao_attribute-based_1999,
	abstract = {The cognitive and neural mechanisms underlying category-specific knowledge remain controversial. Here we report that, across multiple tasks (viewing, delayed match to sample, naming), pictures of animals and tools were associated with highly consistent, category-related patterns of activation in ventral (fusiform gyrus) and lateral (superior and middle temporal gyri) regions of the posterior temporal lobes. In addition, similar patterns of category-related activity occurred when subjects read the names of, and answered questions about, animals and tools. These findings suggest that semantic object information is represented in distributed networks that include sites for storing information about specific object attributes such as form (ventral temporal cortex) and motion (lateral temporal cortex).},
}
@article{pollak_stress_1998,
	abstract = {Emotion and memory are examined within a developmental framework. The point of departure for this discussion is the study of maltreated children whose traumatic experiences have been linked to difficulties in emotional development. It is suggested that cognitive processes such as memory and attention serve to link experience with emotion and emotion with psychopathology. Thus, an information processing approach is used to explain the development of maltreated children's adaptive and maladaptive coping responses. It is argued that maltreated children's association of affective stimuli with traumatic experiences and memories selectively alters the meaning of emotions for these children. More generally, the role of experience and learning as a component of emotional development is emphasized.},
}
@article{farah_category-specificity_1989,
	abstract = {Studies of agnosia have revealed two apparently orthogonal dimensions along which knowledge may break down. In some cases, knowledge of specific categories (such as living things) seems lost, regardless of the modality being tested. In other cases, knowledge in specific modalities (such as vision) seems lost, regardless of the category of stimuli being tested. These different sets of phenomena suggest different organizations for knowledge in the brain, the first by category and the second by modality. Unfortunately, possible confoundings between category, modality, and difficulty level in the previous studies prevent us from drawing strong conclusions from these data. The present study was aimed at assessing the nature of the breakdown in the semantic memory of a prosopagnosic patient, by orthogonally varying category and modality, while assessing difficulty level. The findings do not implicate a simple categorical or modality-dependent organization of his knowledge, but rather an organization in which both category and modality play a role.},
}
@article{mitte_memory_2008,
	abstract = {Although some theories suggest that anxious individuals selectively remember threatening stimuli, findings remain contradictory despite a considerable amount of research. A quantitative integration of 165 studies with 9,046 participants (clinical and nonclinical samples) examined whether a memory bias exists and which moderator variables influence its magnitude. Implicit memory bias was investigated in lexical decision/stimulus identification and word-stem completion paradigms; explicit memory bias was investigated in recognition and recall paradigms. Overall, effect sizes showed no significant impact of anxiety on implicit memory and recognition. Analyses indicated a memory bias for recall, whose magnitude depended on experimental study procedures like the encoding procedure or retention interval. Anxiety influenced recollection of previous experiences; anxious individuals favored threat-related information. Across all paradigms, clinical status was not significantly linked to effect sizes, indicating no qualitative difference in information processing between anxiety patients and high-anxious persons. The large discrepancy between study effects in recall and recognition indicates that future research is needed to identify moderator variables for avoidant and preferred remembering.},
}
@article{caramazza_drawing_1986,
	abstract = {An analysis of the logic of valid inferences about the structure of normal cognitive processes from the study of impaired cognitive performance in brain-damaged patients is presented. The logic of inferences from group studies and single-case studies is compared. It is shown that given certain assumptions, only the single-case method allows valid inferences about the structure of cognitive systems from the analysis of impaired performance. It is also argued that although the single-case approach is not entirely problem-free, the difficulties encountered are relatively minor.},
}
@article{glenberg_what_1997,
}
@article{landis_emotional_2006-1,
	abstract = {Aphasic patients, in particular global aphasics, may still swear and produce emotional utterances with ease. Based on these clinical observations we investigated emotional word ``reading'' in a series of different experiments over 25 years, not only in aphasic patients, but also in the left ({LVF)} and right ({RVF)} visual fields of healthy subjects, and in a depth-recorded epileptic patient. Across these experiments we found: i) behaviorally a strong emotional word effect in the left visual field (right hemisphere --- {RH)} of normals, correlating well with the emotional word performance of aphasic patients, pointing to a specific role of the right hemisphere; ii) electro-physiologically a specific early (100-140 msec) brain response to emotional words during scalp recordings in healthy subjects subsequent to right visual field (left hemisphere --- {LH)} stimulation, that source localization procedures project to posterior areas of the right hemisphere; iii) preliminary data of a very early (60 msec) activation of the left amygdala in a depth-recorded epileptic patient when the same emotional words were presented to the right visual field (left hemisphere); and iv) a consistent gender difference showing that the above findings might be relevant for men only. Both hemispheres therefore appear to be implicated in emotional word ``reading'' but in different ways. We propose that the left amygdala via extrastriate connections acts as a detector of emotional word content at a very early stage of processing; that this amygdala response subsequently modulates the cortical response to emotional words asymmetrically, rendering the left visual cortex less sensitive to emotional words than that of the right hemisphere; and that this modulation is gender dependent.},
}
@article{mummery_functional_1998,
	abstract = {Studies of patients with brain damage suggest that specific brain regions may be differentially involved in representing/processing certain categories of conceptual knowledge. With regard to the dissociation that has received the most attention--between the domains of living things and artifacts--a debate continues as to whether these category-specific effects reflect neural implementation of categories directly or some more basic properties of brain organization. The present positron emission tomography ({PET)} study addressed this issue by probing explicitly for differential activation associated with written names of objects from the domains of living things or artifacts during similarity judgments about different attributes of these objects. Subjects viewed triads of written object names and selected one of two response words as more similar to a target word according to a specified perceptual attribute (typical color of the objects) or an associative attribute (typical location of the objects). The control task required a similarity judgment about the number of syllables in the target and response words. All tasks were performed under two different stimulus conditions: names of living things and names of artifacts. Judgments for both domains and both attribute types activated an extensive, distributed, left-hemisphere semantic system, but showed some differential activation-particularly as a function of attribute type. The left temporo-occipito-parietal junction showed enhanced activity for judgments about object location, whereas the left anteromedial temporal cortex and caudate nucleus were differentially activated by color judgments. Smaller differences were seen for living and nonliving domains, the positive findings being largely consistent with previous studies using objects; in particular, words denoting artifacts produced enhanced activation in the left posterior middle temporal gyrus. These results suggest that, within a distributed conceptual system activated by words, the more prominent neural distinction relates to type of attribute.},
}
@article{kriegeskorte_representational_2013,
}
@article{harm_phonology_1999,
	abstract = {The development of reading skill and bases of developmental dyslexia were explored using connectionist models. Four issues were examined: the acquisition of phonological knowledge prior to reading, how this knowledge facilitates learning to read, phonological and nonphonological bases of dyslexia, and effects of literacy on phonological representation. Compared with simple feedforward networks, representing phonological knowledge in an attractor network yielded improved learning and generalization. Phonological and surface forms of developmental dyslexia, which are usually attributed to impairments in distinct lexical and nonlexical processing "routes," were derived from different types of damage to the network. The results provide a computationally explicit account of many aspects of reading acquisition using connectionist principles.},
}
@article{tyler_towards_2001,
	abstract = {How is conceptual knowledge organized and represented? Are domains (such as living things) and categories (such as tools, fruit) represented explicitly or can domain and category structure emerge out of a distributed system? Taken at face value, evidence from brain-damaged patients and neuroimaging studies suggests that conceptual knowledge is explicitly structured in independent content-based stores. However, recent analyses of the fine-grained details of semantic impairments, combined with research using connectionist modelling, suggest a different picture -- one in which concepts are represented as patterns of activation over multiple semantic properties within a unitary distributed system. Within this context, category-specific deficits emerge as a result of differences in the structure and content of concepts rather than from explicit divisions of conceptual knowledge in separate stores.},
}
@article{harm_computing_2004,
	abstract = {Are words read visually (by means of a direct mapping from orthography to semantics) or phonologically (by mapping from orthography to phonology to semantics)? The authors addressed this long-standing debate by examining how a large-scale computational model based on connectionist principles would solve the problem and comparing the model's performance to people's. In contrast to previous models, the present model uses an architecture in which meanings are jointly determined by the 2 components, with the division of labor between them affected by the nature of the mappings between codes. The model is consistent with a variety of behavioral phenomena, including the results of studies of homophones and pseudohomophones thought to support other theories, and illustrates how efficient processing can be achieved using multiple simultaneous constraints.},
}
@article{alfonso-reese_what_2002,
	abstract = {To understand why some categorization tasks are more difficult than others, we consider five factors that may affect human performance---namely, covariance complexity, optimal accuracy level with and without internal noise, orientation of the optimal categorization rule, and class separability. We argue that covariance complexity, an information-theoretic measure of complexity, is an excellent predictor of task difficulty. We present an experiment that consists of five conditions using a simulated medical decision-making task. In the task human observers view hundreds of hypothetical patient profiles and classify each profile into Disease Category A or B. Each profile is a continuous-valued, three-dimensional stimulus consisting of three vertical bars, where each bar height represents the result of a medical test. Across the five conditions, covariance complexity was systematically manipulated. Results indicate that variation in performance is largely a function of covariance complexity and partly a function of internal noise. The remaining three factors do not explain performance results. We present a challenge to categorization theorists to design models that account for human performance as predicted by covariance complexity.},
}
@article{stickgold_sleep_2001,
}
@article{kouider_subliminal_2009,
}
@article{brown_color_2011,
	abstract = {The relation between colors and their names is a classic case study for investigating the {Sapir--Whorf} hypothesis that categorical perception is imposed on perception by language. Here, we investigate the {Sapir--Whorf} prediction that visual search for a green target presented among blue distractors (or vice versa) should be faster than search for a green target presented among distractors of a different color of green (or for a blue target among different blue distractors). A. L. Gilbert, T. Regier, P. Kay, and R. B. Ivry (2006) reported that this {Sapir--Whorf} effect is restricted to the right visual field ({RVF)}, because the major brain language centers are in the left cerebral hemisphere. We found no categorical effect at the {Green--Blue} color boundary and no categorical effect restricted to the {RVF.} Scaling of perceived color differences by Maximum Likelihood Difference Scaling ({MLDS)} also showed no categorical effect, including no effect specific to the {RVF.} Two models fit the data: a color difference model based on {MLDS} and a standard opponent-colors model of color discrimination based on the spectral sensitivities of the cones. Neither of these models nor any of our data suggested categorical perception of colors at the {Green--Blue} boundary, in either visual field.},
}
@article{eimer_links_2008,
	abstract = {To study links between rapid {ERP} responses to fearful faces and conscious awareness, a backward-masking paradigm was employed where fearful or neutral target faces were presented for different durations and were followed by a neutral face mask. Participants had to report target face expression on each trial. When masked faces were clearly visible (200 ms duration), an early frontal positivity, a later more broadly distributed positivity, and a temporo-occipital negativity were elicited by fearful relative to neutral faces, confirming findings from previous studies with unmasked faces. These emotion-specific effects were also triggered when masked faces were presented for only 17 ms, but only on trials where fearful faces were successfully detected. When masked faces were shown for 50 ms, a smaller but reliable frontal positivity was also elicited by undetected fearful faces. These results demonstrate that early {ERP} responses to fearful faces are linked to observers' subjective conscious awareness of such faces, as reflected by their perceptual reports. They suggest that frontal brain regions involved in the construction of conscious representations of facial expression are activated at very short latencies.},
}
@article{lumley_childhood_2009,
}
@article{wnuczko_when_2012-2,
}
@article{glenberg_symbol_2000,
	abstract = {Latent Semantic Analysis (Landauer \&amp; Dumais, 1997) and Hyperspace Analogue to Language (Burgess \&amp; Lund, 1997) model meaning as the relations among abstract symbols that are arbitrarily related to what they signify. These symbols are ungrounded in that they are not tied to perceptual experience or action. Because the symbols are ungrounded, they cannot, in principle, capture the meaning of novel situations. In contrast, participants in three experiments found it trivially easy to discriminate between descriptions of sensible novel situations (e.g., using a newspaper to protect one's face from the wind) and nonsense novel situations (e.g., using a matchbook to protect one's face from the wind). These results support the Indexical Hypothesis that the meaning of a sentence is constructed by (a) indexing words and phrases to real objects or perceptual, analog symbols; (b) deriving affordances from the objects and symbols; and (c) meshing the affordances under the guidance of syntax.},
}
@article{riddoch_case_1987,
}
@article{anzellotti_differential_2010,
	abstract = {Neuropsychological evidence has highlighted the role of the anterior temporal lobes in the processing of conceptual knowledge. That putative role is only beginning to be investigated with {fMRI} as methodological advances are able to compensate for well-known susceptibility artifacts that affect the quality of the {BOLD} signal. In this article, we described differential {BOLD} activation for pictures of animals and manipulable objects in the anterior temporal lobes, consistent with previous neuropsychological findings. Furthermore, we found that the pattern of {BOLD} signal in the anterior temporal lobes is qualitatively different from that in the fusiform gyri. The latter regions are activated to different extents but always above baseline by images of the preferred and of the nonpreferred categories, whereas the anterior temporal lobes tend to be activated by images of the preferred category and deactivated ({BOLD} below baseline) by images of the nonpreferred category. In our experimental design, we also manipulated the decision that participants made over stimuli from the different semantic categories. We found that in the right temporal pole, the {BOLD} signal shows some evidence of being modulated by the task that participants were asked to perform, whereas {BOLD} activity in more posterior regions (e.g., the fusiform gyri) is not modulated by the task. These results reconcile the {fMRI} literature with the neuropsychological findings of deficits for animals after damage to the right temporal pole and suggest that anterior and posterior regions within the temporal lobes involved in object processing perform qualitatively different computations.},
}
@article{goodale_neurological_1991,
}
@article{kellenbach_pet_2005,
	abstract = {The distinctiveness of temporal lobe regions activated during the retrieval of knowledge regarding structural, colour and associative (encyclopaedic) aspects of familiar objects was investigated using {PET.} These three types of knowledge were contrasted using well matched tasks requiring the detection, in a series of coloured-in line drawings, of occasional anomalous objects (in the three conditions: structurally incorrect chimeras composed of parts of real objects; inappropriately coloured objects; familiar objects that do not exist in the modern world). Relative to a resting baseline condition, all semantic retrieval tasks yielded extensive bilateral activations in occipital and temporal areas, extending anteriorly on the ventral surface of the brain, plus an area in the right superior parietal lobe. In direct semantic-task comparisons focussing on the temporal lobe: (i) structural relative to associative decisions activated the right posterior middle/inferior temporal gyrus; (ii) colour decisions relative to structural judgements were associated with a region in the right superior temporal gyrus; (iii) the associative decision task selectively activated the left anterior middle/superior temporal gyrus and temporal pole relative to both object structure and colour, and also the homologous right temporal pole relative to colour only. These results indicate that each type of stored knowledge involves at least partially distinct cortical areas, and suggest that both anterior/posterior and left/right temporal regions have specialised roles.},
}
@article{jameson_differences_2003,
	abstract = {The accepted model of color naming postulates that 11 ``basic'' color terms representing 11 common perceptual experiences show increased processing salience due to a theorized linkage between perception, visual neurophysiology, and cognition. We tested this theory, originally proposed by Berlin and Kay in 1969. Experiment 1 tested salience by comparing unconstrained color naming across two languages, English and Vietnamese. Results were compared with previous research by Berlin and Kay, Boynton and Olson, and colleagues. Experiment 2 validated our stimuli by comparing {OSA}, Munsell, and newly rendered ``basic'' exemplars using colorimetry and behavioral measures. Our results show that the relationship between the visual and verbal domains is more complex than current theory acknowledges. An interpoint distance model of color-naming behavior is proposed as an alternative perspective on color-naming universality and color-category structure. \copywrite 2003 Wiley Periodicals, Inc. Col Res Appl, 28, 113--138, 2003; Published online in Wiley {InterScience} (www.interscience.wiley.com). {DOI} 10.1002/col.10131},
}
@article{just_neurosemantic_2010,
	abstract = {This article describes the discovery of a set of biologically-driven semantic dimensions underlying the neural representation of concrete nouns, and then demonstrates how a resulting theory of noun representation can be used to identify simple thoughts through their {fMRI} patterns. We use factor analysis of {fMRI} brain imaging data to reveal the biological representation of individual concrete nouns like apple, in the absence of any pictorial stimuli. From this analysis emerge three main semantic factors underpinning the neural representation of nouns naming physical objects, which we label manipulation, shelter, and eating. Each factor is neurally represented in 3--4 different brain locations that correspond to a cortical network that co-activates in non-linguistic tasks, such as tool use pantomime for the manipulation factor. Several converging methods, such as the use of behavioral ratings of word meaning and text corpus characteristics, provide independent evidence of the centrality of these factors to the representations. The factors are then used with machine learning classifier techniques to show that the {fMRI-measured} brain representation of an individual concrete noun like apple can be identified with good accuracy from among 60 candidate words, using only the {fMRI} activity in the 16 locations associated with these factors. To further demonstrate the generativity of the proposed account, a theory-based model is developed to predict the brain activation patterns for words to which the algorithm has not been previously exposed. The methods, findings, and theory constitute a new approach of using brain activity for understanding how object concepts are represented in the mind.},
}
@article{wnuczko_when_2012-3,
}
@article{rosen_emotion_2002,
}
@article{haxby_distributed_2001,
	abstract = {The functional architecture of the object vision pathway in the human brain was investigated using functional magnetic resonance imaging to measure patterns of response in ventral temporal cortex while subjects viewed faces, cats, five categories of man-made objects, and nonsense pictures. A distinct pattern of response was found for each stimulus category. The distinctiveness of the response to a given category was not due simply to the regions that responded maximally to that category, because the category being viewed also could be identified on the basis of the pattern of response when those regions were excluded from the analysis. Patterns of response that discriminated among all categories were found even within cortical regions that responded maximally to only one category. These results indicate that the representations of faces and objects in ventral temporal cortex are widely distributed and overlapping.},
}
@article{ozgen_language_2004,
	abstract = {People perceive colors categorically. But what is the role of the environment (or nurture)---specifically, language---in color perception? The effects of language on the way people categorize and perceive colors have been considered to be minimal, but recent evidence suggests that language may indeed change color perception. Speakers of languages with different color-name repertoires show differences in the way they perceive color. Research shows that categorical effects on color perception can be induced through laboratory training and suggests language can similarly change color perception through the mechanism of perceptual learning.},
}
@article{maquet_role_2001,
}
@article{yamamoto_long-term_1978,
	abstract = {To study the mechanism for long-term potentiation, extracellular and intracellular potential changes were examined in thin hippocampal sections in vitro. The field potential elicited by mossy fiber stimulation in the {CA3} region (primary response) was augmented for observation periods of 15--60 min after conditioning tetanic stimulation. Tetanization of a group of mossy fibers potentiated responses induced by another group of presynaptic fibers. The augmented primary response was sometimes followed by a train of after-discharges. When long-lasting potentiation of the primary response was observed, an increase in excitatory postsynaptic potential amplitude or a depression of inhibitory postsynaptic potentials was found intracellularly. The afterdischarge train was associated with a large intracellular depolarization of long durations. These results suggest that long-term potentiation of the primary response is due to an enhanced excitatory synaptic transmission and a depression of the inhibitory circuit, and that the depression of inhibitory postsynaptic potentials may be related partly to paroxysmal activities of neurons.},
}
@article{reiss_object_2006,
	abstract = {Object substitution masking ({OSM)} refers to impaired target identification caused by common onset, but delayed offset, of a surrounding dot mask. This effect has been hypothesized to reflect reentrant processes that result in the mask replacing the target representation. However, little is known about the depth of processing associated with masked targets in this paradigm. We investigated this issue by examining the effect of {OSM} on the N400 component of the event-related potential, which reflects the degree of semantic mismatch between a target and its context. Participants read a context word followed by a semantically related or unrelated target word surrounded by dots. As expected, delayed dot offset significantly reduced accuracy in identifying the target. The N400 amplitude was also diminished by {OSM.} These findings offer the first evidence that substitution interferes with target processing prior to semantic analysis, demonstrating an important difference between {OSM} and other visual phenomena, such as the attentional blink, in which semantic processing is independent of awareness.},
}
@article{moreno-martinez_ecological_2012,
	abstract = {This work presents a new set of 360 high quality colour images belonging to 23 semantic subcategories. Two hundred and thirty-six Spanish speakers named the items and also provided data from seven relevant psycholinguistic variables: age of acquisition, familiarity, manipulability, name agreement, typicality and visual complexity. Furthermore, we also present lexical frequency data derived from Internet search hits. Apart from the high number of variables evaluated, knowing that it affects the processing of stimuli, this new set presents important advantages over other similar image corpi: (a) this corpus presents a broad number of subcategories and images; for example, this will permit researchers to select stimuli of appropriate difficulty as required, (e.g., to deal with problems derived from ceiling effects); (b) the fact of using coloured stimuli provides a more realistic, ecologically-valid, representation of real life objects. In sum, this set of stimuli provides a useful tool for research on visual object-and word- processing, both in neurological patients and in healthy controls.},
}
@article{tononi_sleep_2006,
}
@article{derefeldt_cognitive_2004,
	abstract = {This report surveys cognitive aspects of color in terms of behavioral, neuropsychological, and neurophysiological data. Color is usually defined as a color stimulus or as perceived color. In this article, a definition of the concept of cognitive color is formulated. To elucidate this concept, those visual tasks are described where it is relevant: in color categorization, color coding, color naming, the Stroop effect, spatial organization of colored visual objects, visual search, and color memory. \copywrite 2003 Wiley Periodicals, Inc. Col Res Appl, 29, 7--19, 2004; Published online in Wiley {InterScience} (www.interscience.wiley.com). {DOI} 10.1002/col.10209},
}
@article{kay_language_2006,
	abstract = {The classic issue of color naming and color cognition has been re-examined in a recent series of articles. Here, we review these developments, and suggest that they move the field beyond a familiar rhetoric of 'nature versus nurture', or 'universals versus relativity', to new concepts and new questions.},
}
@article{hanlon_effects_2009,
	abstract = {{STUDY} {OBJECTIVE}
}
@article{karnath_cortical_2005-1,
}
@article{martin_representation_2007,
}
@article{kellenbach_large_2001,
}
@article{friederici_language_2013,
	abstract = {Learning takes place throughout lifetime but differs in infants and adults because of the immaturity of the {PFC}, a brain region responsible for cognitive control. To test this hypothesis, adults were investigated in a language learning paradigm under inhibitory, cathodal transcranial direct current stimulation over {PFC.} The experiment included a learning session interspersed with test phases and a test-only session. The stimulus material required the learning of grammatical dependencies between two elements in a novel language. In a parallel design, cathodal transcranial direct current stimulation over the left {PFC}, right {PFC}, or sham stimulation was applied during the learning session but not during the test-only session. Event-related brain potentials ({ERPs)} were recorded during both sessions. Whereas no {ERP} learning effects were observed during the learning session, different {ERP} learning effects as a function of prior stimulation type were found during the test-only session, although behavioral learning success was equal across conditions. With sham stimulation, the {ERP} learning effect was reflected in a centro-parietal N400-like negativity indicating lexical processes. Inhibitory stimulation over the left {PFC}, but not over the right {PFC}, led to a late positivity similar to that previously observed in prelinguistic infants indicating associative learning. The present data demonstrate that adults can learn with and without cognitive control using different learning mechanisms. In the presence of cognitive control, adult language learning is lexically guided, whereas it appears to be associative in nature when {PFC} control is downregulated.},
}
@article{purcell_another_1983,
	abstract = {In a recent study, {McCauley}, Parmelee, Sperber, and Carr (1980) reported results indicating that semantic priming had been produced by visual stimuli that were backward masked at durations too brief for greater than chance report. The conclusions drawn from such an experiment are critically dependent upon whether or not the primes were actually masked below the thresh-old for identification during priming trials. The three experiments reported here provide evidence that this requirement was not met. Rather, {McCauley} et al.'s (1980) methodology allowed for an uncontrolled increase in light adaptation during the actual testing of prime efficacy in the priming session. This increase in light adaptation reduced the effectiveness of the backward mask and resulted in an increase in prime visibility during priming trials. Thus, semantic priming probably occurred under conditions in which commensurate visual information was actually available.},
}
@article{squire_cognitive_2011,
	abstract = {Work with patient {H.M.}, beginning in the 1950s, established key principles about the organization of memory that inspired decades of experimental work. Since {H.M.}, the study of human memory and its disorders has continued to yield new insights and to improve understanding of the structure and organization of memory. Here we review this work with emphasis on the neuroanatomy of medial temporal lobe and diencephalic structures important for memory, multiple memory systems, visual perception, immediate memory, memory consolidation, the locus of long-term memory storage, the concepts of recollection and familiarity, and the question of how different medial temporal lobe structures may contribute differently to memory functions.},
}
@article{albright_direction_1984,
	abstract = {We recorded from single neurons in the middle temporal visual area ({MT)} of the macaque monkey and studied their direction and orientation selectivity. We also recorded from single striate cortex (V1) neurons in order to make direct comparisons with our observations in area {MT.} All animals were immobilized and anesthetized with nitrous oxide. Direction selectivity of 110 {MT} neurons was studied with three types of moving stimuli: slits, single spots, and random-dot fields. All of the {MT} neurons were found to be directionally selective using one or more of these stimuli. {MT} neurons exhibited a broad range of direction-tuning bandwidths to all stimuli (minimum = 32 degrees, maximum = 186 degrees, mean = 95 degrees). On average, responses were strongly unidirectional and of similar magnitude for all three stimulus types. Orientation selectivity of 89 {MT} neurons was studied with stationary flashed slits. Eighty-three percent were found to be orientation selective. Overall, orientation-tuning bandwidths were significantly narrower (mean = 64 degrees) than direction-tuning bandwidths for moving stimuli. Moreover, responses to stationary-oriented stimuli were generally smaller than those to moving stimuli. Direction selectivity of 55 V1 neurons was studied with moving slits; orientation selectivity of 52 V1 neurons was studied with stationary flashed slits. In V1, compared with {MT}, direction-tuning bandwidths were narrower (mean = 68 degrees). Moreover, V1 responses to moving stimuli were weaker, and bidirectional tuning was more common. The mean orientation-tuning bandwidth in V1 was also significantly narrower than that in {MT} (mean = 52 degrees), but the responses to stationary-oriented stimuli were of similar magnitude in the two areas. We examined the relationship between optimal direction and optimal orientation for {MT} neurons and found that 61\% had an orientation preference nearly perpendicular to the preferred direction of motion, as is the case for all V1 neurons. However, another 29\% of {MT} neurons had an orientation preference roughly parallel to the preferred direction. These observations, when considered together with recent reports claiming sensitivity of some {MT} neurons to moving visual patterns (39), suggest specific neural mechanisms underlying pattern-motion sensitivity in area {MT.} These results support the notion that area {MT} represents a further specialization over area V1 for stimulus motion processing. Furthermore, the marked similarities between direction and orientation tuning in area {MT} in macaque and owl monkey support the suggestion that these areas are homologues.},
}
@article{kay_color_2005,
	abstract = {Recent, well-controlled studies in cross-language color naming and cross-language tests of color memory and learning have made important contributions to our understanding of which aspects of cross-language color naming and nonverbal response to colors may and may not be attributed to pan-human properties of color appearance. Valuable as these results are, some studies have led to more relativistic conclusions than their results justify. In particular, these conclusions ignore the issue of whether there exists across languages a statistical tendency toward basing color terminology systems on black, white, and the four Hering opponent hues.},
}
@article{shinkareva_using_2008,
	abstract = {Previous studies have succeeded in identifying the cognitive state corresponding to the perception of a set of depicted categories, such as tools, by analyzing the accompanying pattern of brain activity, measured with {fMRI.} The current research focused on identifying the cognitive state associated with a 4s viewing of an individual line drawing (1 of 10 familiar objects, 5 tools and 5 dwellings, such as a hammer or a castle). Here we demonstrate the ability to reliably (1) identify which of the 10 drawings a participant was viewing, based on that participant's characteristic whole-brain neural activation patterns, excluding visual areas; (2) identify the category of the object with even higher accuracy, based on that participant's activation; and (3) identify, for the first time, both individual objects and the category of the object the participant was viewing, based only on other participants' activation patterns. The voxels important for category identification were located similarly across participants, and distributed throughout the cortex, focused in ventral temporal perceptual areas but also including more frontal association areas (and somewhat left-lateralized). These findings indicate the presence of stable, distributed, communal, and identifiable neural states corresponding to object concepts.},
}
@misc{_experience-dependent_2000,
}
@article{tong_aligning_2011,
	abstract = {In this issue of Neuron, Haxby and colleagues describe a new method for aligning functional brain activity patterns across participants. Their study demonstrates that objects are similarly represented across different brains, allowing for reliable classification of one person's brain activity based on another's.},
}
@article{tranel_neural_2003-1,
	abstract = {The neural correlates of naming stimuli presented through the auditory modality have scarcely been studied. Using a {PET} experiment in 10 normal subjects, we began to address this issue by testing the hypothesis that naming animals from their characteristic sounds will engage bilateral primary auditory and auditory association cortices, bilateral early visual association cortices, left inferotemporal ({IT)} cortices, and left frontal operculum. Subjects listened to characteristic animal sounds (e.g. a rooster crowing), and named the animals making the sounds. When contrasted with a baseline task that involved saying up/down to the direction of pitch change in tone sequences, the naming task produced activation in mesial occipital cortices, the left ventral {IT} region, and the left frontal operculum. We interpret the activation in visual association cortices to reflect the process of retrieving conceptual knowledge (e.g. physical structure) pertinent to the animals being named, as in visual images. The left {IT} activation is interpreted to reflect activation of a mediation system for word retrieval, that operates to link conceptual knowledge retrieval to word production, and whose triggering is independent of the sensory modality in which a stimulus is presented.},
}
@article{sincich_circuitry_2005,
	abstract = {Primary and secondary visual cortex (V1 and V2) form the foundation of the cortical visual system. V1 transforms information received from the lateral geniculate nucleus ({LGN)} and distributes it to separate domains in V2 for transmission to higher visual areas. During the past 20 years, schemes for the functional organization of V1 and V2 have been based on a tripartite framework developed by Livingstone \& Hubel (1988). Since then, new anatomical data have accumulated concerning V1's input, its internal circuitry, and its output to V2. These new data, along with physiological and imaging studies, now make it likely that the visual attributes of color, form, and motion are not neatly segregated by V1 into different stripe compartments in V2. Instead, there are just two main streams, originating from cytochrome oxidase patches and interpatches, that project to V2. Each stream is composed of a mixture of magno, parvo, and konio geniculate signals. Further studies are required to elucidate how the patches and interpatches differ in the output they convey to extrastriate cortex.},
}
@article{badre_mechanisms_2012,
	abstract = {The frontal lobes may be organized hierarchically such that more rostral frontal regions modulate cognitive control operations in caudal regions. In our companion paper (Frank {MJ}, Badre D. 2011. Mechanisms of hierarchical reinforcement learning in corticostriatal circuits I: computational analysis. 22:509--526), we provide novel neural circuit and algorithmic models of hierarchical cognitive control in cortico--striatal circuits. Here, we test key model predictions using functional magnetic resonance imaging ({fMRI).} Our neural circuit model proposes that contextual representations in rostral frontal cortex influence the striatal gating of contextual representations in caudal frontal cortex. Reinforcement learning operates at each level, such that the system adaptively learns to gate higher order contextual information into rostral regions. Our algorithmic Bayesian ``mixture of experts'' model captures the key computations of this neural model and provides trial-by-trial estimates of the learner's latent hypothesis states. In the present paper, we used these quantitative estimates to reanalyze {fMRI} data from a hierarchical reinforcement learning task reported in Badre D, Kayser {AS}, {D'Esposito} M. 2010. Frontal cortex and the discovery of abstract action rules. Neuron. 66:315--326. Results validate key predictions of the models and provide evidence for an individual cortico--striatal circuit for reinforcement learning of hierarchical structure at a specific level of policy abstraction. These findings are initially consistent with the proposal that hierarchical control in frontal cortex may emerge from interactions among nested cortico--striatal circuits at different levels of abstraction.},
}
@article{wilson_neural_2009,
}
@incollection{barsalou_systematicity_1989,
	abstract = {The central issue in the study of semantic ambiguity has concerned whether all senses of a polysemous word are initially accessed as opposed to only the contextually relevant sense. As a simplifying assumption, many theorists assume implicitly that the content of each retrieved sense is static, containing the same information across retrievals. Other theorists make this assumption explicitly (e.g., Fodor \& Pylyshyn, 1988, p. 45). But when investigators have assessed the stability of individual word senses, they have generally observed variability in the information retrieved. Reports of semantic variability in retention include Anderson and Ortony (1975), Anderson, Pichert, Goetz, Schallert, Stevens, and Trollip (1976), Barclay, Bransford, Franks, {McCarrell}, and Nitsch (1974), Geis and Winograd (1975), Greenspan (1986), Thompson and Tulving (1970), and Tulving and Thompson (1973). Reports of semantic variability in lexical access include Barsalou (1982), Conrad (1978), Johnson-Laird (1987), Tabossi (1988), Tabossi and Johnson-Laird (1980), and Whitney, {McKay}, and Kellas (1985). A review of variability in the representations that underlie decision making can be found in Kahneman and Miller (1986).},
}
@article{buxbaum_ideational_1998,
	abstract = {It is frequently claimed that ideational apraxia, an impairm ent of the performance of complex actions with objects, is a left-hemisphere syndrome. We assessed the consequences of lefthemisphere damage for naturalistic action performance in two studies. In Study 1, we compared the action errors of left-hemisphere stroke patients ({LCVA)} to previously reported patients with right-hemisphere stroke ({RCVA)} and closed head injury ({CHI)}, and found that {LCVA} were no more vulnerable to errors of action than the other patient groups once differences in severity were controlled. In Study 2, we compared the naturalistic action performance of a patient with severe ideational apraxia and left-hemisphere damage to that of two {RCVA} patients of equal clinical severity. There was considerable quantitative and qualitative similarity in the errors of the three patients. From these and other findings, we argue that deficits in left-hem isphere systems do not compromise com plex action in a unique or transparent manner. We offer an alternative account based on nonspecific resource limitations that accommodates the data from all patient groups.},
}
@article{grossman_brain_2000,
	abstract = {These experiments use functional magnetic resonance imaging ({fMRI)} to reveal neural activity uniquely associated with perception of biological motion. We isolated brain areas activated during the viewing of point-light figures, then compared those areas to regions known to be involved in coherent-motion perception and kinetic-boundary perception. Coherent motion activated a region matching previous reports of human {MT/MST} complex located on the temporo-parieto-occipital junction. Kinetic boundaries activated a region posterior and adjacent to human {MT} previously identified as the kinetic-occipital ({KO)} region or the lateral-occipital ({LO)} complex. The pattern of activation during viewing of biological motion was located within a small region on the ventral bank of the occipital extent of the superior-temporal sulcus ({STS).} This region is located lateral and anterior to human {MT/MST}, and anterior to {KO.} Among our observers, we localized this region more frequently in the right hemisphere than in the left. This was true regardless of whether the point-light figures were presented in the right or left hemifield. A small region in the medial cerebellum was also active when observers viewed biological-motion sequences. Consistent with earlier neuroimaging and single-unit studies, this pattern of results points to the existence of neural mechanisms specialized for analysis of the kinematics defining biological motion.},
}
@article{price_how_2003,
	abstract = {There is growing evidence from functional imaging studies that distinct regions in the fusiform gyri are differentially sensitive to object category. In this paper, we investigate how the areas that are more sensitive to animals than tools respond to other visual and semantic variables. We illustrate that (1) category effects in the fusiform areas are stronger for pictures of objects than their written names; (2) retrieving information on the colour or size of objects activates a left lateralised fusiform area that lies anterior to the category-sensitive areas; and (3) both left and right category-sensitive areas respond strongly to visual feature detection on false fonts-meaningless visual stimuli with no semantic associations. These results dissociate the responses in two fusiform areas: The posterior category-sensitive areas are primarily modulated by visual input, whereas a more anterior polymodal region is involved in the retrieval of visual information. In addition, we demonstrate that the posterior areas which are more active for animals than tools are also more active for fruits than tools. Our data are therefore consistent with the proposal that activation in the lateral posterior fusiform gyri reflects the demands on structural differentiation. Since animals and fruits tend to have more structurally similar neighbours than man-made kinds of objects, category effects are likely to be observed during most picture identification tasks. In contrast, when the stimuli are written or auditory names, category effects may only be observed when the task requires access to fine spatial details in the objects' structures.},
}
@article{boynton_salience_1990,
	abstract = {Using single color terms of their choice, nine subjects named each of 424 colors twice under carefully-controlled conditions. Compared to any other color names, the chromatic basic color terms (red, green, yellow, blue, orange, purple, brown and pink) are all used more consistently within subjects, with greater consensus between subjects, and with shorter mean response times; there is no overlap between the two categories of color names by any of these criteria. The results are interpreted as supporting the conception that basic color terms refer to fundamental sensations for which there is a specific physiological basis.},
}
@article{hesselmann_link_2011,
	abstract = {A central topic of controversy in the search for cortical mechanisms underlying perceptual awareness concerns the fundamental specialization of the visual system into a dorsal ``vision-for-{action/Where''} stream and a ventral ``vision-for-{perception/What''} stream. Specifically, it has been debated whether suppression of visual perception leads to differential reduction in brain activity in the 2 streams---with the dorsal stream remaining largely unaffected and the ventral stream showing a significant reduction in activity. Here, we examined this issue using the recently introduced method of continuous flash suppression ({CFS)}, which offers a particularly sensitive measure of the link between perception and brain activity. Subjects had to detect, during {CFS}, images of manipulable man-made objects (tools). Our results show that despite their substantial difference in connectivity and neuroanatomical specialization, both ventral and dorsal stream areas revealed a similarly tight link to perceptual awareness, that is, strong functional magnetic resonance imaging--blood oxygenation level--dependent activity for visible tools but a significant reduction of activity in the invisible condition. Importantly, this result was found when the masks were kept identical in the visible and invisible conditions. Our data lend support to the notion that neuronal activity and perceptual awareness are tightly linked across human high-order visual cortex.},
}
@article{joseph_color_1997,
	abstract = {This study examined the effect of different object verification tasks on perceptual and conceptual color processing. Participants decided whether two successively presented stimuli (two pictures or a word then a picture) referred to the same object. Although the task did not require object-color processing, prototypical object-color was semantically activated and influenced verification decisions. This automatic conceptual color processing was more powerful than perceptual processing of the surface color presented in the picture. Moreover, conceptual color processing occurred in tasks involving only two pictures, implying that activation of prototypical color does not depend on verbal processing. Rather, activation of prototypical color depends on whether pictures are semantically encoded during verification, which in turn, occurs when verification cannot proceed from structural object information.},
}
@article{teyler_long-term_1987,
}
@article{kalenine_critical_2010-2,
	abstract = {A number of conflicting claims have been advanced regarding the role of the left inferior frontal gyrus, inferior parietal lobe and posterior middle temporal gyrus in action recognition, driven in part by an ongoing debate about the capacities of putative mirror systems that match observed and planned actions. We report data from 43 left hemisphere stroke patients in two action recognition tasks in which they heard and saw an action word ('hammering') and selected from two videoclips the one corresponding to the word. In the spatial recognition task, foils contained errors of body posture or movement amplitude/timing. In the semantic recognition task, foils were semantically related (sawing). Participants also performed a comprehension control task requiring matching of the same verbs to objects (hammer). Using regression analyses controlling for both the comprehension control task and lesion volume, we demonstrated that performance in the semantic gesture recognition task was predicted by per cent damage to the posterior temporal lobe, whereas the spatial gesture recognition task was predicted by per cent damage to the inferior parietal lobule. A whole-brain voxel-based lesion symptom-mapping analysis suggested that the semantic and spatial gesture recognition tasks were associated with lesioned voxels in the posterior middle temporal gyrus and inferior parietal lobule, respectively. The posterior middle temporal gyrus appears to serve as a central node in the association of actions and meanings. The inferior parietal lobule, held to be a homologue of the monkey parietal mirror neuron system, is critical for encoding object-related postures and movements, a relatively circumscribed aspect of gesture recognition. The inferior frontal gyrus, on the other hand, was not predictive of performance in any task, suggesting that previous claims regarding its role in action recognition may require refinement.},
}
@article{radloff_ces-d_1977,
	abstract = {The {CES-D} scale is a short self-report scale designed to measure depressive symptomatology in the general population. The items of the scale are symptoms associated with depression which have been used in previously validated longer scales. The new scale was tested in household interview surveys and in psychiatric settings. It was found to have very high internal consistency and adequate test- retest repeatability. Validity was established by pat terns of correlations with other self-report measures, by correlations with clinical ratings of depression, and by relationships with other variables which support its construct validity. Reliability, validity, and factor structure were similar across a wide variety of demographic characteristics in the general population samples tested. The scale should be a useful tool for epidemiologic studies of de pression.},
}
@article{nir_coupling_2007,
	abstract = {{SummaryBackground}
}
@article{kentridge_attended_2008,
	abstract = {Does any one psychological process give rise to visual awareness? One candidate is selective attention---when we attend to something it seems we always see it. But if attention can selectively enhance our response to an unseen stimulus then attention cannot be a sufficient precondition for awareness. Kentridge, Heywood \&amp; Weiskrantz [Kentridge, R. W., Heywood, C. A., \&amp; Weiskrantz, L. (1999). Attention without awareness in blindsight. Proceedings of the Royal Society of London, Series B, 266, 1805--1811; Kentridge, R. W., Heywood, C. A., \&amp; Weiskrantz, L. (2004). Spatial attention speeds discrimination without awareness in blindsight. Neuropsychologia, 42, 831--835.] demonstrated just such a dissociation in the blindsight subject {GY.} Here, we test whether the dissociation generalizes to the normal population. We presented observers with pairs of coloured discs, each masked by the subsequent presentation of a coloured annulus. The discs acted as primes, speeding discrimination of the colour of the annulus when they matched in colour and slowing it when they differed. We show that the location of attention modulated the size of this priming effect. However, the primes were rendered invisible by metacontrast-masking and remained unseen despite being attended. Visual attention could therefore facilitate processing of an invisible target and cannot, therefore, be a sufficient precondition for visual awareness.},
}
@article{estebanez_correlated_2012,
	abstract = {As in other sensory modalities, one function of the somatosensory system is to detect coherence and contrast in the environment. To investigate the neural bases of these computations, we applied different spatiotemporal patterns of stimuli to rat whiskers while recording multiple neurons in the barrel cortex. Model-based analysis of the responses revealed different coding schemes according to the level of input correlation. With uncorrelated stimuli on 24 whiskers, we identified two distinct functional categories of neurons, analogous in the temporal domain to simple and complex cells of the primary visual cortex. With correlated stimuli, however, a complementary coding scheme emerged: two distinct cell populations, similar to reinforcing and antagonist neurons described in the higher visual area {MT}, responded specifically to correlations. We suggest that similar context-dependent coexisting coding strategies may be present in other sensory systems to adapt sensory integration to specific stimulus statistics.},
}
@article{marslen-wilson_rules_1998,
	abstract = {The significance of the English past tense in current cognitive science is that it offers a clear contrast between a potentially rule-based system---the procedures for forming the regular past tense---and an unpredictable and idiosyncratic set of irregular forms. This contrast has become a focus for a wide-ranging debate about whether mental computation requires the use of symbols. Highly regular combinatorial phenomena, such as the regular past tense, are prime candidates for rule-based symbolic computation. Earlier research concentrated on the evidence for this during language acquisition, looking at how children learned the English regular and irregular verb systems. Over the last five years attention has shifted towards the properties of the adult system, and we review here some recent research into the neural correlates of the two types of procedure. The evidence suggests that there are divergences in the neural systems underlying the generation and perception of regular and irregular forms. Regular inflected forms seem to involve primarily combinatorial processes, while irregular forms appear to have a hybrid status, sharing their semantic properties with the regular forms but diverging in the phonological domain, where their form representations are stored as complete units. This indicates that the regular and irregular past tenses may not, after all, provide a clean contrast in the types of mental computation they implicate.},
}
@article{gerlach_shape_2006,
	abstract = {We examined the neural correlates of visual shape configuration, the binding of local shape characteristics into wholistic object descriptions, by comparing the regional cerebral blood flow associated with recognition of outline drawings and fragmented drawings. We found no areas that responded more to fragmented drawings than to outline drawings even though fragmentation had a clear impact on recognition performance. Instead, a region extending from the inferior occipital gyri to the middle parts of the fusiform gyri was activated during shape configuration of both outline drawings and fragmented drawings. We also examined whether fragmentation had different impact on the recognition of natural objects and artefacts and found that recognition of artefacts was more affected by fragmentation than recognition of natural objects. Thus, the usual finding of an advantage for artefacts in difficult object decision tasks, which is also found in the present experiments with outlines, is reversed when the stimuli are fragmented. This interaction between category (natural versus artefacts) and stimulus type (outlines versus fragmented forms) is in accordance with predictions derived from a recent account of category-specificity and lends support to the notion that category-specific impairments can occur for both natural objects and artefacts following damage to pre-semantic stages in visual object recognition. The implications of the present findings are discussed in relation to theories of perceptual organization, visual object recognition and category-specificity.},
}
@article{naccache_direct_2005,
	abstract = {A classical but still open issue in cognitive psychology concerns the depth of subliminal processing. Can the meaning of undetected words be accessed in the absence of consciousness? Subliminal priming experiments in normal subjects have revealed only small effects whose interpretation remains controversial. Here, we provide a direct demonstration of semantic access for unseen masked words. In three epileptic patients with intracranial electrodes, we recorded brain potentials from the amygdala, a neural structure that responds to fearful or threatening stimuli presented in various modalities, including written words. We show that the subliminal presentation of emotional words modulates the activity of the amygdala at a long latency ({\textgreater}800 ms). Our result indicates that subliminal words can trigger long-lasting cerebral processes, including semantic access to emotional valence.},
}
@article{sandell_color_1979,
	abstract = {Investigated whether macaque monkeys partition the photic spectrum into the same 4 basic hue categories that humans do (i.e., blue, green, yellow, and red). Seven males were trained to respond in the presence of one chromatic stimulus and were tested, in extinction, for generalization to others. In extinction, Ss responded at similar and high levels to stimuli that fell in the same human hue category as the training stimulus and at similar and much lower levels to stimuli that fell in a different human hue category from the training stimulus. It is concluded that macaques and humans categorize the spectrum in a similar fashion. (23 ref)},
}
@article{milner_is_2012,
}
@article{klein_paper_2002,
	abstract = {Polysemous words have different but related meanings (senses), such as paper meaning a newspaper or writing material. Six experiments examined the similarity of word senses using categorization and inference tasks. The experiments found that subjects did not categorize together phrases that used a polysemous word in different senses, though they did when the word was used in the same sense. Different senses of a word were categorized together no more than 20\% of the time, only slightly more often than different meanings of homonyms. Pre-exposing subjects to a polysemous relation did not increase categorization of word senses that had that relation. Finally, induction from one sense of a word to a different sense was also weak. The results are consistent with the view that polysemous senses are represented separately, often with little semantic overlap, helping to explain previous results that using a word in one sense interferes with using it in another sense, even if the senses are related. Implications for lexical representations are discussed.},
}
@article{haxby_multivariate_????,
	abstract = {In 2001, we published a paper on the representation of faces and objects in ventral temporal cortex that introduced a new method for {fMRI} analysis, which subsequently came to be called multivariate pattern analysis ({MVPA).} {MVPA} now refers to a diverse set of methods that analyze neural responses as patterns of activity that reflect the varying brain states that a cortical field or system can produce. This paper recounts the circumstances and events that led to the original study and later developments and innovations that have greatly expanded this approach to {fMRI} data analysis, leading to its widespread application.},
}
@article{lumley_cognitive_2011,
}
@article{wnuczko_when_2012-4,
}
@article{dalgleish_biases_1990,
	abstract = {Theoretical frameworks and experimental paradigms derived from cognitive psychology provide a valuable approach to the investigation of cognitive aspects of disorders of anxiety and depression. Review of the literature provides strong evidence of attentional bias towards threat stimuli in anxiety, though evidence of comparable attentional bias in depression is weaker. There is also strong evidence of memory bias towards mood-congruent materials in depression, though comparable evidence regarding anxiety-congruent memory is mixed. A variety of theoretical frameworks for explaining such phenomena have been advanced, using concepts such as networks, schema and mental models. There is a need now for theoretical frameworks that address themselves to the specificity of the empirical phenomena. Clinical and empirical implications of these findings and models are discussed, including developments in diathesis-stress models of psychopathology, the use of experimental-cognitive paradigms in clinical assessment, and the prospect of therapeutic applications.},
}
@article{zhou_newly_2010,
	abstract = {Linguistic categories have been shown to influence perceptual discrimination, to do so preferentially in the right visual field, to fail to do so when competing demands are made on verbal memory, and to vary with the color-term boundaries of different languages. However, because there are strong commonalities across languages in the placement of color-term boundaries, the question remains open whether observed categorical perception for color can be entirely a result of learned categories or may rely to some degree on innate ones. We show here that lateralized color categorical perception can be entirely the result of learned categories. In a visual search task, reaction times to targets were faster in the right than the left visual field when the target and distractor colors, initially sharing the same linguistic term (e.g., ``blue''), became between-category colors after training (i.e., when two different shades of blue had each acquired a new name). A control group, whose conditions exactly matched those of the experimental group except that no new categories were introduced, did not show this effect, establishing that the effect was not dependent on increased familiarity with either the color stimuli or the task. The present results show beyond question that lateralized categorical perception of color can reflect strictly learned color categories, even artificially learned categories that violate both universal tendencies in color naming and the categorization pattern of the language of the subject.},
}
@article{vanpaemel_search_2008,
	abstract = {A longstanding debate in the categorization literature concerns representational abstraction. Generally, when exemplar models, which assume no abstraction, have been contrasted with prototype models, which assume total abstraction, the former models have been found to be superior to the latter. Although these findings may rule out the idea that total abstraction takes place during category learning and instead suggest that no abstraction is involved, the idea of abstraction retains considerable intuitive appeal. In this article, we propose the varying abstraction model of categorization ({VAM)}, which investigates the possibility that partial abstraction may play a role in category learning. We apply the {VAM} to four previously published data sets that have been used to argue that no abstraction is involved. Contrary to the previous findings, our results provide support for the idea that some form of partial abstraction can be used in people's category representations.},
}
@article{sabsevitz_modulation_2005,
	abstract = {A prevailing neurobiological theory of semantic memory proposes that part of our knowledge about concrete, highly imageable concepts is stored in the form of sensory--motor representations. While this theory predicts differential activation of the semantic system by concrete and abstract words, previous functional imaging studies employing this contrast have provided relatively little supporting evidence. We acquired event-related functional magnetic resonance imaging ({fMRI)} data while participants performed a semantic similarity judgment task on a large number of concrete and abstract noun triads. Task difficulty was manipulated by varying the degree to which the words in the triad were similar in meaning. Concrete nouns, relative to abstract nouns, produced greater activation in a bilateral network of multimodal and heteromodal association areas, including ventral and medial temporal, posterior--inferior parietal, dorsal prefrontal, and posterior cingulate cortex. In contrast, abstract nouns produced greater activation almost exclusively in the left hemisphere in superior temporal and inferior frontal cortex. Increasing task difficulty modulated activation mainly in attention, working memory, and response monitoring systems, with almost no effect on areas that were modulated by imageability. These data provide critical support for the hypothesis that concrete, imageable concepts activate perceptually based representations not available to abstract concepts. In contrast, processing abstract concepts makes greater demands on left perisylvian phonological and lexical retrieval systems. The findings are compatible with dual coding theory and less consistent with single-code models of conceptual representation. The lack of overlap between imageability and task difficulty effects suggests that once the neural representation of a concept is activated, further maintenance and manipulation of that information in working memory does not further increase neural activation in the conceptual store.},
}
@article{warrington_category_1984,
	abstract = {We report a quantitative investigation of the visual identification and auditory comprehension deficits of 4 patients who had made a partial recovery from herpes simplex encephalitis. Clinical observations had suggested the selective impairment and selective preservation of certain categories of visual stimuli. In all 4 patients a significant discrepancy between their ability to identify inanimate objects and inability to identify living things and foods was demonstrated. In 2 patients it was possible to compare visual and verbal modalities and the same pattern of dissociation was observed in both. For 1 patient, comprehension of abstract words was significantly superior to comprehension of concrete words. Consistency of responses was recorded within a modality in contrast to a much lesser degree of consistency between modalities. We interpret our findings in terms of category specificity in the organization of meaning systems that are also modality specific semantic systems.},
}
@article{hodges_semantic_1992,
	abstract = {We report five patients with a stereotyped clinical syndrome characterized by fluent dysphasia with severe anomia, reduced vocabulary and prominent impairment of single-word comprehension, progressing to a stage of virtually complete dissolution of the semantic components of language. A marked reduction in the ability to generate exemplars from restricted semantic categories (e.g. animals, vehicles, etc.) was a consistent and early feature. Tests of semantic memory demonstrated a radically impoverished knowledge about a range of living and man-made items. In contrast, phonology and grammar of spoken language were largely preserved, as was comprehension of complex syntactic commands. Reading showed a pattern of surface dyslexia. Autobiographical and day-to-day (episodic) memory were relatively retained. Non-verbal memory, perceptual and visuospatial abilities were also strikingly preserved. In some cases, behavioural and personality changes may supervene; one patient developed features of the Kluver-Bucy Syndrome. Radiological investigations have shown marked focal temporal atrophy in all five patients, and functional imaging by single positron emission tomography and positron emission tomography (one case) have implicated the dominant temporal lobe in all five. In the older literature, such cases would have been subsumed under the rubric of Pick's disease. Others have been included in series with progressive aphasia. We propose the term semantic dementia, first coined by Snowden et al. (1989), to designate this clinical syndrome.},
}
@article{stickgold_sleep:_1998,
	abstract = {Behavioral studies of memory and learning in both humans and animals support a role for sleep in the consolidation and integration of memories. Physiological studies of hippocampal and cortical activity as well as of brainstem neuromodulatory systems demonstrate the state-dependence of communication both between and within the neocortex and hippocampus. These findings are consonant with observed cognition during sleep and immediately following awakening.},
}
@article{pavlides_influences_1989,
	abstract = {Rat hippocampal ({CA1)} complex spike ``place cells'' of freely behaving rats were recorded in pairs continuously during a series of waking (exploration and still-alert), drowsy (quiet-awake), and sleeping (slow- wave, pre-rapid-eye-movement and rapid-eye-movement sleep) behaviors. Pairs of units were selected that had nonoverlapping place fields. The rats were restricted from entering the place field of either cell overnight, and on the day of recording cells were exposed to their individual place fields independently and in a counterbalanced manner. Following exposure, recordings were made in the subsequent sleep episodes and the firing characteristics of both cells were analyzed. Following exposure, significant increases in the spiking activity of the exposed cell were observed in the subsequent sleeping states that were not evident in the unexposed cell. The increased activity was observed in the rate of firing (spikes/sec), the rate of occurrence of bursts with multiple spikes, as well as the number of bursts displaying short (2--4 msec) interspike intervals. The findings suggest that neuronal activity of hippocampal place cells in the awake states may influence the firing characteristics of these cells in subsequent sleep episodes. The increased firing rates along with the greater number of multiple spike bursts and the shorter interspike intervals within the burst, following exposure to a cell's place field, may represent possible information processing during sleep.},
}
@article{portas2000auditory,
}
@article{dominey_flexible_1998,
}
@article{petersen_positron_1988,
	abstract = {The use of positron emission tomography to measure regional changes in average blood flow during processing of individual auditory and visual words provides support for multiple, parallel routes between localized sensory-specific, phonological, articulatory and semantic-coding areas.},
}
@article{lindsey_color_2002,
	abstract = {Many languages have no basic color term for ``blue.'' Instead, they call short-wavelength stimuli ``green'' or ``dark.'' We show that this cultural, linguistic phenomenon could result from accelerated aging of the eye because of high, chronic exposure to ultraviolet-B ({UV-B)} in sunlight (e.g., phototoxic lens brunescence). Reviewing 203 world languages, we found a significant relationship between {UV} dosage and color naming: In low-{UV} localities, languages generally have the word ``blue''; in high-{UV} areas, languages without ``blue'' prevail. Furthermore, speakers of these non-``blue'' languages often show blue-yellow color vision deficiency. We tested our phototoxicity hypothesis in a color-naming experiment, using computerized, colorimetric simulations of Munsell colors as viewed through clear and brunescent lenses. As predicted, our young subjects used ``blue'' as in English when the simulated lens was clear, but named colors as in tropical languages when the lens was dense. Our within-subjects design precludes a cultural explanation for this result.},
}
@article{montag_rod_1987,
	abstract = {Two protanopes, two deuteranopes, and two normal subjects named 424 {OSA} Uniform Color Scales samples using single-word color terms of their choice under three different experimental conditions. When viewing a stimulus field subtending about 4 deg, the performance of the dichromats revealed a substantial ability to discriminate colors along the red-green axis. When the stimuli were limited to the central fovea, or when rods were excluded with a bleach, dichromats could no longer categorize colors in the red-green dimension. The different conditions did not affect the performance of the normals. The results suggest that rods contribute signals used by dichromats, along with lightness cues, to help discriminate and categorize surface colors.},
}
@article{garcin_optic_????,
}
@article{jax_response_2010,
	abstract = {Viewing objects with the intention to act upon them may activate task-irrelevant motor responses. Many manufactured objects are associated with two action classes: grasping in accordance with object structure and skillful use consistent with object function. We studied the potential for within-object competition during action selection by comparing initiation latencies for ``conflict'' objects (with competing structure and function responses) to ``non-conflict'' objects (with a single response). We demonstrated a novel pattern of within-object interference wherein actions involving conflict objects were slowed when participants skillfully used those objects (grasp-on-use interference) as well as a second pattern of interference when conflict objects were grasped after skillfully using the same objects in previous blocks (long-term use-on-grasp interference). These data suggest that actions to common objects are influenced by competition between rapid but briefly maintained grasp responses and slower but longer-lasting use responses, and advance our understanding of the process and neural substrates of selection for action.},
}
@article{pylkkanen_representation_2006,
}
@article{ellenbogen_interfering_2006,
}
@article{fox_nonoxidative_1988,
	abstract = {Brain glucose uptake, oxygen metabolism, and blood flow in humans were measured with positron emission tomography, and a resting-state molar ratio of oxygen to glucose consumption of 4.1:1 was obtained. Physiological neural activity, however, increased glucose uptake and blood flow much more (51 and 50 percent, respectively) than oxygen consumption (5 percent) and produced a molar ratio for the increases of 0.4:1. Transient increases in neural activity cause a tissue uptake of glucose in excess of that consumed by oxidative metabolism, acutely consume much less energy than previously believed, and regulate local blood flow for purposes other than oxidative metabolism.},
}
@article{watson_action_2013,
	abstract = {Many recent neuroimaging studies have investigated the representation of semantic memory for actions in the brain. We used activation likelihood estimation ({ALE)} meta-analyses to answer two outstanding questions about the neural basis of action concepts. First, on an ``embodied'' view of semantic memory, evidence to date is unclear regarding whether visual motion or motor systems are more consistently engaged by action concepts. Second, few studies have directly investigated the possibility that action concepts accessed verbally or nonverbally recruit different areas of the brain. Because our meta-analyses did not include studies requiring the perception of dynamic depictions of actions or action execution, we were able to determine whether conceptual processing alone recruits visual motion and motor systems. Significant concordance in brain regions within or adjacent to visual motion areas emerged in all meta-analyses. By contrast, we did not observe significant concordance in motor or premotor cortices in any analysis. Neural differences between action images and action verbs followed a gradient of abstraction among representations derived from visual motion information in the left lateral temporal and occipital cortex. The consistent involvement of visual motion but not motor brain regions in representing action concepts may reflect differences in the variability of experience across individuals with perceiving versus performing actions.},
}
@article{binkofski_fronto-parietal_1999,
	abstract = {Functional magnetic resonance imaging ({fMRI)} was used to localize brain areas active during manipulation of complex objects. In one experiment subjects were required to manipulate complex objects for exploring their macrogeometric features as compared to manipulation of a simple smooth object (a sphere). In a second experiment subjects were asked to manipulate complex objects and to silently name them upon recognition as compared to manipulation of complex not recognizable objects without covert naming. Manipulation of complex objects resulted in an activation of ventral premotor cortex [Brodmann's area ({BA)} 44], of a region in the intraparietal sulcus (most probably corresponding to the anterior intraparietal area in the monkey), of area {SII} and of a sector of the superior parietal lobule. When the objects were covertly named additional activations were found in the opercular part of {BA} 44 and in the pars triangularis of the inferior frontal gyrus ({BA} 45). We suggest that a fronto-parietal circuit for manipulation of objects exists in humans and involves basically the same areas as in the monkey. It is proposed that area {SII} analyses the intrinsic object characteristics whilst the superior parietal lobule is related to kinaesthesia.},
}
@article{field_functional_2010,
	abstract = {To understand a neural circuit requires knowledge of its connectivity. Here we report measurements of functional connectivity between the input and ouput layers of the macaque retina at single-cell resolution and the implications of these for colour vision. Multi-electrode technology was used to record simultaneously from complete populations of the retinal ganglion cell types (midget, parasol and small bistratified) that transmit high-resolution visual signals to the brain. Fine-grained visual stimulation was used to identify the location, type and strength of the functional input of each cone photoreceptor to each ganglion cell. The populations of {ON} and {OFF} midget and parasol cells each sampled the complete population of long- and middle-wavelength-sensitive cones. However, only {OFF} midget cells frequently received strong input from short-wavelength-sensitive cones. {ON} and {OFF} midget cells showed a small non-random tendency to selectively sample from either long- or middle-wavelength-sensitive cones to a degree not explained by clumping in the cone mosaic. These measurements reveal computations in a neural circuit at the elementary resolution of individual neurons.
}
@article{pascual_large-scale_2013,
	abstract = {The most rostral portion of the human temporal cortex, the temporal pole ({TP)}, has been described as ``enigmatic'' because its functional neuroanatomy remains unclear. Comparative anatomy studies are only partially helpful, because the human {TP} is larger and cytoarchitectonically more complex than in nonhuman primates. Considered by Brodmann as a single area ({BA} 38), the human {TP} has been recently parceled into an array of cytoarchitectonic subfields. In order to clarify the functional connectivity of subregions of the {TP}, we undertook a study of 172 healthy adults using resting-state functional connectivity {MRI.} Remarkably, a hierarchical cluster analysis performed to group the seeds into distinct subsystems according to their large-scale functional connectivity grouped 87.5\% of the seeds according to the recently described cytoarchitectonic subregions of the {TP.} Based on large-scale functional connectivity, there appear to be 4 major subregions of the {TP:} 1) dorsal, with predominant connectivity to auditory/somatosensory and language networks; 2) ventromedial, predominantly connected to visual networks; 3) medial, connected to paralimbic structures; and 4) anterolateral, connected to the default-semantic network. The functional connectivity of the human {TP}, far more complex than its known anatomic connectivity in monkey, is concordant with its hypothesized role as a cortical convergence zone.},
}
@article{moss_anteromedial_2005-2,
}
@article{adlam_semantic_2006,
	abstract = {Considerable controversy exists regarding the relationship between semantic dementia ({SD)} and progressive aphasia. {SD} patients present with anomia and impaired word comprehension. The widely used consensus criteria also include the need for patients to exhibit associative agnosia and/or prosopagnosia: many authors have used the label {SD} for patients with non-verbal, as well as verbal, semantic deficits on formal testing even if they recognize the objects and people encountered in everyday life; others interpret the criterion of agnosia to require pervasive recognition impairments affecting daily life. According to this latter view, {SD} patients have pathology that disrupts both a bilateral ventrotemporal-fusiform network (resulting in agnosia) and the left hemisphere language network (resulting in profound aphasia). These authors suggest that this profile is different to that seen in the fluent form of primary progressive aphasia ({fPPA)}, a neurodegenerative disease primarily affecting language function. We present data on seven patients who met the diagnostic criteria for {fPPA.} All seven showed deficits relative to matched controls on both verbal and non-verbal measures of semantic memory, and these deficits were modulated by degree of anomia, concept familiarity and item typicality. Voxel-based morphometry revealed reduced grey matter density in the temporal lobes bilaterally (more widespread on the left), with the severity of atrophy in the left inferior temporal lobe being significantly related to performance on both the verbal and non-verbal measures. Together these findings suggest that patients who meet the diagnostic criteria for {fPPA}, can also meet the diagnostic criteria for early-stage {SD} provided that the impact of concept familiarity and typicality is taken into account. In addition, these findings support a claim that the patients' deficits on both verbal and non-verbal tasks reflect progressive deterioration of an amodal integrative semantic memory system critically involving the rostral temporal lobes, rather than a combination of atrophy in the left language network and a separate bilateral ventrotemporal-fusiform network.},
}
@article{horwitz_blue-yellow_2005,
	abstract = {We measured the color tuning of a population of S-cone-driven V1 neurons in awake, fixating monkeys. Analysis of randomly chosen color stimuli that were effective in evoking action potentials showed that these neurons received opposite sign input from the S cones and a combination of L and M cones. Surprisingly, these cells also responded to {LM} cone contrast irrespective of polarity, a nonlinear sensitivity that was masked by conventional linear analysis methods. Taken together, these observations can be summarized in a nonlinear model that combines nonopponent and opponent signals such that luminance contrast enhances color processing. These findings indicate that important aspects of the cortical representation of color cannot be described by classical linear analysis, and reveal a possible neural correlate of perceptual color-luminance interactions.},
}
@article{haslam_does_2007,
	abstract = {Recent neuropsychological evidence, supporting a strong version of Whorfian principles of linguistic relativity, has reinvigorated debate about the role of language in colour categorisation. This paper questions the methodology used in this research and uses a novel approach to examine the unique contribution of language to categorisation behaviour. Results of three investigations are reported. The first required development of objective measures of category coherence and consistency to clarify questions about healthy control performance on the freesorting colour categorisation task used in previous studies. Between-participant consistency was found to be only moderate and the number of colour categories generated was found to vary markedly between individuals. The second study involved longitudinal neuropsychological examination of a patient whose colour categorisation strategy was monitored in the context of a progressive decline in language due to semantic dementia. Performance on measures of category coherence and consistency was found to be relatively stable over time despite a profound decline in the patient's colour language. In a final investigation we demonstrated that, for both the patient and controls, between- and within-participant consistency were higher than expected by (a) random sorting and (b) sorting perceptually similar chips together. These findings indicate that the maintenance of colour categorisation need not depend on language.},
}
@article{franklin_color_2005,
	abstract = {Categorical perception of color is shown when colors from the same category are discriminated less easily than equivalently spaced colors that cross a category boundary. The current experiments tested various models of categorical perception. Experiment 1 tested for categorical responding in 2- to 4-year-olds, the age range for the onset establishment of color term knowledge. Experiment 2 tested for categorical responding in Himba toddlers, whose language segments the color space differently from the way in which the English language does so. Experiment 3 manipulated the conditions of the task to explore whether the categorical responding in Experiments 1 and 2 was equivalent to categorical perception. Categorical perception was shown irrespective of naming and was not stronger in those children with more developed color term knowledge. Cross-cultural differences in the extent of categorical perception were not found. These findings support universalistic models of color categorization and suggest that color term knowledge does not modify categorical perception, at least during the early stages of childhood.},
}
@article{rudrauf_disconnections_2008,
	abstract = {Group-level voxelwise statistical analyses of lesion-deficit relationships have been used to implicate brain structures critical for specific aspects of human cognition and behavior. Current approaches fail to account for the role of fiber tract disruptions in causing deficit, and confound cortical damage with damage to fibers of passage. Here, we develop a framework, Generalized Lesion-Symptom Mapping ({GLSM)}, to integrate fiber tract information from {DTI-based} tractographic atlases in tractwise and voxelwise lesion-deficit analyses. First, we used the geniculo-calcarine system as a validation testbed. Using logistic regressions we predicted right homonymous visual field deficits in 149 subjects with focal brain damage based on lesion location, with and without incorporating fiber tract information. A probabilistic fiber tract atlas [Wakana S, Jiang H, Nagae-Poetscher {LM}, Van Zijl {PC}, Mori S. Fiber tract-based atlas of human white matter anatomy. Radiology 2004;230:77--87] coregistered to our reference brain was used to estimate disconnection to the optic radiations and adjacent fiber tracts. When tract information was not incorporated, lesions in multiple sectors of the temporal lobe were associated with visual field defects. When the optic radiations were incorporated, this artifactual association was eliminated and the calcarine cortex was correctly isolated. Among the incorporated tracts, only the optic radiations significantly predicted visual field defects. Second, we applied the approach to impairments of higher visuoperceptual functions in 111 subjects who were administered the Hooper Visual Organization Test. We included all six association fiber tracts available in the atlas, plus the optic radiations. Tract inclusion narrowed the cortical sectors associated with impaired performance in a manner consistent with recent {fMRI} findings. The left cingulum and inferior longitudinal fasciculus, significantly predicted impairments. The results demonstrate the viability, validity and value of incorporating fiber tract information in lesion-deficit analyses. The enhanced analysis framework opens a new avenue for studying neural systems, with the potential to facilitate identification of both cortical sectors and fiber tracts critical for cognitive functioning.},
}
@article{vannucci2001identification,
abstract = {The different weight of spatial frequency content in the identification of visual objects was investigated. Subjects were required to identify spatially filtered pictures of animals, vegetables and nonliving objects, displayed at 9 resolution levels of filtering following a coarse-to-fine order. Results showed that spatial frequency content differentially affected the three categories of stimuli. Data suggested a different involvement of low and high spatial frequency channels in visual processing of objects in relation to the semantic category.},
}
@article{ruby_effect_2001,
	abstract = {Perspective taking is an essential component in the mechanisms that account for intersubjectivity and agency. Mental simulation of action can be used as a natural protocol to explore the cognitive and neural processing involved in agency. Here we took {PET} measurements while subjects simulated actions with either a first-person or a third-person perspective. Both conditions were associated with common activation in the {SMA}, the precentral gyrus, the precuneus and the {MT/V5} complex. When compared to the first-person perspective, the third-person perspective recruited right inferior parietal, precuneus, posterior cingulate and frontopolar cortex. The opposite contrast revealed activation in left inferior parietal and somatosensory cortex. We suggest that the right inferior parietal, precuneus and somatosensory cortex are specifically involved in distinguishing self-produced actions from those generated by others.},
}
@article{freeman_top-down_2003,
	abstract = {Attention can modulate sensitivity to local stimuli in early vision. But, can attention also modulate integration of local stimuli into global visual patterns? We recently measured effects of attention on the phenomenon of lateral interactions between collinear elements, commonly thought to reflect long-range mechanisms in early visual cortex underlying contour integration. We showed improved detection of low-contrast central Gabor targets in the context of collinear flankers, but only when the collinear flankers were attended for a secondary task rather than ignored in favor of an orthogonal flanker pair. Here, we contrast two hypotheses for how attention might modulate flanker influences on the target: by changing just local sensitivity to the flankers themselves (flanker-modulation-only hypothesis), or by weighting integrative connections between flanker and target (connection-weighting hypothesis). Modeled on the known nonlinear dependence of target visibility on collinear flanker contrast, the first hypothesis predicts that an increase in physical flanker contrast should readily offset any reduction in their effective contrast when ignored, thus eliminating attentional modulation. Conversely, the second hypothesis predicts that attentional modulation should persist even for the highest flanker contrasts. Our results showed the latter outcome and indicated that attention modulates flanker-target integration, rather than just processing of local flanker elements.},
}
@article{solomon_machinery_2007,
	abstract = {Some fundamental principles of colour vision, deduced from perceptual studies, have been understood for a long time. Physiological studies have confirmed the existence of three classes of cone photoreceptors, and of colour-opponent neurons that compare the signals from cones, but modern work has drawn attention to unexpected complexities of early organization: the proportions of cones of different types vary widely among individuals, without great effect on colour vision; the arrangement of different types of cones in the mosaic seems to be random, making it hard to optimize the connections to colour-opponent mechanisms; and new forms of colour-opponent mechanisms have recently been discovered. At a higher level, in the primary visual cortex, recent studies have revealed a simpler organization than had earlier been supposed, and in some respects have made it easier to reconcile physiological and perceptual findings.},
}
@article{bickerton_case_2007,
}
@article{hennevin_learning-induced_1993,
	abstract = {Fear conditioning to an acoustic stimulus produces increases in tone-evoked discharges of neurons in the medial division of the medial geniculate nucleus ({MG).} This study examined the responses of {MG} neurons to a conditioned tone presented in paradoxical sleep ({PS).} After 1 session of habituation to a tone, awake rats underwent conditioning in 3 sessions during which the tone was used as the {CS} preceding a footshock. Control rats received unpaired presentations of tone and shock. The same tone, which never awakened the animal, was presented during {PS} following each daily session. Responses of {MG} neurons to the tone in {PS} were increased after conditioning. This enhancement was as large as that in waking and was manifested earlier after tone onset than in waking. No change appeared after pseudoconditioning. These results demonstrate that associatively induced plasticity in the {MG} can be expressed during {PS.} ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved)},
}
@article{wang_decoding_2012,
	abstract = {Previously, multi-voxel pattern analysis has been used to decode words referring to concrete object categories. In this study we investigated if single-trial-based brain activity was sufficient to distinguish abstract (e.g., mercy) versus concrete (e.g., barn) concept representations. Multiple neuroimaging studies have identified differences in the processing of abstract versus concrete concepts based on the averaged activity across time by using univariate methods. In this study we used multi-voxel pattern analysis to decode functional magnetic resonance imaging ({fMRI)} data when participants perform a semantic similarity judgment task on triplets of either abstract or concrete words with similar meanings. Classifiers were trained to identify individual trials as concrete or abstract. Cross-validated accuracies for classifying trials as abstract or concrete were significantly above chance (P {\textless} 0.05) for all participants. Discriminating information was distributed in multiple brain regions. Moreover, accuracy of identifying single trial data for any one participant as abstract or concrete was also reliably above chance (P {\textless} 0.05) when the classifier was trained solely on data from other participants. These results suggest abstract and concrete concepts differ in representations in terms of neural activity patterns during a short period of time across the whole brain. Hum Brain Mapp, 2012. \copywrite 2012 Wiley Periodicals, Inc.},
}
@article{dalgleish_biases_1990-1,
	abstract = {Theoretical frameworks and experimental paradigms derived from cognitive psychology provide a valuable approach to the investigation of cognitive aspects of disorders of anxiety and depression. Review of the literature provides strong evidence of attentional bias towards threat stimuli in anxiety, though evidence of comparable attentional bias in depression is weaker. There is also strong evidence of memory bias towards mood-congruent materials in depression, though comparable evidence regarding anxiety-congruent memory is mixed. A variety of theoretical frameworks for explaining such phenomena have been advanced, using concepts such as networks, schema and mental models. There is a need now for theoretical frameworks that address themselves to the specificity of the empirical phenomena. Clinical and empirical implications of these findings and models are discussed, including developments in diathesis-stress models of psychopathology, the use of experimental-cognitive paradigms in clinical assessment, and the prospect of therapeutic applications.},
}
@article{chu_kernel_2011,
	abstract = {This paper introduces two kernel-based regression schemes to decode or predict brain states from functional brain scans as part of the Pittsburgh Brain Activity Interpretation Competition ({PBAIC)} 2007, in which our team was awarded first place. Our procedure involved image realignment, spatial smoothing, detrending of low-frequency drifts, and application of multivariate linear and non-linear kernel regression methods: namely kernel ridge regression ({KRR)} and relevance vector regression ({RVR).} {RVR} is based on a Bayesian framework, which automatically determines a sparse solution through maximization of marginal likelihood. {KRR} is the dual-form formulation of ridge regression, which solves regression problems with high dimensional data in a computationally efficient way. Feature selection based on prior knowledge about human brain function was also used. Post-processing by constrained deconvolution and re-convolution was used to furnish the prediction. This paper also contains a detailed description of how prior knowledge was used to fine tune predictions of specific ``feature ratings,'' which we believe is one of the key factors in our prediction accuracy. The impact of pre-processing was also evaluated, demonstrating that different pre-processing may lead to significantly different accuracies. Although the original work was aimed at the {PBAIC}, many techniques described in this paper can be generally applied to any {fMRI} decoding works to increase the prediction accuracy.},
}
@article{bradley_implicit_1995-1,
	abstract = {Implicit and explicit memory biases were assessed in clinically depressed (n = 19), clinically anxious (n = 17), and normal control (n = 18) Ss. The implicit memory test was a primed lexical decision task, with anxiety- and depression-relevant words, and suprathreshold and subthreshold primes. The explicit memory test was incidental free recall of self-referenced words. The depressed group showed greater suprathreshold and subthreshold priming effects for depression words, and recalled more depression words, than the other two groups. These results suggest that clinical depression, but not clinical anxiety, is associated with mood-congruent biases in both automatic and strategic memory processes.},
}
@article{shaver_emotion_1987,
	abstract = {Recent work on natural categories suggests a framework for conceptualizing people's knowledge about emotions. Categories of natural objects or events, including emotions, are formed as a result of repeated experiences and become organized around prototypes (Rosch, 1978); the interrelated set of emotion categories becomes organized within an abstract-to-concrete hierarchy. At the basic level of the emotion hierarchy one finds the handful of concepts (love, joy, anger, sadness, fear, and perhaps, surprise) most useful for making everyday distinctions among emotions, and these overlap substantially with the examples mentioned most readily when people are asked to name emotions (Fehr \& Russell, 1984), with the emotions children learn to name first (Bretherton \& Beeghly, 1982), and with what theorists have called basic or primary emotions. This article reports two studies, one exploring the hierarchical organization of emotion concepts and one specifying the prototypes, or scripts, of five basic emotions, and it shows how the prototype approach might be used in the future to investigate the processing of information about emotional events, cross-cultural differences in emotion concepts, and the development of emotion knowledge.},
}
@article{barsalou_grounded_2008,
	abstract = {Grounded cognition rejects traditional views that cognition is computation on amodal symbols in a modular system, independent of the brain's modal systems for perception, action, and introspection. Instead, grounded cognition proposes that modal simulations, bodily states, and situated action underlie cognition. Accumulating behavioral and neural evidence supporting this view is reviewed from research on perception, memory, knowledge, language, thought, social cognition, and development. Theories of grounded cognition are also reviewed, as are origins of the area and common misperceptions of it. Theoretical, empirical, and methodological issues are raised whose future treatment is likely to affect the growth and impact of grounded cognition.},
}
@article{roberson_color_2000,
	abstract = {The authors sought to replicate and extend the work of E. Rosch Heider (1972) on the Dani with a comparable group from Papua, New Guinea, who speak Berinmo, which has 5 basic color terms. Naming and memory for highly saturated focal, non-focal, and low-saturation stimuli from around the color space were investigated. Recognition of desaturated colors was affected by color vocabulary. When response bias was controlled, there was no recognition advantage for focal stimuli. Paired-associate teaming also failed to show an advantage for focal stimuli. Categorical Perception effects for both English and Berinmo were found, but only at the boundaries of existing linguistic categories. It is concluded that possession of linguistic categories facilitates recognition and influences perceptual judgments.},
}
@article{woollams_sd-squared:_2007,
	abstract = {Within the connectionist triangle model of reading aloud, interaction between semantic and phonological representations occurs for all words but is particularly important for correct pronunciation of lower frequency exception words. This framework therefore predicts that (a) semantic dementia, which compromises semantic knowledge, should be accompanied by surface dyslexia, a frequency-modulated deficit in exception word reading, and (b) there should be a significant relationship between the severity of semantic degradation and the severity of surface dyslexia. The authors evaluated these claims with reference to 100 observations of reading data from 51 cases of semantic dementia. Surface dyslexia was rampant, and a simple composite semantic measure accounted for half of the variance in low-frequency exception word reading. Although in 3 cases initial testing revealed a moderate semantic impairment but normal exception word reading, all of these became surface dyslexic as their semantic knowledge deteriorated further. The connectionist account attributes such cases to premorbid individual variation in semantic reliance for accurate exception word reading. These results provide a striking demonstration of the association between semantic dementia and surface dyslexia, a phenomenon that the authors have dubbed {SD-squared.}},
}
@article{diekelmann_whats_2009,
	abstract = {Summary
}
@article{perkins_lexical_2006,
}
@article{humphreys_motion_2013,
	abstract = {Understanding verbs typically activates posterior temporal regions and, in some circumstances, motion perception area V5. However, the nature and role of this activation remains unclear: does language alone indeed activate V5? And are posterior temporal representations modality-specific motion representations, or supra-modal motion-independent event representations? Here, we address these issues by investigating human and object motion sentences compared to corresponding state descriptions. We adopted the blank screen paradigm, which is known to encourage visual imagery, and used a localizer to identify V5 and temporal structures responding to motion. Analyses in each individual brain suggested that language modulated activity in the posterior temporal lobe but not within V5 in most participants. Moreover, posterior temporal structures strongly responded to both motion sentences and human static sentences. These results suggest that descriptive language alone need not recruit V5 and instead engages more schematic event representations in temporal cortex encoding animacy and motion.},
}
@article{kay_color_2007,
	abstract = {Proponents of a self-identified 'relativist' view of cross-language color naming have confounded two questions: (1) Is color naming largely subject to local linguistic convention? and (2) Are cross-language color naming differences reflected in comparable differences in color cognition by their speakers? The 'relativist' position holds that the correct answer to both questions is Yes, based on data from the Berinmo language of Papua New Guinea. It is shown here that the Berinmo facts instead support a more complex view -- that cross-language color naming follows non-trivial universal tendencies, while cross-language color-naming differences do indeed correlate with differences in color cognition. The rhetoric of 'relativity' versus 'universalism' impedes understanding of cross-language color naming and cognition.},
}
@article{mahon_category-specific_2009,
	abstract = {Summary
}
@article{humphreys_motion_2013-1,
	abstract = {Understanding verbs typically activates posterior temporal regions and, in some circumstances, motion perception area V5. However, the nature and role of this activation remains unclear: does language alone indeed activate V5? And are posterior temporal representations modality-specific motion representations, or supra-modal motion-independent event representations? Here, we address these issues by investigating human and object motion sentences compared to corresponding state descriptions. We adopted the blank screen paradigm, which is known to encourage visual imagery, and used a localizer to identify V5 and temporal structures responding to motion. Analyses in each individual brain suggested that language modulated activity in the posterior temporal lobe but not within V5 in most participants. Moreover, posterior temporal structures strongly responded to both motion sentences and human static sentences. These results suggest that descriptive language alone need not recruit V5 and instead engages more schematic event representations in temporal cortex encoding animacy and motion.},
}
@article{fedorenko_lexical_2012,
	abstract = {Work in theoretical linguistics and psycholinguistics suggests that human linguistic knowledge forms a continuum between individual lexical items and abstract syntactic representations, with most linguistic representations falling between the two extremes and taking the form of lexical items stored together with the syntactic/semantic contexts in which they frequently occur. Neuroimaging evidence further suggests that no brain region is selectively sensitive to only lexical information or only syntactic information. Instead, all the key brain regions that support high-level linguistic processing have been implicated in both lexical and syntactic processing, suggesting that our linguistic knowledge is plausibly represented in a distributed fashion in these brain regions. Given this distributed nature of linguistic representations, multi-voxel pattern analyses ({MVPAs)} can help uncover important functional properties of the language system. In the current study we use {MVPAs} to ask two questions: (1) Do language brain regions differ in how robustly they represent lexical vs. syntactic information? and (2) Do any of the language bran regions distinguish between ``pure'' lexical information (lists of words) and ``pure'' abstract syntactic information (jabberwocky sentences) in the pattern of activity? We show that lexical information is represented more robustly than syntactic information across many language regions (with no language region showing the opposite pattern), as evidenced by a better discrimination between conditions that differ along the lexical dimension (sentences vs. jabberwocky, and word lists vs. nonword lists) than between conditions that differ along the syntactic dimension (sentences vs. word lists, and jabberwocky vs. nonword lists). This result suggests that lexical information may play a more critical role than syntax in the representation of linguistic meaning. We also show that several language regions reliably discriminate between ``pure'' lexical information and ``pure'' abstract syntactic information in their patterns of neural activity.},
}
@article{fishbein_disruptive_1971,
	abstract = {The fact that sleep is associated with very active endogenous neural (chemical and electrical) processes, suggests that these processes may be involved in the maintenance of long-term memory storage. The present experiments were designed to examine the hypothesis that rapid eye movement ({REM)} sleep deprivation will produce impairment of long-term memory. Mice deprived of {REM} sleep for 3, 5 or 7 continuous days, during the interval between a one-trial inhibitory avoidance training experience and a subsequent retention test, displayed a temporary retrograde amnesia when tested 30 min or three hr following termination of {REM} deprivation. The mice did not recover from the amnesia if electroconvulsive shock was administered immediately following the interval of {REM} sleep deprivation. In a further study, the generality of these findings was obtained by depriving mice of {REM} sleep during the interval between a discrimination training experiment in a black-white T-maze and the subsequent retention test.},
}
@incollection{ghosh_adaptive_2012-1,
}
@article{makar_formate_1975-1,
}
@article{postle_working_2006,
	abstract = {Cognitive neuroscience research on working memory has been largely motivated by a standard model that arose from the melding of psychological theory with neuroscience data. Among the tenets of this standard model are that working memory functions arise from the operation of specialized systems that act as buffers for the storage and manipulation of information, and that frontal cortex (particularly prefrontal cortex) is a critical neural substrate for these specialized systems. However, the standard model has been a victim of its own success, and can no longer accommodate many of the empirical findings of studies that it has motivated. An alternative is proposed: Working memory functions arise through the coordinated recruitment, via attention, of brain systems that have evolved to accomplish sensory-, representation-, and action-related functions. Evidence from behavioral, neuropsychological, electrophysiological, and neuroimaging studies, from monkeys and humans, is considered, as is the question of how to interpret delay-period activity in the prefrontal cortex.},
}
@article{bramao_interaction_2012,
	abstract = {In this study, we used event-related potentials ({ERPs)} to evaluate the contribution of surface color and color knowledge information in object identification. We constructed two color-object verification tasks -- a surface and a knowledge verification task -- using high color diagnostic objects; both typical and atypical color versions of the same object were presented. Continuous electroencephalogram was recorded from 26 subjects. A cluster randomization procedure was used to explore the differences between typical and atypical color objects in each task. In the color knowledge task, we found two significant clusters that were consistent with the N350 and late positive complex ({LPC)} effects. Atypical color objects elicited more negative {ERPs} compared to typical color objects. The color effect found in the N350 time window suggests that surface color is an important cue that facilitates the selection of a stored object representation from long-term memory. Moreover, the observed {LPC} effect suggests that surface color activates associated semantic knowledge about the object, including color knowledge representations. We did not find any significant differences between typical and atypical color objects in the surface color verification task, which indicates that there is little contribution of color knowledge to resolve the surface color verification. Our main results suggest that surface color is an important visual cue that triggers color knowledge, thereby facilitating object identification.},
}
@article{rosch_natural_1973,
	abstract = {The hypothesis of the study was that the domains of color and form are structured into nonarbitrary, semantic categories which develop around perceptually salient ``natural prototypes.'' Categories which reflected such an organization (where the presumed natural prototypes were central tendencies of the categories) and categories which violated the organization (natural prototypes peripheral) were taught to a total of 162 members of a Stone Age culture which did not initially have hue or geometric-form concepts. In both domains, the presumed ``natural'' categories were consistently easier to learn than the ``distorted'' categories. Even when not central, natural prototype stimuli tended to be more rapidly learned and more often chosen as the most typical example of the category than were other stimuli. Implications for general differences between natural categories and the artificial categories of concept formation research were discussed.},
}
@article{mahon_concepts_2009,
	abstract = {One of the most provocative and exciting issues in cognitive science is how neural specificity for semantic categories of common objects arises in the functional architecture of the brain. More than two decades of research on the neuropsychological phenomenon of category-specific semantic deficits has generated detailed claims about the organization and representation of conceptual knowledge. More recently, researchers have sought to test hypotheses developed on the basis of neuropsychological evidence with functional imaging. From those two fields, the empirical generalization emerges that object domain and sensory modality jointly constrain the organization of knowledge in the brain. At the same time, research within the embodied cognition framework has highlighted the need to articulate how information is communicated between the sensory and motor systems, and processes that represent and generalize abstract information. Those developments point toward a new approach for understanding category specificity in terms of the coordinated influences of diverse regions and cognitive systems.},
}
@article{broughton_human_1982,
}
@article{wright_psychometric_1972,
}
@article{zacks_event_2007,
	abstract = {People perceive and conceive of activity in terms of discrete events. Here we propose a theory according to which the perception of boundaries between events arises from ongoing perceptual processing and regulates attention and memory. Perceptual systems continuously make predictions about what will happen next. When transient errors in predictions arise, an event boundary is perceived. According to the theory, the perception of events depends on both sensory cues and knowledge structures that represent previously learned information about event parts and inferences about actors' goals and plans. Neurological and neurophysiological data suggest that representations of events may be implemented by structures in the lateral prefrontal cortex and that perceptual prediction error is calculated and evaluated by a processing pathway including the anterior cingulate cortex and subcortical neuromodulatory systems.},
}
@article{oreilly_conjunctive_2001,
	abstract = {The authors present a theoretical framework for understanding the roles of the hippocampus and neocortex in learning and memory. This framework incorporates a theme found in many theories of hippocampal function: that the hippocampus is responsible for developing conjunctive representations binding together stimulus elements into a unitary representation that can later be recalled from partial input cues. This idea is contradicted by the fact that hippocampally lesioned rats can learn nonlinear discrimination problems that require conjunctive representations. The authors' framework accommodates this finding by establishing a principled division of labor, where the cortex is responsible for slow learning that integrates over multiple experiences to extract generalities whereas the hippocampus performs rapid learning of the arbitrary contents of individual experiences. This framework suggests that tasks involving rapid, incidental conjunctive learning are better tests of hippocampal function. The authors implement this framework in a computational neural network model and show that it can account for a wide range of data in animal learning.},
}
@article{stein_high-level_2011,
	abstract = {When incompatible images are presented to the two eyes, one image dominates awareness while the other is rendered invisible by interocular suppression. It has remained unclear whether complex visual information can reach high-level processing stages in the ventral visual pathway during such interocular suppression. Here, we asked whether basic face shape, which is thought to be encoded in areas of the ventral stream, can be processed without visual awareness. We measured aftereffects induced by prolonged exposure to distorted faces during continuous flash suppression. Despite constant physical stimulation, in some trials the adaptor face was fully suppressed from awareness, while in other trials it overcame suppression and became partially visible. Aftereffects were induced even by entirely invisible adaptors, albeit reduced compared to partially visible adaptors, and only when adaptor and test stimuli were presented in the same size to the same eye. However, when adaptor and test stimuli were presented to different eyes or to the same eye but in different sizes, aftereffects were restricted to partially visible adaptors. These results suggest that a monocular, low-level component of face shape adaptation escapes interocular suppression and can proceed without visual awareness. By contrast, high-level components of basic face shape encoding involving ventral stream processing are eliminated by interocular suppression and require visual awareness.},
}
@article{ricci_functional_1999,
	abstract = {In an effort to examine the functional neuroanatomy of semantic memory, we studied the relative cerebral blood flow of eight healthy young subjects using {15O-water} positron emission tomography ({PET).} Relative to a visual baseline control condition, each of four visual matching-to-sample tasks activated components of the ventral visual processing stream, including the inferior occipital and temporal cortices. Contrasting the task with the highest semantic component, a variation on the Pyramids and Palm Trees paradigm, with a size discrimination task resulted in focal activation in the anterior inferior temporal lobe, focused in the parahippocampal gyrus. There was additional activation in {BA47} of the inferior frontal cortex. These data replicate and extend previously reported results using similar paradigms, and are consistent with cognitive neuropsychological models that stress the executive role of {BA47} in semantic processing tasks.},
}
@article{regier_language_2009,
	abstract = {The Whorf hypothesis holds that we view the world filtered through the semantic categories of our native language. Over the years, consensus has oscillated between embrace and dismissal of this hypothesis. Here, we review recent findings on the naming and perception of color, and argue that in this semantic domain the Whorf hypothesis is half right, in two different ways: (1) language influences color perception primarily in half the visual field, and (2) color naming across languages is shaped by both universal and language-specific forces. To the extent that these findings generalize to other semantic domains they suggest a possible resolution of the debate over the Whorf hypothesis.},
}
@article{tsuchiya_continuous_2004,
	abstract = {Visual illusions that produce perceptual suppression despite constant retinal input, such as binocular rivalry ({BR)} or flash suppression ({FS)}, are potent tools to study the neural correlates of consciousness. However, the duration and timing of perceptual suppression in {BR} are difficult to control, and {FS} attains only short duration of suppression, too short to produce aftereffect. Furthermore, {FS} requires pre-adapting period, which makes it impossible to use in studies that require complete perceptual unawareness. Here, we introduce Continuous Flash Suppression ({CFS).} With {CFS}, we can control the timing of suppression and suppress stimuli for long duration ({\textgreater} several minutes) without subjects noticing the suppressed stimuli at all. We used several categories of figures (Gabor patches and angry faces) as suppressed stimuli and other categories as continuously changing dominant stimuli (Gabor patches of different orientations, random textures consisted of small color rectangles, gray or color neutral faces, scrambled faces). Both stimuli were presented at the fovea (10x10 deg, with a stereoscope, 50 cm from the display). The dominance duration of suppressed stimuli during a 60s trial was the observation variable. As the contrast and saliency of suppressed stimuli decreases, dominance duration of the suppressed figure decreases. As suppressed stimuli are low-pass filtered, the dominance of the suppressed figure decreases. {ISI} between dominant stimuli is crucial; in general, short {ISI} ({\textless}1sec) produces strong and prolonged suppression. Under a wide range of parameters, a stimulus that usually dominates about 30s in a 60s {BR} trial can be suppressed completely (i.e. 0s dominance in a 60s trial). We report a classical human fear conditioning study that utilized {CFS.} Subjects could report their on-going subjective visibility of figures during 2s stimuli presentation, while they tried to associate electrical shocks with angry face stimuli that were completely masked by {CFS.}},
}
@article{boden_semantic_2000,
	abstract = {This paper uses a connectionist model to identify some properties which collectively show that connectionist networks supply means for accomplishing a version of systematicity. It is argued that "context--dependent systematicity" is achievable within a connectionist framework. The arguments put forward rest on a particular formulation of content and context of connectionist representation, based on connectionist primitives in a learning environment. The perspective is motivated by the fundamental differences between the connectionist and classical architectures, in terms of prerequisites, lower-level functionality and inherent constraints. The claim is supported by a set of experiments using a connectionist architecture that demonstrates both an ability of enforcing and how novel items can be handled without prior classification. The claim relies on extended learning feedback which enforces representational context dependence. ({PsycINFO} Database Record (c) 2012 {APA}, all rights reserved)},
}
@article{hanson_brain_2007,
	abstract = {Over the past decade, object recognition work has confounded voxel response detection with potential voxel class identification. Consequently, the claim that there are areas of the brain that are necessary and sufficient for object identification cannot be resolved with existing associative methods (e.g., the general linear model) that are dominant in brain imaging methods. In order to explore this controversy we trained full brain (40,000 voxels) single {TR} (repetition time) classifiers on data from 10 subjects in two different recognition tasks on the most controversial classes of stimuli (house and face) and show 97.4\% median out-of-sample (unseen {TRs)} generalization. This performance allowed us to reliably and uniquely assay the classifier's voxel diagnosticity in all individual subjects' brains. In this two-class case, there may be specific areas diagnostic for house stimuli (e.g., {LO)} or for face stimuli (e.g., {STS);} however, in contrast to the detection results common in this literature, neither the fusiform face area nor parahippocampal place area is shown to be uniquely diagnostic for faces or places, respectively.},
}
@article{grafton_localization_1996,
	abstract = {Positron emission tomography imaging of cerebral blood flow was used to localize brain areas involved in the representation of hand grasping movements. Seven normal subjects were scanned under three conditions. In the first, they observed precision grasping of common objects performed by the examiner. In the second, they imagined themselves grasping the objects without actually moving the hand. These two tasks were compared with a control task of object viewing. Grasp observation activated the left rostral superior temporal sulcus, left inferior frontal cortex (area 45), left rostral inferior parietal cortex (area 40), the rostral part of left supplementary motor area ({SMA-proper)}, and the right dorsal premotor cortex. Imagined grasping activated the left inferior frontal (area 44) and middle frontal cortex, left caudal inferior parietal cortex (area 40), a more extensive response in left rostral {SMA-proper}, and left dorsal premotor cortex. The two conditions activated different areas of the right posterior cerebellar cortex. We propose that the areas active during grasping observation may form a circuit for recognition of hand-object interactions, whereas the areas active during imagined grasping may be a putative human homologue of a circuit for hand grasping movements recently defined in nonhuman primates. The location of responses in {SMA-proper} confirms the rostrocaudal segregation of this area for imagined and real movement. A similar segregation is also present in the cerebellum, with imagined and observed grasping movements activating different parts of the posterior lobe and real movements activating the anterior lobe.},
}
@article{gordon_hayman_role_1993,
	abstract = {The question of whether globally amnesic subjects can learn new semantic (factual) information is controversial. Some students of amnesia believe that they can, others that they cannot. In this article we report an extensive experiment conducted with the amnesic patient {K.C.} in which we examined the role of repetition and associative interference in his learning of new semantic information. In the course of 8 study sessions distributed over 4 weeks, we taught {K.C.} novel, amusing definitions of 96 target words (e.g., ``a talkative {featherbrain---PARAKEET'').} We varied systematically the degree of both pre-experimental and intraexperimental associative interference, as well as the amount of study. The results of the experiment showed that {K.C.} can learn new semantic knowledge, and retain it over a period as long as 30 months indistinguishably from control subjects. The results further showed that the efficacy of such learning depends critically on both repetition of the material and the absence, or minimization, of pre-experimental and intraexperimental associative interference. These findings suggest that the extent to which at least some amnesic patients can acquire and retain new semantic knowledge depends on the conditions under which learning occurs, and that unqualified statements regarding the deficiency or absence of such learning in amnesia are not justified.},
}
@article{ross_whats_2012,
	abstract = {Famous people and artifacts are referred to as ``unique entities'' ({UEs)} due to the unique nature of the knowledge we have about them. Past imaging and lesion experiments have indicated that the anterior temporal lobes ({ATLs)} as having a special role in the processing of {UEs.} It has remained unclear which attributes of {UEs} were responsible for the observed effects in imaging experiments. In this study, we investigated what factors of {UEs} influence brain activity. In a training paradigm, we systematically varied the uniqueness of semantic associations, the presence/absence of a proper name, and the number of semantic associations to determine factors modulating activity in regions subserving the processing of {UEs.} We found that a conjunction of unique semantic information and proper names modulated activity within a section of the left {ATL.} Overall, the processing of {UEs} involved a wider left-hemispheric cortical network. Within these regions, brain activity was significantly affected by the unique semantic attributes especially in the presence of a proper name, but we could not find evidence for an effect of the number of semantic associations. Findings are discussed in regard to current models of {ATL} function, the neurophysiology of semantics, and social cognitive processing.},
}
@article{rodd_modelling_2004,
	abstract = {Most words in English are ambiguous between different interpretations; words can mean different things in different contexts. We investigate the implications of different types of semantic ambiguity for connectionist models of word recognition. We present a model in which there is competition to activate distributed semantic representations. The model performs well on the task of retrieving the different meanings of ambiguous words, and is able to simulate data reported by Rodd, Gaskell, and Marslen-Wilson [J. Mem. Lang. 46 (2002) 245] on how semantic ambiguity affects lexical decision performance. In particular, the network shows a disadvantage for words with multiple unrelated meanings (e.g., bark) that coexists with a benefit for words with multiple related word senses (e.g., twist). The ambiguity disadvantage arises because of interference between the different meanings, while the sense benefit arises because of differences in the structure of the attractor basins formed during learning. Words with few senses develop deep, narrow attractor basins, while words with many senses develop shallow, broad basins. We conclude that the mental representations of word meanings can be modelled as stable states within a high-dimensional semantic space, and that variations in the meanings of words shape the landscape of this space.},
}
@article{chao_representation_2000,
	abstract = {We used {fMRI} to examine the neural response in frontal and parietal cortices associated with viewing and naming pictures of different categories of objects. Because tools are commonly associated with specific hand movements, we predicted that pictures of tools, but not other categories of objects, would elicit activity in regions of the brain that store information about motor-based properties. We found that viewing and naming pictures of tools selectively activated the left ventral premotor cortex ({BA} 6). Single-unit recording studies in monkeys have shown that neurons in the rostral part of the ventral premotor cortex (canonical F5 neurons) respond to the visual presentation of graspable objects, even in the absence of any subsequent motor activity. Thus, the left ventral premotor region that responded selectively to tools in the current study may be the human homolog of the monkey canonical F5 area. Viewing and naming tools also selectively activated the left posterior parietal cortex ({BA} 40). This response is similar to the firing of monkey anterior intraparietal neurons to the visual presentation of graspable objects. In humans and monkeys, there appears to be a close link between manipulable objects and information about the actions associated with their use. The selective activation of the left posterior parietal and left ventral premotor cortices by pictures of tools suggests that the ability to recognize and identify at least one category of objects (tools) may depend on activity in specific sites of the ventral and dorsal visual processing streams.},
}
@article{mahon_representation_2010,
	abstract = {Tool use depends on processes represented in distinct regions of left parietal cortex. We studied the role of visual experience in shaping neural specificity for tools in parietal cortex by using functional magnetic resonance imaging with sighted, late-blind, and congenitally blind participants. Using a region-of-interest approach in which tool-specific areas of parietal cortex were identified in sighted participants viewing pictures, we found that specificity in blood-oxygen-level-dependent responses for tools in the left inferior parietal lobule and the left anterior intraparietal sulcus is independent of visual experience. These findings indicate that motor- and somatosensory-based processes are sufficient to drive specificity for representations of tools in regions of parietal cortex. More generally, some aspects of the organization of the dorsal object-processing stream develop independently of the visual information that forms the major sensory input to that pathway in sighted individuals.},
}
@article{luck_visual_2013,
	abstract = {Visual working memory capacity is of great interest because it is strongly correlated with overall cognitive ability, can be understood at the level of neural circuits, and is easily measured. Recent studies have shown that capacity influences tasks ranging from saccade targeting to analogical reasoning. A debate has arisen over whether capacity is constrained by a limited number of discrete representations or by an infinitely divisible resource, but the empirical evidence and neural network models currently favor a discrete item limit. Capacity differs markedly across individuals and groups, and recent research indicates that some of these differences reflect true differences in storage capacity whereas others reflect variations in the ability to use memory capacity efficiently.},
}
@article{tononi_consciousness_2008,
	abstract = {The integrated information theory ({IIT)} starts from phenomenology and makes use of thought experiments to claim that consciousness is integrated information. Specifically: (i) the quantity of consciousness corresponds to the amount of integrated information generated by a complex of elements; (ii) the quality of experience is specified by the set of informational relationships generated within that complex. Integrated information (Phi) is defined as the amount of information generated by a complex of elements, above and beyond the information generated by its parts. Qualia space (Q) is a space where each axis represents a possible state of the complex, each point is a probability distribution of its states, and arrows between points represent the informational relationships among its elements generated by causal mechanisms (connections). Together, the set of informational relationships within a complex constitute a shape in Q that completely and univocally specifies a particular experience. Several observations concerning the neural substrate of consciousness fall naturally into place within the {IIT} framework. Among them are the association of consciousness with certain neural systems rather than with others; the fact that neural processes underlying consciousness can influence or be influenced by neural processes that remain unconscious; the reduction of consciousness during dreamless sleep and generalized seizures; and the distinct role of different cortical architectures in affecting the quality of experience. Equating consciousness with integrated information carries several implications for our view of nature.},
}
@article{buxbaum_naturalistic_1995,
	abstract = {Abstract We report a subject who, subsequent to closed head injury, demonstrated a severe left hand ideational apraxia and apraxic agraphia, consistent with callosal disconnection syndrome. In contrast to the left hand, performance of the right hand was unimpaired on traditional tests of gesture to command, sight of object, and with actual object use, but proved deficient on tests of spatial and constructional ability. We examined the consequences of these hand-specific deficits for the performance of naturalistic action tasks. The patient made errors with each hand; however, the right hand performed more poorly than the left hand. In addition, the types of errors made by each hand differed in a manner consistent with the results of neuropsychological testing and indicative of disconnection phenomena. We suggest that unlike gesture, naturalistic action requires the contribution of the specialized abilities of each hemisphere, integrated across callosal structures. Traditional testing of gesture may underestimate the right hemisphere's capacity for action programming.},
}
@incollection{raichle_positron-emission_1980,
	abstract = {An understanding of disease processes in the human brain must ultimately be based on a knowledge of the underlying regional hemodynamic, metabolic, and biochemical changes. Although some such information is currently available from various animal models, the conflicting nature of these data often leaves many important questions unanswered and emphasizes the immense difficulty of developing and studying laboratory models of human disease. One obvious alternative is to develop a means by which the hemodynamic, biochemical and metabolic bases of cerebral disease can be safely studied sequentially in humans by using externally detected radiolabeled tracers.},
}
@article{schindler_automatic_2004-1,
	abstract = {When we reach out to pick something up, our arm is directed to the target by visuomotor networks in the cortical dorsal stream. However, our reach trajectories are influenced also by nontarget objects, which might be construed as potential obstacles. We tested two patients with bilateral dorsal-stream (parietal lesions, both of whom were impaired at pointing to visual stimuli (optic ataxia). We asked them to reach between two cylinders, which varied in location from trial to trial. We found that the patients' reaches remained invariant with changes in obstacle location. In a control task when they were asked to point midway between the two objects, however, their responses shifted in an orderly fashion. We conclude that the dorsal stream provides the visual guidance we automatically build into our movements to avoid potential obstacles, as well as that required to ensure arrival at the target.},
}
@article{hendrickson_atomic_1975,
}
@article{medler_functional_2005,
	abstract = {Lesioning studies are often used in cognitive neuroscience to make inferences about the architecture of cognition. Recently, computational models have been used to address some of the underlying assumptions---such as modularity and locality---often implicitly used when interpreting lesion data. In this article, we explore the ``functional localization'' assumption and its role in interpreting lesioning data, especially from double dissociations. The functional localization assumption states that units or subunits within an information processing system become functionally specialized for dealing with specific aspects of the input environment. Networks were trained on one of two problems---an abstract ``rules and sub-rules'' problem, and a more concrete ``logic classification'' problem---and then systematically lesioned. Networks were analyzed in terms of their overt behavior, and more importantly, in terms of their internal structure. Performance deficits in both form and magnitude could be directly related to the ablated internal structure of the networks. That is, if an ablated area had little or no functional localization, then little or no behavioral dissociations were observed. If, however, the ablated area had very specific internal structure, then very specific behavioral dissociations were observed. It is important to note, however, that there was not a one-to-one correspondence between internal structure and behavioral dissociations, implying that cognitive neuroscientists must be careful when using lesioning data to theorize about the functional architecture of cognition.},
}
@article{borowsky_modularity_2005,
	abstract = {Research on the modularity of perceptual and cognitive processes has often pointed to a ventral-dorsal distinction in cortical pathways that depend upon the nature of the stimuli and the task. However, it is not clear whether the dorsal, occipital-parietal stream specializes in locating visual objects (i.e., a ``where'' stream), or taking action toward objects (i.e., a ``how'' stream), although there is some consensus for a ventral, occipital-temporal ``what'' stream that specializes in the identification of visual objects. It is also not clear to what extent word and picture processing are modular along these streams, as functional imaging maps to date have not addressed the modularity question directly. Here we present two types of functional imaging maps that directly show modularity and intersection of processing function for word and picture stimuli in tasks that require decisions about ``what is'', ``where is'', or ``how do you interact with'' a stimulus (N=6 participants). Our results reveal a middle dorsal ``how'' stream with some modular regions of activation that are distinct from activation during ``where'' processing, and that words and pictures involve several modular regions of activation along these streams.},
}
@article{hanson_high-resolution_2011,
	abstract = {Does the "fusiform face area" ({FFA)} code only for faces? This question continues to elude the neuroimaging field due to at least two kinds of problems: first, the relatively low spatial resolution of {fMRI} in which the {FFA} was defined and second, the potential bias inherent in prevailing statistical methods for analyzing the actual diagnosticity of cortical tissue. Using high-resolution (1 mm x 1 mm x 1 mm) imaging data of the fusiform face area ({FFA)} from 4 subjects who had categorized images as 'animal', 'car', 'face', or 'sculpture', we used multivariate linear and non-linear classifiers to decode the resultant voxel patterns. Prior to identifying the appropriate classifier we performed exploratory analysis to determine the nature of the distributions over classes and the voxel intensity pattern structure between classes. The {FFA} was visualized using non-metric multidimensional scaling revealing "string-like" sequences of voxels, which appeared in small non-contiguous clusters of categories, intertwined with other categories. Since this analysis suggested that feature space was highly non-linear, we trained various statistical classifiers on the class-conditional distributions (labelled) and separated the four categories with 100\% reliability (over replications) and generalized to out-of-sample cases with high significance (up to 50\%; p{\textless}.000001, chance=25\%). The increased noise inherent in high-resolution neuroimaging data relative to standard resolution resisted any further gains in category performance above {\textasciitilde}60\% (with {FACE} category often having the highest bias per category) even coupled with various feature extraction/selection methods. A sensitivity/diagnosticity analysis for each classifier per voxel showed: (1) reliable (with {S.E.{\textless}3\%)} sensitivity present throughout the {FFA} for all 4 categories, and (2) showed multi-selectivity; that is, many voxels were selective for more than one category with some high diagnosticity but at submaximal intensity. This work is clearly consistent with the characterization of the {FFA} as a distributed, object-heterogeneous similarity structure and bolsters the view that the {FFA} response to {"FACE"} stimuli in standard resolution may be primarily due to a linear bias, which has resulted from an averaging artefact.},
}
@article{mcnorgan_integrating_2011,
	abstract = {Research suggests that concepts are distributed across brain regions specialized for processing information from different sensorimotor modalities. Multimodal semantic models fall into one of two broad classes differentiated by the assumed hierarchy of convergence zones over which information is integrated. In shallow models, communication within- and between-modality is accomplished using either direct connectivity, or a central semantic hub. In deep models, modalities are connected via cascading integration sites with successively wider receptive fields. Four experiments provide the first direct behavioral tests of these models using speeded tasks involving feature inference and concept activation. Shallow models predict no within-modal versus cross-modal difference in either task, whereas deep models predict a within-modal advantage for feature inference, but a cross-modal advantage for concept activation. Experiments 1 and 2 used relatedness judgments to tap participants' knowledge of relations for within- and cross-modal feature pairs. Experiments 3 and 4 used a dual-feature verification task. The pattern of decision latencies across Experiments 1-4 is consistent with a deep integration hierarchy.},
}
@article{grabowski_premotor_1998-1,
	abstract = {It has been shown that the retrieval of words denoting visually presented concrete entities engages neural systems in the left temporal lobe and that the precise pattern of activation within the temporal lobe depends in part on the conceptual category to which the entity belongs. Here, we used [{15O]water} positron emission tomography to test the hypothesis that the pattern of activation associated with word retrieval in left frontal lobe would also be related to conceptual category. The design entailed the performance of three tasks requiring the retrieval of words denoting animals, tools, and unique persons. The visual stimuli were presented at different rates, to produce equal performance success across categories, a feature which also had the effect of equalizing the proportion of scan time spent in mental search. All three word retrieval tasks activated the left inferior frontal gyrus, but they differed in their recruitment of two other premotor and prefrontal areas. Activity in a portion of the middle frontal gyrus, corresponding to Brodmann area 46, bore a linear relation to response latency and may index the extent of mental search. This region was most active when subjects named persons. Activity in the anterior bank of the precentral gyrus, along the inferior and middle frontal gyri, was most marked for naming tools. This region overlaps the area activated when subjects generate words for actions. We suggest that it is engaged by the retrieval of words denoting actions or objects with characteristic actions. The data presented here provide additional support for the notion that ``nonclassical'' language areas in extrasylvian frontal and temporal regions mediate word retrieval and that the pattern of their engagement relates to conceptual category.},
}
@article{tranel_further_2008,
	abstract = {The neural underpinnings of conceptual knowledge have been studied intensively, but many unanswered questions remain. In a previous study examining recognition of persons, animals, and tools in 116 participants with unilateral brain lesions, we found no instance of a patient who manifested defective recognition in all three categories. We reasoned that the spatial distribution of the lesion loci critical for the appearance of recognition defects for these different categories explained why this 'three-way' defect could not be found in patients with unilateral lesions, and we proposed that only a suitable bilateral lesion would be likely to produce such a combined defect. In the study reported here, we tested this hypothesis by investigating recognition performances in 55 participants with bilateral cortical lesions. In support of the hypothesis, nine patients, all of whose lesions included bilateral occipitotemporal and/or temporal cortices, had a three-way recognition impairment (persons, M=18.3\%; animals, M=35.7\%; tools, M=71.3\%; all scores {\textgreater}2 {SDs} below normal). As expected, bilateral lesions to other neural sectors, for example prefrontal cortices, did not lead to recognition impairments. These findings provide further support for the notion that retrieval of knowledge for concrete entities from different conceptual categories depends on partially segregated neural systems, located in different sectors of occipitotemporal and temporal regions in right and left hemisphere.},
}
@article{postle_repetitive_2006,
	abstract = {Understanding the contributions of the prefrontal cortex ({PFC)} to working memory is central to understanding the neural bases of high-level cognition. One question that remains controversial is whether the same areas of the dorsolateral {PFC} ({dlPFC)} that participate in the manipulation of information in working memory also contribute to its short-term retention ({STR).} We evaluated this question by first identifying, with functional magnetic resonance imaging ({fMRI)}, brain areas involved in manipulation. Next, these areas were targeted with repetitive transcranial magnetic stimulation ({rTMS)} while subjects performed tasks requiring only the {STR} or the {STR} plus manipulation of information in working memory. {fMRI} indicated that manipulation-related activity was independent of retention-related activity in both the {PFC} and superior parietal lobule ({SPL).} {rTMS}, however, yielded a different pattern of results. Although {rTMS} of the {dlPFC} selectively disrupted manipulation, {rTMS} of the {SPL} disrupted manipulation and {STR} to the same extent. {rTMS} of the postcentral gyrus (a control region) had no effect on performance. The implications of these results are twofold. In the {PFC}, they are consistent with the view that this region contributes more importantly to the control of information in working memory than to its {STR.} In the {SPL}, they illustrate the importance of supplementing the fundamentally correlational data from neuroimaging with a disruptive method, which affords stronger inference about structure-function relations.},
}
@article{mahon_spatial_2013,
	abstract = {It is widely argued that the ability to recognize and identify manipulable objects depends on the retrieval and simulation of action-based information associated with using those objects. Evidence for that view comes from {fMRI} studies that have reported differential {BOLD} contrast in dorsal visual stream regions when participants view manipulable objects compared with a range of baseline categories. An alternative interpretation is that processes internal to the ventral visual pathway are sufficient to support the visual identification of manipulable objects and that the retrieval of object-associated use information is contingent on analysis of the visual input by the ventral stream. Here, we sought to distinguish these two perspectives by exploiting the fact that the dorsal stream is largely driven by magnocellular input, which is biased toward low spatial frequency visual information. Thus, any tool-selective responses in parietal cortex that are driven by high spatial frequencies would be indicative of inputs from the ventral visual pathway. Participants viewed images of tools and animals containing only low, or only high, spatial frequencies during {fMRI.} We find an internal parcellation of left parietal ``tool-preferring'' voxels: Inferior aspects of left parietal cortex are driven by high spatial frequency information and have privileged connectivity with ventral stream regions that show similar category preferences, whereas superior regions are driven by low spatial frequency information. Our findings suggest that the automatic activation of complex object-associated manipulation knowledge is contingent on analysis of the visual input by the ventral visual pathway.},
}
@incollection{dozois_cognitive_2008,
}
@article{okane_evidence_2004,
	abstract = {Until recently, it seemed unlikely that any semantic knowledge could be acquired following extensive bilateral damage to the medial temporal lobes ({MTL).} Although recent studies have demonstrated some semantic learning in amnesic patients, questions remain regarding the limits of this capacity and the extent to which it relies on those patients' residual {MTL} function. The present study examined whether detailed, semantic memory could be acquired by a patient with no functioning hippocampus. We used cued recall and forced-choice recognition tasks to investigate whether the patient {H.M.} had acquired knowledge of people who became famous after the onset of his amnesia. Results revealed that, with first names provided as cues, he was able to recall the corresponding famous last name for 12 of 35 postoperatively famous personalities. This number nearly doubled when semantic cues were added, suggesting that his knowledge of the names was not limited to perceptual information, but was incorporated in a semantic network capable of supporting explicit recall. In forced-choice recognition, {H.M.} discriminated 87\% of postmorbid famous names from foils. Critically, he was able to provide uniquely identifying semantic facts for one-third of these recognized names, describing John Glenn, for example, as ``the first rocketeer'' and Lee Harvey Oswald as a man who ``assassinated the president.'' Although {H.M.'s} semantic learning was clearly impaired, the results provide robust, unambiguous evidence that some new semantic learning can be supported by structures beyond the hippocampus proper. \copywrite 2004 Wiley-Liss, Inc.},
}
@article{martin_neuropsychological_2003,
}
@article{esser_breakdown_2009,
	abstract = {Effective connectivity between cortical areas decreases during slow wave sleep. This decline can be observed in the reduced interareal propagation of activity evoked either directly in cortex by transcranial magnetic stimulation ({TMS)} or by sensory stimulation. We present here a large-scale model of the thalamocortical system that is capable of reproducing these experimental observations. This model was constructed according to a large number of physiological and anatomical constraints and includes over 30,000 spiking neurons interconnected by more than 5 million synaptic connections and organized into three cortical areas. By simulating the different effects of arousal promoting neuromodulators, the model can produce a waking or a slow wave sleep-like mode. In this work, we also seek to explain why intercortical signal transmission decreases in slow wave sleep. The traditional explanation for reduced brain responses during this state, a thalamic gate, cannot account for the reduced propagation between cortical areas. Therefore we propose that a cortical gate is responsible for this diminished intercortical propagation. We used our model to test three candidate mechanisms that might produce a cortical gate during slow wave sleep: a propensity to enter a local down state following perturbation, which blocks the propagation of activity to other areas, increases in potassium channel conductance that reduce neuronal responsiveness, and a shift in the balance of synaptic excitation and inhibition toward inhibition, which decreases network responses to perturbation. Of these mechanisms, we find that only a shift in the balance of synaptic excitation and inhibition can account for the observed in vivo response to direct cortical perturbation as well as many features of spontaneous sleep.},
}
@article{noppeney_action_2005,
	abstract = {The sensory--action theory proposes that the neural substrates underlying action representations are related to a visuomotor action system encompassing the left ventral premotor cortex, the anterior intraparietal ({AIP)} and left posterior middle temporal gyrus ({LPMT).} Using {fMRI}, we demonstrate that semantic decisions on action, relative to non-action words, increased activation in the left {AIP} and {LPMT} irrespective of whether the words were presented in a written or spoken form. Left {AIP} and {LPMT} might thus play the role of amodal semantic regions that can be activated via auditory as well as visual input. Left {AIP} and {LPMT} did not distinguish between different types of actions such as hand actions and whole body movements, although a right {STS} region responded selectively to whole body movements.},
}
@article{roberson_color_2007,
	abstract = {An intriguing new study with Russian and English participants has provided compelling support for the view that 'categorical perception' of color categories is verbally mediated and varies with culture and language.},
}
@article{zabelina_suppressed_????,
	abstract = {The present study investigated the limits of semantic processing without awareness, during continuous flash suppression ({CFS).} We used compound remote associate word problems, in which three seemingly unrelated words (e.g., pine, crab, sauce) form a common compound with a single solution word (e.g., apple). During the first 3 s of each trial, the three problem words or three irrelevant words (control condition) were suppressed from awareness, using {CFS.} The words then became visible, and participants attempted to solve the word problem. Once the participants solved the problem, they indicated whether they had solved it by insight or analytically. Overall, the compound remote associate word problems were solved significantly faster after the problem words, as compared with irrelevant words, were presented during the suppression period. However this facilitation occurred only when people solved with analysis, not with insight. These results demonstrate that semantic processing, but not necessarily semantic integration, may occur without awareness.},
}
@article{decety_neural_1999,
	abstract = {Our ability to generate actions and to recognize actions performed by others is the bedrock of our social life. Behavioral evidence suggests that the processes underlying perception and action might share a common representational framework. That is, observers might understand the actions of another individual in terms of the same neural code that they use to produce the same actions themselves. What neurophysiological evidence, if any, supports such a hypothesis? In this article, brain imaging studies addressing this question are reviewed and examined in the light of the functional segregation of the perceptual mechanisms subtending visual recognition and those used for action. We suggest that there are not yet conclusive arguments for a clear neurophysiological substrate supporting a common coding between perception and action.},
}
@article{wnuczko_when_2012-5,
	abstract = {Objectives. Recent research suggests that inhibition at early stages of visual processing may be age invariant. We test this proposal using a priming of pop-out ({PoP)} measure developed by Lamy, Antebi, Aviani, and Carmel (2008. Priming of pop-out provides reliable measures of target activation and distractor inhibition in selective attention. Vision Research, 48, 30--41. doi:10.1016/j.visres.2007.10.009). In {PoP}, a unique item, which visually ``pops-out'' in a field of distractors, grabs our attention faster when its defining feature (e.g., color red) repeats across trials and slower when distractor- and target-defining features switch between trials. Here, we explore whether the processes underlying {PoP}, which prevent access to distractors and facilitate access to the singleton, remain intact with age.
}
@article{casey_modeling_2012,
	abstract = {A long standing debate in cognitive neuroscience has been the extent to which perceptual processing is influenced by prior knowledge and experience with a task. A converging body of evidence now supports the view that a task does influence perceptual processing, leaving us with the challenge of understanding the locus of, and mechanisms underpinning, these influences. An exemplar of this influence is learned categorical perception ({CP)}, in which there is superior perceptual discrimination of stimuli that are placed in different categories. Psychophysical experiments on humans have attempted to determine whether early cortical stages of visual analysis change as a result of learning a categorization task. However, while some results indicate that changes in visual analysis occur, the extent to which earlier stages of processing are changed is still unclear. To explore this issue, we develop a biologically motivated neural model of hierarchical vision processes consisting of a number of interconnected modules representing key stages of visual analysis, with each module learning to exhibit desired local properties through competition. With this system level model, we evaluate whether a {CP} effect can be generated with task influence to only the later stages of visual analysis. Our model demonstrates that task learning in just the later stages is sufficient for the model to exhibit the {CP} effect, demonstrating the existence of a mechanism that requires only a high-level of task influence. However, the effect generalizes more widely than is found with human participants, suggesting that changes to earlier stages of analysis may also be involved in the human {CP} effect, even if these are not fundamental to the development of {CP.} The model prompts a hybrid account of task-based influences on perception that involves both modifications to the use of the outputs from early perceptual analysis along with the possibility of changes to the nature of that early analysis itself.},
}
@article{whitehouse_adult_2009,
}
@article{rayner_lexical_1986,
}
@article{lupyan_making_2010,
}
@book{steriade_brainstem_2005,
}
@article{walker_practice_2002,
	abstract = {Improvement in motor skill performance is known to continue for at least 24 hr following training, yet the relative contributions of time spent awake and asleep are unknown. Here we provide evidence that a night of sleep results in a 20\% increase in motor speed without loss of accuracy, while an equivalent period of time during wake provides no significant benefit. Furthermore, a significant correlation exists between the improved performance overnight and the amount of stage 2 {NREM} sleep, particularly late in the night. This finding of sleep-dependent motor skill improvement may have important implications for the efficient learning of all skilled actions in humans.},
}
@article{friston_modules_2011,
}
@article{hsu_chromaticity_2012,
	abstract = {Sensorimotor theories of semantic memory require overlap between conceptual and perceptual representations. One source of evidence for such overlap comes from neuroimaging reports of co-activation during memory retrieval and perception; for example, regions involved in color perception (i.e., regions that respond more to colored than grayscale stimuli) are activated by retrieval of object color. One unanswered question from these studies is whether distinctions that are observed during perception are likewise observed during memory retrieval. That is, are regions defined by a chromaticity effect in perception similarly modulated by the chromaticity of remembered objects (e.g., lemons more than coal)? Subjects performed color perception and color retrieval tasks while undergoing {fMRI.} We observed increased activation during both perception and memory retrieval of chromatic compared to achromatic stimuli in overlapping areas of the left lingual gyrus, but not in dorsal or anterior regions activated during color perception. These results support sensorimotor theories but suggest important distinctions within the conceptual system.},
}
@article{wee_group-constrained_2014,
	abstract = {Emergence of advanced network analysis techniques utilizing resting-state functional magnetic resonance imaging (R-{fMRI)} has enabled a more comprehensive understanding of neurological disorders at a whole-brain level. However, inferring brain connectivity from R-{fMRI} is a challenging task, particularly when the ultimate goal is to achieve good control--patient classification performance, owing to perplexing noise effects, curse of dimensionality, and inter-subject variability. Incorporating sparsity into connectivity modeling may be a possible solution to partially remedy this problem since most biological networks are intrinsically sparse. Nevertheless, sparsity constraint, when applied at an individual level, will inevitably cause inter-subject variability and hence degrade classification performance. To this end, we formulate the R-{fMRI} time series of each region of interest ({ROI)} as a linear representation of time series of other {ROIs} to infer sparse connectivity networks that are topologically identical across individuals. This formulation allows simultaneous selection of a common set of {ROIs} across subjects so that their linear combination is best in estimating the time series of the considered {ROI.} Specifically, l 1-norm is imposed on each subject to filter out spurious or insignificant connections to produce sparse networks. A group-constraint is hence imposed via multi-task learning using a l 2-norm to encourage consistent non-zero connections across subjects. This group-constraint is crucial since the network topology is identical for all subjects while still preserving individual information via different connectivity values. We validated the proposed modeling in mild cognitive impairment identification and promising results achieved demonstrate its superiority in disease characterization, particularly greater sensitivity to early stage brain pathologies. The inferred group-constrained sparse network is found to be biologically plausible and is highly associated with the disease-associated anatomical anomalies. Furthermore, our proposed approach achieved similar classification performance when finer atlas was used to parcellate the brain space.},
}
@article{perani_word_1999,
	abstract = {We report two positron emission tomography ({PET)} studies of cerebral activation during picture and word matching tasks, in which we compared directly the processing of stimuli belonging to different semantic categories (animate and inanimate) in the visual (pictures) and verbal (words) modality. In the first experiment, brain activation was measured in eleven healthy adults during a same/different matching task for textures, meaningless shapes and pictures of animals and artefacts (tools). Activations for meaningless shapes when compared to visual texture discrimination were localized in the left occipital and inferior temporal cortex. Animal picture identification, either in the comparison with meaningless shapes and in the direct comparison with non-living pictures, involved primarily activation of occipital regions, namely the lingual gyrus bilaterally and the left fusiform gyrus. For artefact picture identification, in the same comparison with meaningless shape-baseline and in the direct comparison with living pictures, all activations were left hemispheric, through the dorsolateral frontal (Ba 44/6 and 45) and temporal (Ba 21, 20) cortex. In the second experiment, brain activation was measured in eight healthy adults during a same/different matching task for visually presented words referring to animals and manipulable objects (tools); the baseline was a pseudoword discrimination task. When compared with the tool condition, the animal condition activated posterior left hemispheric areas, namely the fusiform (Ba 37) and the inferior occipital gyrus (Ba 18). The right superior parietal lobule (Ba 7) and the left thalamus were also activated. The reverse comparison (tools vs animals) showed left hemispheric activations in the middle temporal gyrus (Ba 21) and precuneus (Ba 7), as well as bilateral activation in the occipital regions. These results are compatible with different brain networks subserving the identification of living and non-living entities; in particular, they indicate a crucial role of the left fusiform gyrus in the processing of animate entities and of the left middle temporal gyrus for tools, both from words and pictures. The activation of other areas, such as the dorsolateral frontal cortex, appears to be specific for the semantic access of tools only from pictures.},
}
@article{pobric_category-specific_2010,
	abstract = {Summary
}
@article{fell_role_2011,
	abstract = {In recent years, studies ranging from single-unit recordings in animals to electroencephalography and magnetoencephalography studies in humans have demonstrated the pivotal role of phase synchronization in memory processes. Phase synchronization --- here referring to the synchronization of oscillatory phases between different brain regions --- supports both working memory and long-term memory and acts by facilitating neural communication and by promoting neural plasticity. There is evidence that processes underlying working and long-term memory might interact in the medial temporal lobe. We propose that this is accomplished by neural operations involving phase--phase and phase--amplitude synchronization. A deeper understanding of how phase synchronization supports the flexibility of and interaction between memory systems may yield new insights into the functions of phase synchronization in general.},
}
@article{webb_sleep_1978,
}
@article{davidoff_language_2001,
	abstract = {In a pioneering set of experiments, Rosch investigated the colour processing of a remote traditional culture. It was concluded that colours form universally natural and salient categories. However, our own cross-cultural research, backed up by neuropsychological data and interference studies, indicates that perceptual categories are derived from the words in the speaker's language. The new data support a rather strong version of the Whorfian view that perceptual categories are organized by the linguistic systems of our mind.},
}
@article{schecklmann_reduced_2011,
	abstract = {Altered prefrontal brain activity (e.g. hypofrontality) during cognitive tasks such as working memory is a core neuroimaging marker in unipolar ({UNI)} and bipolar ({BI)} depression. The present study investigated for the first time {UNI} (n=16) and {BI} patients (n=14) in a working memory task including different processes (storage and matching) and components (object and spatial visual) with functional near-infrared spectroscopy ({fNIRS)} over the prefrontal cortex. In healthy controls (n=15) comparable to both patient groups, changes of oxygenated and deoxygenated haemoglobin indicated increased ventro-lateral, dorso-lateral prefrontal and superior frontal cortex activity for object and spatial visual working memory storage as compared to the control condition. In contrast, both patient groups showed diminished brain activity in all working memory conditions. Results revealed unspecific deficits that did not allow the differentiation between unipolar and bipolar depression in dependence of working memory processes or components. However, {fNIRS} can be considered as a valid, easy manageable, low cost and rapid tool for measuring (diminished) prefrontal cortex functions.},
}
@book{von_frisch_bees:_1964,
}
@article{lebowitz_fixable_2013,
	abstract = {Objective: Previous research has shown that biological (e.g., genetic, biochemical) accounts of depression---currently in ascendancy---are linked to the general public's pessimism about the syndrome's prognosis. This research examined for the first time whether people with depressive symptoms would associate biological accounts of depression with pessimism about their own prognoses and whether a psychoeducation intervention portraying the biology of depression as malleable could decrease prognostic pessimism among symptomatic individuals. Method: In 3 studies, participants were recruited online and assessed for depression symptoms. Those with significant depressive symptomatology (a Beck Depression Inventory-{II} score of at least 16) rated their endorsement of biochemical and genetic causal attributions for their symptoms and indicated expected length of symptom duration. An audiovisual intervention emphasizing the malleability of gene effects and neurochemistry was developed, and its effects on symptomatic individuals' prognostic pessimism, feelings of agency, guilt, and general hopelessness were measured. Results: Biochemical and genetic causal attributions for depression were significantly associated with prognostic pessimism among symptomatic individuals. The malleability intervention significantly reduced prognostic pessimism, increased feelings of agency, and decreased general hopelessness. Conclusions: Biochemical and genetic attributions for depression are related to prognostic pessimism among individuals with depressive symptoms, and not just among the general public. However, emphasizing the malleability of gene effects and brain chemistry in depression can foster more optimism about depression-related beliefs. ({PsycINFO} Database Record (c) 2013 {APA}, all rights reserved) (journal abstract)},
}
@article{roberson_color_2005,
	abstract = {The question of whether language affects our categorization of perceptual continua is of particular interest for the domain of color where constraints on categorization have been proposed both within the visual system and in the visual environment. Recent research (Roberson, Davies, \&amp; Davidoff, 2000; Roberson et al., in press) found substantial evidence of cognitive color differences between different language communities, but concerns remained as to how representative might be a tiny, extremely remote community. The present study replicates and extends previous findings using additional paradigms among a larger community in a different visual environment. Adult semi-nomadic tribesmen in Southern Africa carried out similarity judgments, short-term memory and long-term learning tasks. They showed different cognitive organization of color to both English and another language with the five color terms. Moreover, Categorical Perception effects were found to differ even between languages with broadly similar color categories. The results provide further evidence of the tight relationship between language and cognition.},
}
@article{froemke_long-term_2013,
	abstract = {Synapses and receptive fields of the cerebral cortex are plastic. However, changes to specific inputs must be coordinated within neural networks to ensure that excitability and feature selectivity are appropriately configured for perception of the sensory environment. We induced long-lasting enhancements and decrements to excitatory synaptic strength in rat primary auditory cortex by pairing acoustic stimuli with activation of the nucleus basalis neuromodulatory system. Here we report that these synaptic modifications were approximately balanced across individual receptive fields, conserving mean excitation while reducing overall response variability. Decreased response variability should increase detection and recognition of near-threshold or previously imperceptible stimuli. We confirmed both of these hypotheses in behaving animals. Thus, modification of cortical inputs leads to wide-scale synaptic changes, which are related to improved sensory perception and enhanced behavioral performance.},
}
@article{erickson_neurobiology_2003,
	abstract = {Cognitive alterations occur over the lifespan of every species studied and have been quantified carefully in humans, other primates and rodents. Correspondingly, changes in hippocampal function have been associated with a number of observed memory impairments across species. It appears that humans, alone, show Alzheimer's disease-like cognitive and neural pathology spontaneously. Thus, a comparison of normal age-related changes in cognition in other animals can help disambiguate the boundary between normal and pathological states of aging in humans. Another important contribution made from studying aging in non-human species is the ability to examine, in more detail, the basic neural mechanisms that may be responsible for brain aging in these species. So far, most of the functional neurobiological studies have been conducted in the aged rat. We propose that the link between rodent and human work can be made much stronger by combining neurophysiological and behavioral investigation of normal aging in the non-human primate.},
}
@article{squire_cognitive_2011-1,
	abstract = {Work with patient {H.M.}, beginning in the 1950s, established key principles about the organization of memory that inspired decades of experimental work. Since {H.M.}, the study of human memory and its disorders has continued to yield new insights and to improve understanding of the structure and organization of memory. Here we review this work with emphasis on the neuroanatomy of medial temporal lobe and diencephalic structures important for memory, multiple memory systems, visual perception, immediate memory, memory consolidation, the locus of long-term memory storage, the concepts of recollection and familiarity, and the question of how different medial temporal lobe structures may contribute differently to memory functions.},
}
@article{salisbury_semantic_2012,
	abstract = {Information is stored in distributed cortical networks, but it is unclear how distributed stores are synthesized into a unified percept. Activation of local circuits in the gamma range (30 {\textless} {\textless} 80 Hz), and distributed stores in the low theta range (3--5 Hz) may underlie perceptual binding. Words have a crucial role in semantic memory. Within memory, the activation of distributed semantic stores is facilitated by conceptually related previous items, termed semantic priming. We sought to detect event-related brain oscillations ({EROs)} sensitive to semantic activation and priming. Here, we show that low theta evoked power and intertrial phase locking (4--5 Hz) from 250--350 msec over left hemisphere language areas was greater to related than to unrelated words. Theta band event-related oscillations over left hemisphere language areas may provide a brain signature for semantic activation across distributed stores being facilitated by semantic priming.},
}
@article{segal_appraisal_1988,
}
@article{shimaoka_dynamical_2011,
	abstract = {Continuous Flash Suppression ({CFS)} is a technique in which a stationary image in one eye can be reliably suppressed by rapid presentation of different flashing images in the other. In this paper we address why flashing stimuli modulate the visibility of the stimuli. We determine, in particular, which type of neural network is sufficient for the modulation of the dominance duration, assuming that elemental units are endowed with reciprocal inhibition and adaptation. We show that the model introduced by Wilson (2007) reproduces flash suppression, which is considered to be involved in {CFS}, but does not reproduce {CFS.} We then extend the model by including a stimulus feature dimension. With this extension, we found that the model accounts for the modulation of visibility observed in {CFS.} In addition, this model captured some defining characteristics of {CFS} such as dependence on flash interval and the depth of suppression. Our findings suggest that a network with inhibition and adaptation including feature dimension provides a crucial mechanism for the modulation of the dominance duration in {CFS.}},
}
@article{massimini_cortical_2010,
	abstract = {We recorded the electroencephalographic ({EEG)} responses evoked by transcranial magnetic stimulation ({TMS)} during the first rapid eye movement ({REM)} sleep episode of the night and we compared them with the responses obtained during previous wakefulness and {NREM} sleep. Confirming previous findings, upon falling into {NREM} sleep, cortical activations became more local and stereotypical, indicating a significant impairment of the intracortical dialogue. During {REM} sleep, a state in which subjects regain consciousness but are almost paralyzed, {TMS} triggered more widespread and differentiated patterns of cortical activation, that were similar to the ones observed in wakefulness. Similarly, {TMS/hd-EEG} may be used to probe the internal dialogue of the thalamocortical system in brain injured patients that are unable to move and communicate.},
}
@article{kellenbach_actions_2003,
	abstract = {{PET} was used to investigate the neural correlates of action knowledge in object representations, particularly the left lateralized network of activations previously implicated in the processing of tools and their associated actions: ventral premotor cortex ({VPMCx)}, posterior middle temporal gyrus ({PMTG)}, and intraparietal sulcus ({IPS).} Judgments were made about the actions and functions associated with manipulable man-made objects (e.g., hammer); this enabled us to measure activations in response to both explicit and implicit retrieval of knowledge about actions associated with manipulable tools. Function judgments were also made about nonmanipulable artifacts (e.g., traffic light) providing a direct comparison for manipulable objects. Although neither the left {VPMCx} nor the left {PMTG} were selective for tool stimuli (nonmanipulable objects also activated these areas relative to a visual control condition), both regions responded more strongly to manipulable objects, suggesting a role for these cortical areas in the processing of knowledge associated with tools. Furthermore, these activations were insensitive to retrieval task, suggesting that visually presented tools automatically recruit both left {VPMCx} and left {PMTG} in response to action features that are inherent in tool representations. In contrast, the {IPS} showed clear selectivity for explicit retrieval of action information about manipulable objects. No regions of cortex were more activated by function relative to action judgments about artifacts. These results are consistent with the brain's preferential responsiveness to how we interact with objects, rather than what they are used for.},
}
@article{wilson_mrc_1988,
	abstract = {The {MRC} machine-usable dictionary contains 150,837 words and up 26 linguistic and psycholinguistic attributes for each. The attributes are from sources that are publicly available but are difficult to obtain and structure into a single dictionary. Three utility programs are described that permit the selection of words defined by a set of specified attribute values and the selection of attribute values for a set of specified words. These programs permit the construction of word sets for psycholinguistic experiments that control for the attributes specified in the dictionary. The dictionary may also be of use to researchers in artificial intelligence and computer science who require psychological and linguistic descriptions of words.},
}
@article{price_meta-analyses_2005,
	abstract = {The neural systems sustaining object naming were examined using the activation likelihood estimation ({ALE)} meta-analysis approach on the results of 16 previously published studies. The activation task in each study required subjects to name pictures of objects or animals, but the baseline tasks varied. Separate meta-analyses were carried out on studies that used: (1) high-level baselines to control for speech processing and visual input; and (2) low-level baselines that did not control for speech or complex visual processing. The results of the two meta-analyses were then compared directly, revealing a double dissociation in the activation pattern for studies using high and low baselines. To interpret the differential activations, we report two new functional imaging experiments. The aim of the first was to characterize activation differences associated with visual stimuli that are typically used in baseline conditions (complex visual features, simple structures, or fixation). The aim of the second was to classify object-naming regions in terms of whether they were engaged preferentially by semantic or phonological processes. The results reveal a remarkably precise correspondence between the areas identified by the meta-analyses as affected differentially by baseline and the areas that are affected differentially by non-object structure, semantics or phonology. As expected, high-level baselines reduced object-naming activation in areas associated with the processing of complex visual features and speech production. In addition, high-level baselines increased sensitivity to activation in areas associated with semantic processing, visual-speech integration and response selection. For example, activation in the anterior temporal areas that neuropsychological studies have associated with semantic processing was more strongly activated in the context of high-level baselines. These results therefore have implications for understanding the convergence of functional imaging and neuropsychological findings. Hum Brain Mapp 25:70--82, 2005. \copywrite 2005 Wiley-Liss, Inc.},
}
@article{oberman_face_2007,
	abstract = {Abstract People spontaneously mimic a variety of behaviors, including emotional facial expressions. Embodied cognition theories suggest that mimicry reflects internal simulation of perceived emotion in order to facilitate its understanding. If so, blocking facial mimicry should impair recognition of expressions, especially of emotions that are simulated using facial musculature. The current research tested this hypothesis using four expressions (happy, disgust, fear, and sad) and two mimicry-interfering manipulations (1) biting on a pen and (2) chewing gum, as well as two control conditions. Experiment 1 used electromyography over cheek, mouth, and nose regions. The bite manipulation consistently activated assessed muscles, whereas the chew manipulation activated muscles only intermittently. Further, expressing happiness generated most facial action. Experiment 2 found that the bite manipulation interfered most with recognition of happiness. These findings suggest that facial mimicry differentially contributes to recognition of specific facial expressions, thus allowing for more refined predictions from embodied cognition theories.},
}
@article{formisano_mirror-symmetric_2003,
	abstract = {Understanding the functional organization of the human primary auditory cortex ({PAC)} is an essential step in elucidating the neural mechanisms underlying the perception of sound, including speech and music. Based on invasive research in animals, it is believed that neurons in human {PAC} that respond selectively with respect to the spectral content of a sound form one or more maps in which neighboring patches on the cortical surface respond to similar frequencies (tonotopic maps). The number and the cortical layout of such tonotopic maps in the human brain, however, remain unknown. Here we use silent, event-related functional magnetic resonance imaging at 7 Tesla and a cortex-based analysis of functional data to delineate with high spatial resolution the detailed topography of two tonotopic maps in two adjacent subdivisions of {PAC.} These maps share a low-frequency border, are mirror symmetric, and clearly resemble those of presumably homologous fields in the macaque monkey.},
}
@article{lambon_ralph_neural_2007,
}
@article{buxbaum_role_1997,
	abstract = {Does semantic knowledge of objects mediate object selection and use? We present data from two patients that speak to this question. The first, {DM}, is a semantic dementia patient previously reported by Breedin, Saffran, and Coslett (1994) who, despite moderate to severe loss of functional and associative object knowledge, was nevertheless able to perform almost normally on single-object use and on more complex tests of naturalistic action. The second, {HB}, is a dementia patient who exhibited an executive disorder but performed as well as controls on a detailed battery of semantic memory and single-object use tests. Unlike {DM}, he made numerous errors on the naturalistic action tests, among which were errors of object selection and usage. Taken together, these data suggestthatintactsemantic memory forobjects is neithernecessary norsufficient to ensure good object utilisation in naturalistic action. The data cannot be accommodated by accounts postulating that action with objects is performed exclusively via nonsemantic or visual semantic routes, but are most consistent with an account in which nonsemantic information augments deficient functional/associational semantic elements in an action-oriented network.},
}
@article{riddoch_tale_2008,
	abstract = {The performance of two patients with visual agnosia was compared across a number of tests examining visual processing. The patients were distinguished by having dorsal and medial ventral extrastriate lesions. While inanimate objects were disadvantaged for the patient with a dorsal extrastriate lesion, animate items are disadvantaged for the patient with the medial ventral extrastriate lesion. The patients also showed contrasting patterns of performance on the Navon Test: The patient with a dorsal extrastriate lesion demonstrated a local bias while the patient with a medial ventral extrastriate lesion had a global bias. We propose that the dorsal and medial ventral visual pathways may be characterized at an extrastriate level by differences in local relative to more global visual processing and that this can link to visually based category-specific deficits in processing.},
}
@article{pulvermuller_meaning_2012,
	abstract = {Which types of nerve cell circuits enable humans to use and understand meaningful signs and words? Philosophers were the first to point out that the arbitrary links between signs and their meanings differ fundamentally between semantic word types. Neuroscience provided evidence that semantic kinds do indeed matter: Brain diseases affect specific semantic categories and leave others relatively intact. Patterns of precisely timed brain activation in specific areas of cortex reflect the comprehension of words with specific semantic features. The classic referential link between words and the objects they are used to speak about can be understood as a result of associative learning driven by correlated neuronal activity in perisylvian language areas and sensory, especially higher visual but also olfactory, somatosensory and auditory, areas. However, the meaning of words used to speak about actions calls for a different account. For learning their meaning, specific action and interaction contexts are critical, and neuronal links between language and action systems of the human brain likely store such action-semantic information. In fact, after learning, the action system is sparked when such words and utterances are being used or understood, and, correspondingly, functional changes in the brain's motor system influence the recognition of action-related expressions. These results show that language is ``woven into action'' at the level of the brain. Word-object, word--action and word-word contexts are discussed in view of further facets of semantics and their brain basis, including emotional-affective, abstract and combinatorial aspects of meaning. All of these aspects and corresponding neuronal circuit types interact in the processing of the meaning of words and sentences in the human mind and brain.},
}
@article{bahrami_attentional_2007,
	abstract = {Visual neuroscience has long sought to determine the extent to which stimulus-evoked activity in visual cortex depends on attention and awareness. Some influential theories of consciousness maintain that the allocation of attention is restricted to conscious representations . However, in the load theory of attention , competition between task-relevant and task-irrelevant stimuli for limited-capacity attention does not depend on conscious perception of the irrelevant stimuli. The critical test is whether the level of attentional load in a relevant task would determine unconscious neural processing of invisible stimuli. Human participants were scanned with high-field {fMRI} while they performed a foveal task of low or high attentional load. Irrelevant, invisible monocular stimuli were simultaneously presented peripherally and were continuously suppressed by a flashing mask in the other eye . Attentional load in the foveal task strongly modulated retinotopic activity evoked in primary visual cortex (V1) by the invisible stimuli. Contrary to traditional views , we found that availability of attentional capacity determines neural representations related to unconscious processing of continuously suppressed stimuli in human primary visual cortex. Spillover of attention to cortical representations of invisible stimuli (under low load) cannot be a sufficient condition for their awareness.},
}
@article{fagot_cross-species_2006,
	abstract = {Berlin and Kay (1969) found systematic restrictions in the color terms of the world's languages and were inclined to look to the primate visual system for their origin. Because the visual system does not provide adequate neurophysiological discontinuities to supply natural color category boundaries, and because recent evidence points to a linguistic origin (Davidoff, Davies, \& Roberson, 1999), a new approach was used to investigate the controversial issue of the origin of color categories. Baboons and humans were given the same task of matching-to-sample colors that crossed the blue/green boundary. The data and consequent modeling were remarkably clear-cut. All human subjects matched our generalization probe stimuli as if to a sharp boundary close to the midpoint between their training items. Despite good color discrimination, none of the baboons showed any inclination to match to a single boundary but rather responded with two boundaries close to the training stimuli. The data give no support to the claim that color categories are explicitly instantiated in the primate color vision system.},
}
@incollection{cohen_cognitive_1980,
}
@article{tononi_information_2010,
	abstract = {A proper understanding of cognitive functions cannot be achieved without an understanding of consciousness, both at the empirical and at the theoretical level. This paper argues that consciousness has to do with a system's capacity for information integration. In this approach, every causal mechanism capable of choosing among alternatives generates information, and information is integrated to the extent that it is generated by a system above and beyond its parts. The set of integrated informational relationships generated by a complex of mechanisms--its quale--specify both the quantity and the quality of experience. As argued below, depending on the causal structure of a system, information integration can reach a maximum value at a particular spatial and temporal grain size. It is also argued that changes in information integration reflect a system's ability to match the causal structure of the world, both on the input and the output side. After a brief review suggesting that this approach is consistent with several experimental and clinical observations, the paper concludes with some prospective remarks about the relevance of understanding information integration for analyzing cognitive function, both normal and pathological.},
}
@article{moran_neural_1987,
	abstract = {Temporopolar cortex ({TP)} can be subdivided into agranular, dysgranular, and granular components. The telencephalic input into the temporopolar cortex arises from the orbitofrontal and medial frontal regions, modality-specific visual and auditory association areas, paralimbic regions, the piriform olfactory cortex, the hippocampus, the amygdala, the claustrum, and the basal forebrain. Afferents from limbic and paralimbic regions are directed mostly to the agranular and dysgranular sectors of the temporal pole, whereas afferents from isocortical association areas are distributed predominantly within the granular sector. The temporopolar cortex provides a site for the potential convergence of sensory and limbic inputs. Auditory inputs predominate in the dorsolateral part of the temporopolar cortex whereas visual inputs become prominent only in the ventral portions of this region. Olfactory inputs are directed mostly to the medial parts of the temporal pole. These medial parts also receive more extensive projections from the amygdaloid nuclei.},
}
@article{siegel_rem_2001,
	abstract = {It has been hypothesized that {REM} (rapid eye movement) sleep has an important role in memory consolidation. The evidence for this hypothesis is reviewed and found to be weak and contradictory. Animal studies correlating changes in {REM} sleep parameters with learning have produced inconsistent results and are confounded by stress effects. Humans with pharmacological and brain lesion--induced suppression of {REM} sleep do not show memory deficits, and other human sleep-learning studies have not produced consistent results. The time spent in {REM} sleep is not correlated with learning ability across humans, nor is there a positive relation between {REM} sleep time or intensity and encephalization across species. Although sleep is clearly important for optimum acquisition and performance of learned tasks, a major role in memory consolidation is unproven.},
}
@article{joseph_fmri_2006,
	abstract = {The present study used functional magnetic resonance imaging to examine cortical specialization for letter processing. We assessed whether brain regions that were involved in letter processing exhibited domain-specific and/or mandatory responses, following Fodor's definition of properties of modular systems (Fodor, {J.A.}, 1983. The Modularity of Mind. The {MIT} Press, Cambridge, {MA.).} Domain-specificity was operationalized as selective, or exclusive, activation for letters relative to object and visual noise processing and a baseline fixation task. Mandatory processing was operationalized as selective activation for letters during both a silent naming and a perceptual matching task. In addition to these operational definitions, other operational definitions of selectivity for letter processing discussed by [Pernet, C., Celsis, P., Demonet, J., 2005. Selective response to letter categorization within the left fusiform gyrus. {NeuroImage} 28, 738-744] were applied to the data. Although the left fusiform gyrus showed a specialized response to letters using the definition of selectivity put forth by [Pernet, C., Celsis, P., Demonet, J., 2005. Selective response to letter categorization within the left fusiform gyrus. {NeuroImage} 28, 738-744], this region did not exhibit specialization for letters according to our more conservative definition of selectivity. Instead, this region showed equivalent activation by letters and objects in both the naming and matching tasks. Hence, the left fusiform gyrus does not exhibit domain-specific or mandatory processing but may reflect a shared input system for both stimulus types. The left insula and some portions of the left inferior parietal lobule, however, did show a domain-specific response for letter naming but not for letter matching. These regions likely subserve some linguistically oriented cognitive process that is unique to letters, such as grapheme-to-phoneme translation or retrieval of phonological codes for letter names. Hence, cortical specialization for letters emerged in the naming task in some peri-sylvian language related cortices, but not in occipito-temporal cortex. Given that the domain-specific response for letters in left peri-sylvian regions was only present in the naming task, these regions do not process letters in a mandatory fashion, but are instead modulated by the linguistic nature of the task.},
}
@article{cox_afni:_1996,
	abstract = {A package of computer programs for analysis and visualization of three-dimensional human brain functional magnetic resonance imaging ({FMRI)} results is described. The software can color overlay neural activation maps onto higher resolution anatomical scans. Slices in each cardinal plane can be viewed simultaneously. Manual placement of markers on anatomical landmarks allows transformation of anatomical and functional scans into stereotaxic (Talairach-Tournoux) coordinates. The techniques for automatically generating transformed functional data sets from manually labeled anatomical data sets are described. Facilities are provided for several types of statistical analyses of multiple {3D} functional data sets. The programs are written in {ANSI} C and Motif 1.2 to run on Unix workstations.},
}
@article{azuma_why_1997,
	abstract = {Past lexical decision studies investigating the number of meanings ({NOM)} effect have produced mixed results. A second variable, the relatedness among a word's meanings, has not been widely studied. In Experiment 1, Relatedness (High or Low), {NOM} (Many or Few), and nonword condition (legal nonwords or pseudohomophones) were manipulated in lexical decision. No significant effects of {NOM} or Relatedness were observed in the legal nonword condition. However, in the pseudohomophone condition, Relatedness and {NOM} both produced significant main effects, and an interaction. Words with few, unrelated meanings produced the slowest response times ({RTs);} all other words produced statistically equivalent {RTs.} Results of the pseudohomophone condition of Experiment 1 were replicated in Experiment 2, except the main effect of {NOM} was not significant. The overall unreliability of {NOM} effects in these (and previous) experiments lead us to question the contribution of {NOM} to the observed interaction. {NOM} metrics are often confounded with relatedness; words with many meanings tend to have highly related meanings. The results show that relatedness among meanings can influence lexical decision performance; the challenge is now to explore alternative measures, other than simple enumeration, to adequately describe word meanings.},
}
@article{kourtzi_activation_2000,
	abstract = {A still photograph of an object in motion may convey dynamic information about the position of the object immediately before and after the photograph was taken (implied motion). Medial temporal/medial superior temporal cortex ({MT/MST)} is one of the main brain regions engaged in the perceptual analysis of visual motion. In two experiments we examined whether {MT/MST} is also involved in representing implied motion from static images. We found stronger functional magnetic resonance imaging ({fMRI)} activation within {MT/MST} during viewing of static photographs with implied motion compared to viewing of photographs without implied motion. These results suggest that brain regions involved in the visual analysis of motion are also engaged in processing implied dynamic information from static images.},
}
@article{ekstrom_how_2010,
	abstract = {Functional magnetic resonance imaging ({fMRI)} has become the dominant means of measuring behavior-related neural activity in the human brain. Yet the relation between the blood oxygen-level dependent ({BOLD)} signal and underlying neural activity remains an open and actively researched question. A widely accepted model, established for sensory neo-cortex, suggests that the {BOLD} signal reflects peri-synaptic activity in the form of the local field potential rather than the spiking rate of individual neurons. Several recent experimental results, however, suggest situations in which {BOLD}, spiking, and the local field potential dissociate. Two different models are discussed, based on the literature reviewed to account for this dissociation, a circuitry-based and vascular-based explanation. Both models are found to account for existing data under some testing situations and in certain brain regions. Because both the vascular and local circuitry-based explanations challenge the {BOLD-LFP} coupling model, these models provide guidance in predicting when {BOLD} can be expected to reflect neural processing and when the underlying relation with {BOLD} may be more complex than a direct correspondence.},
}
@article{filliter_manipulability_2005,
	abstract = {Object naming studies have generally observed that both normal and brain damaged individuals are faster and more accurate at identifying non-living objects than living objects (Humphreys, Riddoch, \&amp; Quinlan, 1988; Warrington \&amp; Shallice, 1984). However, a potential confounding variable, manipulability, has been present in past studies that may mediate this effect. Previous studies that have observed a non-living advantage have often used manipulable and non-manipulable exemplars to represent the non-living and living groups, respectively. Under conditions which controlled for object manipulability and familiarity, results demonstrated advantages for the identification of non-manipulable and for living objects.},
}
@article{matsuki_event-based_2011,
	abstract = {In some theories of sentence comprehension, linguistically-relevant lexical knowledge such as selectional restrictions is privileged in terms of the time-course of its access and influence. We examined whether event knowledge computed by combining multiple concepts can rapidly influence language understanding even in the absence of selectional restriction violations. Specifically, we investigated whether instruments can combine with actions to influence comprehension of ensuing patients. Instrument-verb-patient triplets were created in a norming study designed to tap directly into event knowledge. In self-paced reading (Experiment 1), participants were faster to read patient nouns such as hair when they were typical of the instrument-action pair (Donna used the shampoo to wash vs. the hose to wash). Experiment 2 showed that these results were not due to direct instrument-patient relations. Experiment 3 replicated Experiment 1 using eyetracking, with effects of event typicality observed in first fixation and gaze durations on the patient noun. This research demonstrates that conceptual event-based expectations are computed and used rapidly and dynamically during on-line language comprehension. We discuss relationships among plausibility and predictability, as well as their implications. We conclude that selectional restrictions may be best considered as event-based conceptual knowledge, rather than lexical-grammatical knowledge.},
}
@article{gibson_noisy-channel_2013-1,
	abstract = {The distribution of word orders across languages is highly nonuniform, with subject-verb-object ({SVO)} and subject-object-verb ({SOV)} orders being prevalent. Recent work suggests that the {SOV} order may be the default in human language. Why, then, is {SVO} order so common? We hypothesize that {SOV/SVO} variation can be explained by language users' sensitivity to the possibility of noise corrupting the linguistic signal. In particular, the noisy-channel hypothesis predicts a shift from the default {SOV} order to {SVO} order for semantically reversible events, for which potential ambiguity arises in {SOV} order because two plausible agents appear on the same side of the verb. We found support for this prediction in three languages (English, Japanese, and Korean) by using a gesture-production task, which reflects word-order preferences largely independent of native language. Other patterns of crosslinguistic variation (e.g., the prevalence of case marking in {SOV} languages and its relative absence in {SVO} languages) also straightforwardly follow from the noisy-channel hypothesis.},
}
@article{lambon_ralph_relationship_1997,
	abstract = {We studied the relationship between naming and semantic memory in a group of 10 patients with dementia of Alzheimer's type. In an extension to a previous cross-sectional study (Hodges, J. R. et al., Brain and Language, 1996, 54, 302-325), this relationship was investigated at two longitudinal points within each patient's cognitive decline. Two types of naming performance were compared: items that each patient named correctly at the first stage but failed to name at the second stage, as contrasted with items named correctly at both stages (thereby providing a control for cognitive decline in general). Semantic knowledge of the concepts represented by the pictures in the naming test was investigated at each stage using definitions to the spoken object name, scored particularly for the number of sensory and associative/functional features provided by the patient. At stage 2, an analysis of the definitions for named--{\textgreater}unnamed items as contrasted with named--{\textgreater}named objects revealed a significant loss of both sensory and associative information. A comparison between natural kinds (animals and birds) and artefacts (household objects, vehicles, etc.), however, demonstrated a striking interaction between category and type of information contained in the definitions. Specifically, stage 2 definitions of artefacts in the named--{\textgreater}unnamed set showed a disproportionate loss of associative/functional information, while definitions of animal names that patients failed to produce in response to the pictures were notably lacking in sensory features. This pattern supports the notion that successful naming relies on a subset of critical semantic features which vary somewhat across different categories of semantic knowledge. We suggest that these findings are best encompassed by a conception of semantic organization, Weighted Overlappingly Organized Features ({WOOF)}, in which (i) knowledge about all objects is represented by a central, distributed network of features activated by both words and pictures, but (ii) natural kinds and artefacts are differentially weighted in favour of those features that are involved in learning about and experiencing different kinds of objects.},
}
@incollection{glenberg_bodys_2003,
}
@article{oliveri_all_2004,
	abstract = {A number of researchers have proposed that the premotor and motor areas are critical for the representation of words that refer to actions, but not objects. Recent evidence against this hypothesis indicates that the left premotor cortex is more sensitive to grammatical differences than to conceptual differences between words. However, it may still be the case that other anterior motor regions are engaged in processing a word's sensorimotor features. In the present study, we used singleand paired-pulse transcranial magnetic stimulation to test the hypothesis that left primary motor cortex is activated during the retrieval of words (nouns and verbs) associated with specific actions. We found that activation in the motor cortex increased for action words compared with non-action words, but was not sensitive to the grammatical category of the word being produced. These results complement previous findings and support the notion that producing a word activates some brain regions relevant to the sensorimotor properties associated with that word regardless of its grammatical category.},
}
@article{sudre_tracking_2012,
	abstract = {We present a methodological approach employing magnetoencephalography ({MEG)} and machine learning techniques to investigate the flow of perceptual and semantic information decodable from neural activity in the half second during which the brain comprehends the meaning of a concrete noun. Important information about the cortical location of neural activity related to the representation of nouns in the human brain has been revealed by past studies using {fMRI.} However, the temporal sequence of processing from sensory input to concept comprehension remains unclear, in part because of the poor time resolution provided by {fMRI.} In this study, subjects answered 20 questions (e.g. is it alive?) about the properties of 60 different nouns prompted by simultaneous presentation of a pictured item and its written name. Our results show that the neural activity observed with {MEG} encodes a variety of perceptual and semantic features of stimuli at different times relative to stimulus onset, and in different cortical locations. By decoding these features, our {MEG-based} classifier was able to reliably distinguish between two different concrete nouns that it had never seen before. The results demonstrate that there are clear differences between the time course of the magnitude of {MEG} activity and that of decodable semantic information. Perceptual features were decoded from {MEG} activity earlier in time than semantic features, and features related to animacy, size, and manipulability were decoded consistently across subjects. We also observed that regions commonly associated with semantic processing in the {fMRI} literature may not show high decoding results in {MEG.} We believe that this type of approach and the accompanying machine learning methods can form the basis for further modeling of the flow of neural information during language processing and a variety of other cognitive processes.},
}
@article{pazzaglia_action_2013,
}
@article{gernsbacher_resolving_1984,
	abstract = {Word recognition studies conducted over the past 2 decades manipulated lexical familiarity by presenting words of high vs low printed frequency, and most reported an interaction between printed frequency and one of several second variables, namely, orthographic regularity, semantic concreteness, or polysemy. However, the direction of these interactions was inconsistent from study to study. Six new experiments clarify these discordant results. Exps I and {II}, conducted with 89 college students, demonstrate that words of the same low printed frequency are not always equally familiar to Ss. Instead, Ss' ratings of experiential familiarity suggest that many of the low-printed-frequency words used in prior studies varied along this dimension. Four lexical decision experiments, conducted with 78 undergraduates, reexamined the prior findings by orthogonally manipulating lexical familiarity, as assessed by experiential familiarity ratings, with bigram frequency, semantic concreteness, and number of meanings. Results suggest that of these variables, only experiential familiarity reliably affects word recognition latencies. This in turn suggests that previous inconsistent findings were due to confounding experiential familiarity with a second variable. (68 ref) ({PsycINFO} Database Record (c) 2010 {APA}, all rights reserved)},
}
@article{oreilly_conjunctive_2001-1,
	abstract = {The authors present a theoretical framework for understanding the roles of the hippocampus and neocortex in learning and memory. This framework incorporates a theme found in many theories of hippocampal function: that the hippocampus is responsible for developing conjunctive representations binding together stimulus elements into a unitary representation that can later be recalled from partial input cues. This idea is contradicted by the fact that hippocampally lesioned rats can learn nonlinear discrimination problems that require conjunctive representations. The authors' framework accommodates this finding by establishing a principled division of labor, where the cortex is responsible for slow learning that integrates over multiple experiences to extract generalities whereas the hippocampus performs rapid learning of the arbitrary contents of individual experiences. This framework suggests that tasks involving rapid, incidental conjunctive learning are better tests of hippocampal function. The authors implement this framework in a computational neural network model and show that it can account for a wide range of data in animal learning.},
}
@article{agosta_language_2010,
}
@article{brualla_auditory_1998-1,
	abstract = {The present study uses the N400 component of event-related potentials ({ERPs)} as a processing marker of single spoken words presented during sleep. Thirteen healthy volunteers participated in the study. The auditory {ERPs} were registered in response to a semantic priming paradigm made up of pairs of words (50\% related, 50\% unrelated) presented in the waking state and during sleep stages {II}, {III--IV} and {REM.} The amplitude, latency and scalp distribution parameters of the negativity observed during stage {II} and the {REM} stage were contrasted with the results obtained in the waking state. The {`N400-like'} effect elicited in these stages of sleep showed a mean amplitude for pairs of unrelated words significantly greater than for related pairs and an increment of latency. These results suggest that during these sleep stages a semantic priming effect is maintained actively although the lexical processing time increases.},
}
@article{girelli_are_1997,
	abstract = {Motion information tends to be segregated from color and form information in the visual system, both perceptually and neuroanatomically, and it is therefore possible that different mechanisms of attention are used to select targets defined by these different feature types during visual search. To test this hypothesis, we recorded the N2pc component of the event-related potential waveform during visual search tasks with color, orientation, and motion targets. The N2pc component has previously been shown to reflect a specific attentional mechanism that is present for color and form targets, and we sought to determine whether this component would also be present for motion targets. The N2pc component was indeed observed for motion targets as well as color and orientation targets, consistent with the use of a common attentional mechanism across feature types. In addition, we found that motion singletons (i.e., individual items that moved in the opposite direction from the other items in the army) elicited an N2pc component even when they were task-irrelevant, indicating that motion discontinuities may produce an automatic orienting of attention.},
}
@article{smith_metal_1975-2,
}
@article{caramazza_interpretation_1998,
	abstract = {Abstract What does the existence of semantic category-specific deficits tell us about the organization of conceptual knowledge in the brain? Do these deficits reflect the existence of specialized mechanisms for the recognition and storage of specific semantic categories? Or do they merely reflect differences In the correlational structure of the properties that define concepts in different semantic domains? The received explanations of category-specific deficits have adopted a reductionist perspective, appealing to some or other non-categorical principle to explain the disorder. Some have appealed to the relative importance of the visual properties of objects in distinguishing among members of a semantic category; others have appealed to the relative strengths of correlations between visual and functional properties in different categories. However, there is also a proposal that semantic category-specific deficits reflect the fact that conceptual knowledge is organized into broad semantic domains. These proposals are briefly reviewed here.},
}
@article{barsalou_situated_2003,
	abstract = {Four theories of the human conceptual system---semantic memory, exemplar models, feed-forward connectionist nets, and situated simulation theory---are characterised and contrasted on five dimensions: (1) architecture (modular vs. non-modular), (2) representation (amodal vs. modal), (3) abstraction (decontextualised vs. situated), (4) stability (stable vs. dynamical), and (5) organisation (taxonomic vs. action--environment interface). Empirical evidence is then reviewed for the situated simulation theory, and the following conclusions are reached. Because the conceptual system shares mechanisms with perception and action, it is non-modular. As a result, conceptual representations are multi-modal simulations distributed across modality-specific systems. A given simulation for a concept is situated, preparing an agent for situated action with a particular instance, in a particular setting. Because a concept delivers diverse simulations that prepare agents for action in many different situations, it is dynamical. Because the conceptual system's primary purpose is to support situated action, it becomes organised around the action--environment interface.},
}
@article{pereira_information_2011,
	abstract = {Information mapping using pattern classifiers has become increasingly popular in recent years, although without a clear consensus on which classifier(s) ought to be used or how results should be tested. This paper addresses each of these questions, both analytically and through comparative analyses on five empirical datasets. We also describe how information maps in multiple class situations can provide information concerning the content of neural representations. Finally, we introduce a publically available software toolbox designed specifically for information mapping.},
}
@article{goense_neurophysiology_2008,
	abstract = {{SummaryBackground}
}
@article{watson_functional_2011-2,
	abstract = {Our current understanding of the neural basis of semantic memory is informed primarily by studies of concrete objects. However, conceptual knowledge encompasses many other, albeit less concrete, domains. This article reviews evidence from neuroimaging and patient studies that speaks to the neural basis of action concepts and the words that refer to them. These data highlight 2 important principles governing the neural instantiation of semantic knowledge. First, the organization of conceptual representations in the brain parallels perception and action. Action concepts are at least partially represented within modality-specific areas responsible for the perception and execution of dynamic actions. Second, unimodal sensory and motor cortices act as ``points of entry'' for more abstract action knowledge. Increasingly abstract conceptual knowledge derived from these modalities is represented in brain areas located anterior and centripetal to modality-specific regions. Extending research on the neural basis of semantics to include dynamic and relational aspects of the world gives us a more complete appreciation of the range of cognitive and communication impairments that may be experienced by patients with neurologic disease.},
}
@article{gainotti_neuroanatomical_1995,
	abstract = {Abstract Previous studies of category-specific semantic disturbances have focused their attention on the intrinsic cognitive structure of these disorders. The present survey aims to evaluate the relationships between disrupted semantic category and localisation of the underlying brain damage, in order to establish whether the injured brain areas house just those neurophysiological mechanisms that should have critically contributed to the acquisition of the disrupted semantic categories. We took into account in our review two double dissociations concerning respectively: (1) the impairment of a specific linguistic category--we contrast those disorders selectively affecting verbs (action names) with those selectively affecting nouns (object names); (2) the impairment of a specific conceptual/semantic domain--we contrast disorders selectively affecting living beings with those preferentially affecting man-made artefacts. The hypothesis that different categories of knowledge may be closely intertwined with different sources of sensory-motor information, was substantially confirmed. The lesion preferentially encroached on the left frontal lobe when the category ``verbs'' was selectively affected; it involved the left temporal lobe and the posterior association areas when the category ``nouns'' was preferentially disrupted; it involved bilateral temporo-limbic structures and inferior temporal lobes when the category ``living beings'' was selectively disrupted; it usually encroached on the left fronto-parietal areas when man-made artefacts and body parts were preferentially affected. These data support the hypothesis that: (a) action schemata may critically contribute to the development of the semantic representation of verbs, (b) mechanisms of sensory integration may play an important role in establishing the semantic representation of nouns; (c) high-level visual processing and multi-modal sensory convergency may critically contribute to organising the semantic representation of living beings; (d) motor-kinaesthetic integration may play a leading role in developing the semantic representation of man-made artefacts.},
}
@article{makar_formate_1975-2,
}
@article{meighen_hybrids_1975,
	abstract = {The activities of hybrid dimers of alkaline phosphatase containing two chemically modified subunits have been investigated. One hybrid species was prepared by dissociation and reconstitution of a mixture of two variants produced by chemical modification of the native enzyme with succinic anhydride and tetranitromethane, respectively. The succinyl-nitrotyrosyl hybrid was separated from the other members of the hybrid set by {DEAE-Sephadex} chromatography and then converted to a succinyl-aminotyrosyl hybrid by reduction of the modified tyrosine residues with sodium dithionite. A comparison of the activities of these two hybrids with the activities of the succinyl, nitrotyrosyl and aminotyrosyl derivatives has shown that either the subunits of alkaline phosphatase function independently or if the subunits turnover alternately in a reciprocating mechanism, then the intrinsic activity of each subunit must be strongly dependent on its partner subunit.},
}
@article{martin_neural_2003,
	abstract = {Motivated by neuropsychological investigations of category-specific impairments, many functional brain imaging studies have found distinct patterns of neural activity associated with different object categories. However, the extent to which these category-related activation patterns reflect differences in conceptual representation remains controversial. To investigate this issue, functional magnetic resonance imaging ({fMRI)} was used to record changes in neural activity while subjects interpreted animated vignettes composed of simple geometric shapes in motion. Vignettes interpreted as conveying social interactions elicited a distinct and distributed pattern of neural activity, relative to vignettes interpreted as mechanical actions. This neural system included regions in posterior temporal cortex associated with identifying human faces and other biological objects. In contrast, vignettes interpreted as conveying mechanical actions resulted in activity in posterior temporal lobe sites associated with identifying manipulable objects such as tools. Moreover, social, but not mechanical, interpretations elicited activity in regions implicated in the perception and modulation of emotion (right amygdala and ventromedial prefrontal cortex). Perceiving and understanding social and mechanical concepts depends, in part, on activity in distinct neural networks. Within the social domain, the network includes regions involved in processing and storing information about the form and motion of biological objects, and in perceiving, expressing, and regulating affective responses.},
}
@article{lee_attributing_2012,
	abstract = {The right posterior superior temporal sulcus ({pSTS)} is a neural region involved in assessing the goals and intentions underlying the motion of social agents. Recent research has identified visual cues, such as chasing, that trigger animacy detection and intention attribution. When readily available in a visual display, these cues reliably activate the {pSTS.} Here, using functional magnetic resonance imaging, we examined if attributing intentions to random motion would likewise engage the {pSTS.} Participants viewed displays of four moving circles and were instructed to search for chasing or mirror-correlated motion. On chasing trials, one circle chased another circle, invoking the percept of an intentional agent; while on correlated motion trials, one circle's motion was mirror reflected by another. On the remaining trials, all circles moved randomly. As expected, {pSTS} activation was greater when participants searched for chasing vs correlated motion when these cues were present in the displays. Of critical importance, {pSTS} activation was also greater when participants searched for chasing compared to mirror-correlated motion when the displays in both search conditions were statistically identical random motion. We conclude that {pSTS} activity associated with intention attribution can be invoked by top--down processes in the absence of reliable visual cues for intentionality.},
}
@article{mur_revealing_2008,
}
@incollection{elman_language_1995,
	abstract = {Despite considerable diversity among theories about how humans process language, there are a number of fundamental assumptions which are shared by most such theories. This consensus extends to the very basic question about what counts as a cognitive process. So although many cognitive scientists are fond of referring to the brain as a `mental organ' (e.g., Chomsky, 1975)--implying a similarity to other organs such as the liver or kidneys--it is also assumed that the brain is an organ with special properties which set it apart. Brains `carry out computation' (it is argued); they `entertain propositions'; and they `support representations'. Brains may be organs, but they are very different than the other organs found in the body. Obviously, there are substantial differences between brains and kidneys, just as there are between kidneys and hearts and the skin. It would be silly to minimze these differences. On the other hand, a cautionary note is also in order. The domains over which the various organs operate are quite different, but their common biological substrate is quite similar. The brain is indeed quite remarkable, and does some things which are very similar to human-made symbol processors; but there are also profound differences between the brain and digital symbol processors, and attempts to ignore these on grounds of simplification or abstraction run the risk of fundamentally misunderstanding the nature of neural computation (Churchland \& Sejnowski, 1992). In a larger sense, I raise the more general warning that (as Ed Hutchins has suggested) ``cognition may not be what we think it is''. Among other things, I will suggest in this chapter that language (and cognition in general) may be more usefully understood as the behavior of a dynamical system. I believe this is a view which both acknowledges the similarity of the brain to other bodily organs and respects the evolutionary history of the nervous system, while also acknowledging the very remarkable properties possessed by the brain. In the view I will outline, representations are not abstract symbols but rather regions of state space. Rules are not operations on symbols but rather embedded in the dynamics of the system, a dynamics which permits movement from certain regions to others while making other transitions difficult. Let me emphasize from the beginning that I am not arguing that language behavior is not rule-governed. Instead, I suggest that the nature of the rules may be different than what we have conceived them to be. The remainder of this chapter is organized as follows. In order to make clear how the dynamical approach (instantiated concretely here as a connectionist network) differs from the standard approach, I begin by summarizing some of the central characteristics of the traditional approach to language processing. Then I shall describe a connectionist model which embodies different operating principles from the classical approach to symbolic computation. The results of several simulations using that architecture are presented and discussed. Finally, I will discuss some of the results which may be yielded by this perspective.},
}
@misc{_positive_????,
	abstract = {The human amygdala's involvement in negative emotion is well established, but relatively little is known regarding its role in positive emotion. Here we examined the neural response to emotionally positive, negative, and neutral words using {fMRI.} Relative to neutral words, positive and negative e...},
}
@article{tononi_why_2008,
	abstract = {Consciousness fades during deep nonrapid eye movement ({NREM)} sleep early in the night, yet cortical neurons remain active, keep receiving sensory inputs, and can display patterns of synchronous activity. Why then does consciousness fade? According to the integrated information theory of consciousness, what is critical for consciousness is not firing rates, sensory input, or synchronization per se, but rather the ability of a system to integrate information. If consciousness is the capacity to integrate information, then the brain should be able to generate consciousness to the extent that it has a large repertoire of available states (information), yet it cannot be decomposed into a collection of causally independent subsystems (integration). A key prediction stemming from this hypothesis is that such ability should be greatly reduced in deep {NREM} sleep; the dreamless brain either breaks down into causally independent modules, shrinks its repertoire of possible responses, or both. In this article, we report the results of a series of experiments in which we employed a combination of transcranial magnetic stimulation and high-density electroencephalography ({TMS/hd-EEG)} to directly test this prediction in humans. Altogether, {TMS/hdEEG} measurements suggest that the sleeping brain, despite being active and reactive, loses its ability of entering states that are both integrated and differentiated; it either breaks down in causally independent modules, responding to {TMS} with a short and local activation, or it bursts into an explosive and aspecific response, producing a full-fledged slow wave.},
}
@article{martens_specifying_2009-1,
	abstract = {Classical theories assume that unconscious automatic processes are autonomous and
}
@article{shevell_color_2008,
	abstract = {The appearance of an object or surface depends strongly on the light from other objects and surfaces in view. This review focuses on color in complex scenes, which have regions of different colors in view simultaneously and/or successively, as in natural viewing. Two fundamental properties distinguish the chromatic representation evoked by a complex scene from the representation for an isolated patch of light. First, in complex scenes, the color of an object is not fully determined by the light from that object reaching the eye. Second, the chromatic representation of a complex scene contributes not only to hue, saturation, and brightness, but also to other percepts such as shape, texture, and object segmentation. These two properties are cornerstones of this review, which examines color perception with context that varies over space or time, including color constancy, and chromatic contributions to such percepts as orientation, contour, depth, and motion.},
}
@article{sadato_activation_1996,
}
@article{desmond_estimating_2002,
	abstract = {Estimation of statistical power in functional {MRI} ({fMRI)} requires knowledge of the expected percent signal change between two conditions as well as estimates of the variability in percent signal change. Variability can be divided into intra-subject variability, reflecting noise within the time series, and inter-subject variability, reflecting subject-to-subject differences in activation. The purpose of this study was to obtain estimates of percent signal change and the two sources of variability from {fMRI} data, and then use these parameter estimates in simulation experiments in order to generate power curves. Of interest from these simulations were conclusions concerning how many subjects are needed and how many time points within a scan are optimal in an {fMRI} study of cognitive function. Intra-subject variability was estimated from resting conditions, and inter-subject variability and percent signal change were estimated from verbal working memory data. Simulations derived from these parameters illustrate how percent signal change, intra- and inter-subject variability, and number of time points affect power. An empirical test experiment, using {fMRI} data acquired during somatosensory stimulation, showed good correspondence between the simulation-based power predictions and the power observed within somatosensory regions of interest. Our analyses suggested that for a liberal threshold of 0.05, about 12 subjects were required to achieve 80\% power at the single voxel level for typical activations. At more realistic thresholds, that approach those used after correcting for multiple comparisons, the number of subjects doubled to maintain this level of power.},
}
@article{binkofski_mirror_2003,
	abstract = {Mirror apraxia is a condition in which patients with lesions of the posterior parietal cortex have deficits in reaching to objects presented through a mirror. The aim of the present study was to investigate possible mechanisms underlying this disorder. First, we addressed the question of whether mirror apraxia is exhibited to the same extent in peripersonal and in body space. Four patients with lesions of the posterior parietal lobe on either side and with marked mirror apraxia were required to reach for objects that were presented to them through a mirror and located either in body space (i.e. on the body surface) or in peripersonal space (i.e. in the reaching distance). Whereas reaching for objects located in body space was flawless in all patients, the performance deteriorated when the same objects were transferred to the peripersonal space. Although the objects were located only a few centimetres above the body surface, the patients reached towards the virtual object in the mirror. Based on these results we suggest that mirror apraxia may originate from a dissociation between the representations of body schema and peripersonal space and that objects located on the body surface become integrated into the body schema. In the second part of the study, using positron emission tomography study ({PET)}, we studied the cerebral activation pattern during reaching to objects presented through a mirror in the peripersonal space in healthy subjects. The results show that increased neural activity in the anterior part of the intraparietal sulcus and in the dorsal premotor cortex was bound to the transformation of the target position from the mirror space to the real space. In contrast, the activity related to object localization in the mirror occurred at the parieto-occipital junction. Both mirror and arm transformation involved the medial posterior part of the superior parietal lobule, putatively area V6a. The results demonstrate that acting through a mirror is processed in a number of cortical areas of the dorsal stream.},
}
@article{breedin_reversal_1994,
	abstract = {Abstract Normal subjects are better at identifying and remembering concrete as compared to abstract words (the concreteness effect). We present data on a patient, {DM}, who shows the opposite pattern. {DM} has a progressive semantic loss due to atrophic changes in his temporal lobes, particularly on the left. His semantic impairment predominantly involves object terms, with relative sparing of abstract nouns and most aspects of verb meaning. {DM} showed an advantage for abstract words on a wide range of tasks (e.g. producing definitions, synonymy judgments). These data challenge accounts that attribute the concreteness effect to a quantitative superiority at the level of the underlying conceptual representations. We suggest that there are qualitative differences between abstract and concrete concepts, and that, in particular, concrete concepts are more dependent on perceptual attributes that were disproportionately impaired in {DM.} We propose, further, that perceptual components of semantic representations are associated with structures in the inferior temporal lobe(s).},
}
@article{balota_automatic_1983,
	abstract = {An experiment was conducted to investigate the influence of a briefly presented pattern-masked stimulus on (1) subjects' latency' to make a lexical decision regarding a subsequent letter string and (2) their episodic encoding of that letter string in long-term memory. During the first half of the experiment subjects participated in a primed lexical decision task ({LDT).} Half of the subjects received the primes at a preexperimentally determined critical threshold, whereas the remaining half received the primes at a suprathreshold level. The primes were either related ({GRAPE).} neutral ({XXXXX)}, or unrelated ({BOX)} to the targets ({JAM).} The results of this priming task indicated that subjects responded faster to words which followed a related prime than to words which followed an unrelated prime in both the suprathreshold and, more interestingly, in the threshold condition, where the subjects were actually unable to reliably report the presence of the prime. Subjects were then given an episodic recognition test for the target words which were presented during the {LDT.} In the crucial conditons, the target was either contextually paired with the same related priming word or a different related word. For example, if the subject received the prime {GRAPE} followed by the target {JAM}, then at recognition the subject either received the pair {GRAPE} {JAM} or {TRAFFIC} {JAM}, with the task being to simply recognize the second word in each pair. The recognition results indicated that for the suprathreshold condition there was a large delecterious effect of switching context between study and test, whereas, for the threshold condition, there was virtually no effect of switching context. These results were viewed as indicating that it is possible to produce activation in semantic memory via a threshold stimulus, as indicated by the obtained priming effect; however, this activation does not appear to be useful in directing conscious attention for long-term storage.},
}
@article{colis_cognitive_2006,
}
@article{gaillard_nonconscious_2006,
	abstract = {Whether masked words can be processed at a semantic level remains a controversial issue in cognitive psychology. Although recent behavioral studies have demonstrated masked semantic priming for number words, attempts to generalize this finding to other categories of words have failed. Here, as an alternative to subliminal priming, we introduce a sensitive behavioral method to detect nonconscious semantic processing of words. The logic of this method consists of presenting words close to the threshold for conscious perception and examining whether their semantic content modulates performance in objective and subjective tasks. Our results disclose two independent sources of modulation of the threshold for access to consciousness. First, prior conscious perception of words increases the detection rate of the same words when they are subsequently presented with stronger masking. Second, the threshold for conscious access is lower for emotional words than for neutral ones, even for words that have not been previously consciously perceived, thus implying that written words can receive nonconscious semantic processing.},
}
@article{kiss_erps_2008,
	abstract = {To investigate whether facial expression is processed in the absence of conscious awareness, {ERPs} were recorded in a task in which participants had to identify the expression of masked fearful and neutral target faces. On supraliminal trials (200 ms target duration), in which identification performance was high, a sustained positivity to fearful versus neutral target faces started 140 ms after target face onset. On subliminal trials (8 ms target duration), identification performance was at chance level, but {ERPs} still showed systematic fear-specific effects. An early positivity to fearful target faces was present but smaller than on supraliminal trials. A subsequent enhanced N2 to fearful faces was only present for subliminal trials. In contrast, a P3 enhancement to fearful faces was observed on supraliminal but not subliminal trials. Results demonstrate rapid emotional expression processing in the absence of awareness.},
}
@article{fedorenko_functional_2011,
	abstract = {Neuroscientists have debated for centuries whether some regions of the human brain are selectively engaged in specific high-level mental functions or whether, instead, cognition is implemented in multifunctional brain regions. For the critical case of language, conflicting answers arise from the neuropsychological literature, which features striking dissociations between deficits in linguistic and nonlinguistic abilities, vs. the neuroimaging literature, which has argued for overlap between activations for linguistic and nonlinguistic processes, including arithmetic, domain general abilities like cognitive control, and music. Here, we use functional {MRI} to define classic language regions functionally in each subject individually and then examine the response of these regions to the nonlinguistic functions most commonly argued to engage these regions: arithmetic, working memory, cognitive control, and music. We find little or no response in language regions to these nonlinguistic functions. These data support a clear distinction between language and other cognitive processes, resolving the prior conflict between the neuropsychological and neuroimaging literatures.},
}
@article{damasio_neural_2004,
	abstract = {Using both the lesion method and functional imaging in large cohorts of subjects investigated with the same experimental tasks, we tested the following hypotheses: (A) that the retrieval of words which denote concrete entities belonging to distinct conceptual categories depends upon partially segregated regions in higher-order cortices of the left temporal lobe; and (B) that the retrieval of conceptual knowledge pertaining to the same concrete entities also depends on partially segregated regions; however, those regions will be different from those postulated in hypothesis A, and located predominantly in the right hemisphere (the second hypothesis tested only with the lesion method). The analyses provide support for hypothesis A in that several regions outside the classical Broca and Wernicke language areas are involved in name retrieval of concrete entities, and that there is a partial segregation in the temporal lobe with respect to the conceptual category to which the entities belong, and partial support for hypothesis B in that retrieval of conceptual knowledge is partially segregated from name retrieval in the lesion study. By comparing different approaches the article also addresses a number of method issues that have surfaced in recent studies in this field.},
}
@article{dagenbach_task-induced_1989,
	abstract = {Near-threshold masked semantic priming of lexical decisions is examined under prime presentation conditions established with several different judgment tasks, using a variety of converging indicators to determine whether subjects can introspect on the prime. In the apparent absence of such awareness, priming effects are found to vary nonmonotonically with stimulus onset asynchrony ({SOA)} between prime and mask. Priming initially decreases as {SOA} is shortened in the threshold region, but increases as {SOA} is shortened further. This phenomenon may help to account for discrepancies between studies in which prime presentation conditions were established with different judgment tasks. In addition, priming is influenced by the type of prime information required for successful performance in the judgment task. Facilitation results from related primes relative to unrelated primes after prime presentation conditions have been established with either detection judgments or word discrimination judgments. However, after semantic similarity judgments, related primes produce inhibition. The implication is that different judgment tasks induce different strategies for retrieving information from perceptual encoding mechanisms. These strategies carry over into the priming task, where they influence the operation of encoding mechanisms even when the strategies fail and prime inputs remain unavailable to introspection.},
}
@article{hinton_distributed_1984,
}
